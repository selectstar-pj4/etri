#!/usr/bin/env python3
"""
Web-based COCO Annotation Interface (Flask)
Web-based annotation tool that can be used on remote servers
"""

import argparse
import base64
import json
import os
import threading
import tempfile
import shutil
from io import BytesIO
from datetime import datetime

from flask import Flask, render_template, request, jsonify, make_response
from PIL import Image
from pycocotools.coco import COCO
try:
    from openai import OpenAI
    from openai import RateLimitError
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Gemini support removed - using OpenAI only
GEMINI_AVAILABLE = False

# Google Sheets ì—°ë™
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GOOGLE_SHEETS_AVAILABLE = True
    if __name__ == "__main__" or os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
        print(f"[DEBUG] gspread imported successfully from: {gspread.__file__}")
except ImportError as e:
    GOOGLE_SHEETS_AVAILABLE = False
    print(f"[WARN] gspread not installed. Google Sheets integration will be disabled.")
    print(f"[WARN] Import error: {e}")
    print(f"[DEBUG] Python path: {sys.executable}")
    print(f"[DEBUG] sys.path: {sys.path[:3]}")  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
    print("[INFO] Install with: pip install gspread google-auth")

import re
import sys

# ë””ë²„ê¹…: Python ê²½ë¡œ ì¶œë ¥
if __name__ == "__main__" or os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
    print(f"[DEBUG] Python executable: {sys.executable}")
    print(f"[DEBUG] Python version: {sys.version}")

app = Flask(__name__)
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0

# íŒŒì¼ ì €ì¥ì„ ìœ„í•œ ì ê¸ˆ ê°ì²´ (ì¤‘ë³µ ë°ì´í„° ë°©ì§€)
file_locks = {
    'exo': threading.Lock(),
    'ego': threading.Lock()
}

# API Keys (config.pyì—ì„œ ë¡œë“œ, ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
try:
    from config import OPENAI_API_KEY, DEFAULT_MODEL
    # Google Sheets ì„¤ì • (ì„ íƒì‚¬í•­)
    try:
        from config import GOOGLE_SHEETS_SPREADSHEET_ID, GOOGLE_SHEETS_CREDENTIALS_PATH
    except ImportError:
        GOOGLE_SHEETS_SPREADSHEET_ID = None
        GOOGLE_SHEETS_CREDENTIALS_PATH = None
    # ì‘ì—…ì ID ì„¤ì • (ì„ íƒì‚¬í•­)
    try:
        from config import WORKER_ID
    except ImportError:
        WORKER_ID = None
except ImportError:
    import os
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
    DEFAULT_MODEL = os.getenv('DEFAULT_MODEL', 'openai')
    GOOGLE_SHEETS_SPREADSHEET_ID = os.getenv('GOOGLE_SHEETS_SPREADSHEET_ID', None)
    GOOGLE_SHEETS_CREDENTIALS_PATH = os.getenv('GOOGLE_SHEETS_CREDENTIALS_PATH', None)
    WORKER_ID = os.getenv('WORKER_ID', None)
    if not OPENAI_API_KEY:
        print("[WARN] OpenAI API key not found. Please create config.py or set OPENAI_API_KEY environment variable.")

# ì‘ì—…ì ID ì¶œë ¥
if WORKER_ID:
    print(f"[INFO] ì‘ì—…ì ID: {WORKER_ID}")
else:
    print("[WARN] ì‘ì—…ì IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. config.pyì— WORKER_IDë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

# Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
google_sheets_client = None
if GOOGLE_SHEETS_AVAILABLE and GOOGLE_SHEETS_SPREADSHEET_ID and GOOGLE_SHEETS_CREDENTIALS_PATH:
    try:
        if os.path.exists(GOOGLE_SHEETS_CREDENTIALS_PATH):
            scopes = ['https://www.googleapis.com/auth/spreadsheets']
            credentials = Credentials.from_service_account_file(
                GOOGLE_SHEETS_CREDENTIALS_PATH, scopes=scopes
            )
            google_sheets_client = gspread.authorize(credentials)
            print(f"[INFO] Google Sheets ì—°ë™ í™œì„±í™”: {GOOGLE_SHEETS_SPREADSHEET_ID}")
        else:
            print(f"[WARN] Google Sheets credentials íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {GOOGLE_SHEETS_CREDENTIALS_PATH}")
    except Exception as e:
        print(f"[WARN] Google Sheets ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        google_sheets_client = None
elif GOOGLE_SHEETS_AVAILABLE:
    print("[INFO] Google Sheets ì—°ë™ ë¹„í™œì„±í™” (ì„¤ì • í•„ìš”)")

class COCOWebAnnotator:
    """Web-based COCO annotation tool for creating question-response pairs."""
    
    def __init__(self, mscoco_folder, coco_json_path, output_json_path, categories_json_path=None, test_folder=None):
        # mscoco í´ë” ê²½ë¡œ (exo_imagesì™€ ego_imagesê°€ ìˆëŠ” í´ë”)
        self.mscoco_folder = mscoco_folder
        # í…ŒìŠ¤íŠ¸ í´ë”ê°€ ì§€ì •ë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ë³¸ í´ë” ì‚¬ìš©
        if test_folder:
            self.exo_images_folder = os.path.join(mscoco_folder, test_folder)
            self.ego_images_folder = os.path.join(mscoco_folder, 'ego_images')  # í…ŒìŠ¤íŠ¸ ì‹œì—ë„ egoëŠ” ê¸°ë³¸ í´ë”
        else:
            self.exo_images_folder = os.path.join(mscoco_folder, 'exo_images')
            self.ego_images_folder = os.path.join(mscoco_folder, 'ego_images')
        self.coco_json_path = coco_json_path
        # output_json_pathë¥¼ exo/egoë¡œ ë¶„ë¦¬
        output_dir = os.path.dirname(output_json_path) if os.path.dirname(output_json_path) else '.'
        output_basename = os.path.basename(output_json_path) if os.path.basename(output_json_path) else 'annotations.json'
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ê³  exo/ego ì ‘ë¯¸ì‚¬ ì¶”ê°€
        if output_basename.endswith('.json'):
            base_name = output_basename[:-5]
        else:
            base_name = output_basename
        
        self.output_json_path_exo = os.path.join(output_dir, f'{base_name}_exo.json')
        self.output_json_path_ego = os.path.join(output_dir, f'{base_name}_ego.json')
        
        # Initialize COCO API
        self.coco = COCO(coco_json_path)
        all_image_ids = list(self.coco.imgs.keys())
        
        # ì´ë¯¸ì§€ ìˆœì„œ ì •ë ¬: exo_images ë¨¼ì €, ê·¸ ë‹¤ìŒ ego_images
        exo_image_ids = []
        ego_image_ids = []
        unknown_image_ids = []
        
        # test_folderê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ í´ë”ì— ìˆëŠ” ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬
        if test_folder:
            # test_folderì— ìˆëŠ” ì‹¤ì œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            test_folder_files = set()
            if os.path.exists(self.exo_images_folder):
                test_folder_files = set(os.listdir(self.exo_images_folder))
            
            for image_id in all_image_ids:
                image_info = self.coco.imgs[image_id]
                file_name = image_info.get('file_name', '')
                
                # test_folderì— ìˆëŠ” íŒŒì¼ë§Œ í¬í•¨
                if file_name in test_folder_files:
                    exo_path = os.path.join(self.exo_images_folder, file_name)
                    if os.path.exists(exo_path):
                        exo_image_ids.append(image_id)
        else:
            # test_folderê°€ ì—†ìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ ìˆœíšŒ
            for image_id in all_image_ids:
                image_info = self.coco.imgs[image_id]
                file_name = image_info.get('file_name', '')
                
                # exo_images í´ë”ì— ìˆëŠ”ì§€ í™•ì¸
                exo_path = os.path.join(self.exo_images_folder, file_name)
                ego_path = os.path.join(self.ego_images_folder, file_name)
                
                if os.path.exists(exo_path):
                    exo_image_ids.append(image_id)
                elif os.path.exists(ego_path):
                    ego_image_ids.append(image_id)
                else:
                    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ exoì— ì¶”ê°€ (ë˜ëŠ” unknownì— ì¶”ê°€)
                    unknown_image_ids.append(image_id)
        
        # ì´ë¯¸ì§€ IDë¥¼ íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” í•¨ìˆ˜
        def sort_by_filename(image_id_list):
            """ì´ë¯¸ì§€ ID ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬"""
            def get_filename(image_id):
                image_info = self.coco.imgs.get(image_id, {})
                return image_info.get('file_name', '')
            
            return sorted(image_id_list, key=get_filename)
        
        # test_folderê°€ ì§€ì •ë˜ë©´ exoë§Œ, ì•„ë‹ˆë©´ exo + ego + unknown
        if test_folder:
            self.image_ids = sort_by_filename(exo_image_ids)
            print(f"[INFO] Test folder mode: {len(exo_image_ids)} images from {test_folder} (sorted by filename)")
        else:
            # exo ë¨¼ì €, ê·¸ ë‹¤ìŒ ego, ë§ˆì§€ë§‰ì— unknown (ê°ê° íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬)
            sorted_exo = sort_by_filename(exo_image_ids)
            sorted_ego = sort_by_filename(ego_image_ids)
            sorted_unknown = sort_by_filename(unknown_image_ids)
            self.image_ids = sorted_exo + sorted_ego + sorted_unknown
            print(f"[INFO] Image order: {len(exo_image_ids)} exo images, {len(ego_image_ids)} ego images, {len(unknown_image_ids)} unknown images (all sorted by filename)")

        # --- ì¶”ê°€: category id -> name ë§¤í•‘ ë¡œë“œ ---
        self.category_id_to_name = {}
        if categories_json_path and os.path.exists(categories_json_path):
            try:
                with open(categories_json_path, 'r', encoding='utf-8') as f:
                    cats = json.load(f)
                    # catsê°€ [{"id": 74, "name": "mouse", ...}, ...] í˜•íƒœë¼ê³  ê°€ì •
                    for c in cats:
                        cid = c.get('id')
                        name = c.get('name')
                        if cid is not None and name:
                            self.category_id_to_name[int(cid)] = str(name)
            except Exception as e:
                print(f"[WARN] Failed to load categories_json: {e}")
        # pycocotools fallback
        if not self.category_id_to_name:
            # COCOì˜ ì¹´í…Œê³ ë¦¬ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©
            for cid, info in self.coco.cats.items():
                self.category_id_to_name[int(cid)] = info.get('name', 'unknown')
        # -----------------------------------------
        
        # Load existing annotations (exoì™€ ego ëª¨ë‘ ë¡œë“œ)
        self.annotations = []
        self._reload_annotations()
    
    def _reload_annotations(self):
        """Reload exo and ego annotations (called when needed)"""
        self.annotations = []
        # exo annotations ë¡œë“œ
        if os.path.exists(self.output_json_path_exo):
            try:
                with open(self.output_json_path_exo, 'r', encoding='utf-8') as f:
                    exo_anns = json.load(f)
                    self.annotations.extend(exo_anns)
            except (FileNotFoundError, json.JSONDecodeError) as e:
                print(f"[WARN] Failed to load exo annotations: {e}")
        # ego annotations ë¡œë“œ
        if os.path.exists(self.output_json_path_ego):
            try:
                with open(self.output_json_path_ego, 'r', encoding='utf-8') as f:
                    ego_anns = json.load(f)
                    self.annotations.extend(ego_anns)
            except (FileNotFoundError, json.JSONDecodeError) as e:
                print(f"[WARN] Failed to load ego annotations: {e}")
    

def get_vqa_json_by_filename(image_filename, coco_json_path, mscoco_folder=None, question=None, response=None, rationale=None, bbox=None, view=None):
    """
    ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ë©´, COCO jsonì—ì„œ í•´ë‹¹ ì´ë¯¸ì§€ì˜ image_id/annotation/bbox/categoryë¥¼ ì°¾ì•„
    VQA Output ì˜ˆì‹œì— ë§ëŠ” json(dict)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    question, response, rationale, bbox, viewëŠ” ì¸ìë¡œ ë°›ì•„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ê²°ê³¼ëŠ” íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•Šê³  dictë¡œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    import os
    from pycocotools.coco import COCO

    coco = COCO(coco_json_path)
    # íŒŒì¼ëª… -> image_id, image_path ì°¾ê¸°
    image_id = None
    for img in coco.dataset["images"]:
        if img["file_name"] == image_filename:
            image_id = img["id"]
            break
    if image_id is None:
        raise ValueError(f"Image filename '{image_filename}' not found in COCO json.")

    # ìƒëŒ€ ê²½ë¡œë¡œ image_path ìƒì„± (viewê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
    view_type = view if view else 'exo'
    # mscoco í´ë”ëª… ì¶”ì¶œ
    if mscoco_folder:
        mscoco_folder_name = os.path.basename(os.path.normpath(mscoco_folder))
    else:
        mscoco_folder_name = 'mscoco'
    
    if view_type == 'ego':
        image_path = f"{mscoco_folder_name}/ego_images/{image_filename}"
    else:
        image_path = f"{mscoco_folder_name}/exo_images/{image_filename}"

    # bbox ìë™/ìˆ˜ë™ ì…ë ¥: ì…ë ¥ê°’ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ, ì—†ìœ¼ë©´ ì „ì²´ bbox ëª¨ë‘
    anns = coco.loadAnns(coco.getAnnIds(imgIds=image_id))
    all_bboxes = [a.get("bbox", []) for a in anns]
    bbox_out = bbox if bbox is not None else all_bboxes

    vqa_json = {
        "image_id": image_id,
        "image_path": image_path,  # ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½
        "question": question if question is not None else "",
        "response": response if response is not None else "",
        "rationale": rationale if rationale is not None else "",
        "bbox": bbox_out,
        "view": view_type
    }
    return vqa_json

# Global annotator instance
annotator = None

# ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìºì‹œ (image_idë¥¼ í‚¤ë¡œ ì‚¬ìš©)
image_analysis_cache = {}

# idx ê²€ìƒ‰ ë¼ìš°íŠ¸ ì¶”ê°€ #
@app.route('/api/find/<int:image_id>')
def find_by_image_id(image_id):
    """Return dataset index for the given COCO image_id."""
    if annotator is None or not annotator.image_ids:
        return jsonify({'error': 'Annotator not initialized'}), 500
    try:
        idx = annotator.image_ids.index(image_id)
        return jsonify({'index': idx, 'total': len(annotator.image_ids)})
    except ValueError:
        return jsonify({'error': f'Image ID {image_id} not found'}), 404

@app.route('/')
def index():
    """Render the main annotation interface."""
    response = make_response(render_template('index.html', worker_id=WORKER_ID))
    # ë¸Œë¼ìš°ì € ìºì‹œ ë°©ì§€
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/worker_id', methods=['GET'])
def get_worker_id():
    """Get worker ID from config."""
    return jsonify({'worker_id': WORKER_ID})

@app.route('/api/exo_image_indices', methods=['GET'])
def get_exo_image_indices():
    """Get list of all exo image indices (for batch processing) - ë¹ ë¥¸ ë²„ì „"""
    try:
        exo_indices = []
        for idx, image_id in enumerate(annotator.image_ids):
            image_info = annotator.coco.imgs[image_id]
            file_name = image_info.get('file_name', '')
            exo_path = os.path.join(annotator.exo_images_folder, file_name)
            if os.path.exists(exo_path):
                exo_indices.append(idx)
        
        return jsonify({
            'success': True,
            'exo_indices': exo_indices,
            'total': len(exo_indices)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/image/<int:index>')
def get_image(index):
    """Get image information for a specific index."""
    if index >= len(annotator.image_ids):
        return jsonify({'error': 'Invalid index'}), 400
        
    image_id = annotator.image_ids[index]
    image_info = annotator.coco.imgs[image_id]
    
    # Get annotations for this image
    ann_ids = annotator.coco.getAnnIds(imgIds=image_id)
    annotations = annotator.coco.loadAnns(ann_ids)

    # === ìƒˆë¡œ ì¶”ê°€: bbox/ì¹´í…Œê³ ë¦¬ ë¬¶ìŒ ë°°ì—´ ===
    anns_payload = []
    for ann in annotations:
        bbox = ann.get('bbox', [])
        cid = ann.get('category_id', None)
        name = annotator.category_id_to_name.get(int(cid), 'unknown') if cid is not None else 'unknown'
        anns_payload.append({
            'bbox': bbox,
            'category_id': cid,
            'category_name': name
        })

    # === ì¶”ê°€: category_names ì±„ìš°ê¸° ===
    category_names = []
    for ann in annotations:
        cid = ann.get('category_id', None)
        name = annotator.category_id_to_name.get(int(cid)) if cid is not None else None
        category_names.append(name if name else 'unknown')

    # Check existing annotations (exoì™€ ego ëª¨ë‘ í™•ì¸)
    existing_annotation = None
    for ann in annotator.annotations:
        if ann['image_id'] == image_id:
            existing_annotation = ann
            break

    # Convert image to base64 for web display
    # ê¸°ì¡´ annotationì˜ view íƒ€ì… í™•ì¸í•˜ì—¬ í•´ë‹¹ í´ë”ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    view_type = 'exo'  # ê¸°ë³¸ê°’
    if existing_annotation:
        view_type = existing_annotation.get('view', 'exo')
    else:
        # annotationsì—ì„œ ì°¾ê¸°
        for ann in annotator.annotations:
            if ann.get('image_id') == image_id:
                view_type = ann.get('view', 'exo')
                break
    
    # view íƒ€ì…ì— ë”°ë¼ ì˜¬ë°”ë¥¸ í´ë”ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    if view_type == 'ego':
        image_path = os.path.join(annotator.ego_images_folder, image_info['file_name'])
    else:
        image_path = os.path.join(annotator.exo_images_folder, image_info['file_name'])
    
    # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í´ë”ì—ì„œ ì‹œë„
    if not os.path.exists(image_path):
        print(f"[WARN] Image not found at {image_path}, trying alternative paths...")
        # exoì—ì„œ ì°¾ê¸°
        alt_path_exo = os.path.join(annotator.exo_images_folder, image_info['file_name'])
        alt_path_ego = os.path.join(annotator.ego_images_folder, image_info['file_name'])
        
        if os.path.exists(alt_path_exo):
            image_path = alt_path_exo
            view_type = 'exo'
            print(f"[INFO] Found image in exo_images: {image_path}")
        elif os.path.exists(alt_path_ego):
            image_path = alt_path_ego
            view_type = 'ego'
            print(f"[INFO] Found image in ego_images: {image_path}")
        else:
            # ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
            error_msg = f"Image not found: {image_info['file_name']}\n"
            error_msg += f"Tried paths:\n"
            error_msg += f"  - {alt_path_exo} (exists: {os.path.exists(alt_path_exo)})\n"
            error_msg += f"  - {alt_path_ego} (exists: {os.path.exists(alt_path_ego)})"
            print(f"[ERROR] {error_msg}")
            return jsonify({'error': error_msg}), 500
    
    try:
        with Image.open(image_path) as img:
            original_width, original_height = img.size
            # Resize if too large but keep track of scale
            max_width, max_height = 800, 600
            scale = min(max_width/original_width, 
                       max_height/original_height, 1.0)
            if scale < 1.0:
                new_width = int(original_width * scale)
                new_height = int(original_height * scale)
                img = img.resize((new_width, new_height), 
                                Image.Resampling.LANCZOS)
            else:
                new_width, new_height = original_width, original_height
            
            buffer = BytesIO()
            img.save(buffer, format='JPEG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
    except (IOError, OSError, ValueError) as e:
        return jsonify({'error': f'Failed to load image: {e}'}), 500
    return jsonify({
        'image_id': image_id,
        'image_data': f'data:image/jpeg;base64,{img_base64}',
        'width': image_info['width'],
        'height': image_info['height'],
        'display_width': new_width,
        'display_height': new_height,
        'scale': scale,
        'file_name': image_info['file_name'],
        'bboxes': [ann['bbox'] for ann in annotations],
        'categories': [ann.get('category_id', 0) for ann in annotations],
        'category_names': category_names,  # <<< ì¶”ê°€
        'anns': anns_payload, # <<< ì¶”ê°€
        'existing_annotation': existing_annotation,
        'view_type': view_type,  # ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë”ì— ë”°ë¼ ê²°ì •ëœ view íƒ€ì…
        'current_index': index,
        'total_images': len(annotator.image_ids)
    })

@app.route('/api/translate/question', methods=['POST'])
def translate_question():
    """Translate Korean question to English using GPT-5."""
    data = request.json
    question_ko = data.get('question_ko', '').strip()
    view_type = data.get('view_type', 'exo')  # 'exo' or 'ego'
    
    if not question_ko:
        return jsonify({'success': False, 'error': 'Question (Korean) is required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        # OpenAI API í˜¸ì¶œ (ì½”ë“œì—ì„œ ì§ì ‘ API í‚¤ ì‚¬ìš©)
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # view_typeì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if view_type == 'ego':
            # ego_data_sample.json í˜•ì‹ ì°¸ê³ 
            prompt = f"""Translate the following Korean question to English. You MUST follow this EXACT format for EGO-CENTRIC questions:

CORRECT FORMAT FOR EGO-CENTRIC QUESTIONS:
[Question with <ATT>, <POS>, <REL> tags embedded naturally in the sentence] <choice>(a) option1, (b) option2, (c) option3, (d) option4</choice> And provide the bounding box coordinate of the region related to your answer.

CRITICAL - EGO-CENTRIC QUESTION STARTING PHRASES:
1. If the Korean question contains "~ê´€ì ì—ì„œ" (from the perspective of ~):
   â†’ Translate to: "From the perspective of [person/object], ..."
   Example: "ì‘ì€ ì†Œë…€ì˜ ê´€ì ì—ì„œ" â†’ "From the perspective of the little girl, ..."

2. If the Korean question contains "ë‚´ê°€" or "I'm" (when I am in the image):
   â†’ Translate to: "When I'm [action/position], ..."
   Examples:
   - "ë‚´ê°€ ì†ŒíŒŒ ì˜¤ë¥¸ìª½ì— ì•‰ì•„ ìˆì„ ë•Œ" â†’ "When I'm sitting on the right side of the sofa, ..."
   - "ë‚´ê°€ ì˜ìì— ì•‰ì•„ ìˆì„ ë•Œ" â†’ "When I'm sitting on the chair, ..."
   - "ë‚´ê°€ í…Œì´ë¸” ì•ì— ì„œ ìˆì„ ë•Œ" â†’ "When I'm standing in front of the table, ..."

CRITICAL TAG USAGE RULES:

1. <REL> tag - Use ONLY for RELATIONSHIP terms (distance, order, placement):
   - Examples: "farthest", "closest", "second-closest", "highest in position"
   - DO NOT use for objects or locations

2. <POS> tag - Use ONLY for POSITION/LOCATION information from the perspective:
   - Examples: "on the left side", "on the right side", "in front of", "behind", "to the left of", "to the right of"
   - DO NOT use for object attributes or relationships
   - DO NOT use generic phrases like "in the image"
   - Remember: In ego-centric questions, "left/right" are from the person's perspective

3. <ATT> tag - Use ONLY for ATTRIBUTES or TARGET GROUPS:
   - Examples: "round object", "green object", "white object", "rectangular object", "party item", "furry creature"
   - Use for describing WHAT object/group is being asked about
   
ğŸš¨ CRITICAL - <ATT> TAG IS MANDATORY WHEN:
   - Korean question contains attribute words like: "í°ìƒ‰" (white), "ë¹¨ê°„ìƒ‰" (red), "ì›í˜•" (round), "ì •ì‚¬ê°í˜•" (square), "ì‚¬ëŒ" (person), "ê°ì²´" (object), "ë¬¼ì²´" (item), etc.
   - Korean question ends with "~ì‚¬ëŒì€?" (which person?), "~ê°ì²´ëŠ”?" (which object?), "~ë¬¼ì²´ëŠ”?" (which item?)
   - Korean question mentions specific attributes: "~ìƒ‰" (color), "~ëª¨ì–‘" (shape), "~ì¬ì§ˆ" (material)
   - ALWAYS wrap attribute descriptions in <ATT> tags, even if the question seems simple
   - WRONG: "which white object" (missing <ATT> tag)
   - CORRECT: "which <ATT>white object</ATT>"
   - WRONG: "which person" (missing <ATT> tag)
   - CORRECT: "which <ATT>person</ATT>" or "which <ATT>person in white shirt</ATT>"

Reference examples from ego_data_sample.json:

Example 1: "From the perspective of the little girl standing in front of the man, which <ATT>party item</ATT> is <REL>farthest</REL> and located <POS>to the right</POS> of her? <choice>(a) cake, (b) camera, (c) party plate, (d) flower</choice> And provide the bounding box coordinate of the region related to your answer."

Example 2: "When I'm sitting on the right side of the large sofa, which <ATT>square or rectangular object</ATT> on the <POS>right side of the room</POS> is <REL>farthest from me</REL>? <choice>(a) fan, (b) large bottle, (c) shoe, (d) tv</choice> And provide the bounding box coordinate of the region related to your answer."

Example 3: "From the perspective of the woman, which <ATT>silver object</ATT> <POS>to the right of</POS> her is <REL>closest to her</REL>? <choice>(a) fork, (b) knife, (c) spoon, (d) wine glass</choice> And provide the bounding box coordinate of the region related to your answer."

Korean question: {question_ko}

Translate to English following the EXACT format above. Make sure:
- Use "From the perspective of ~" if Korean contains "~ê´€ì ì—ì„œ"
- Use "When I'm ~" if Korean contains "ë‚´ê°€" or "I'm"
- <REL> is used ONLY for relationship terms (farthest, closest, etc.)
- <POS> is used ONLY for position/location information from the person's perspective (on the left side, on the right side, etc.)
- <ATT> is used ONLY for attributes or target groups (round object, green object, white object, person, etc.)
- ğŸš¨ MANDATORY: If Korean question contains ANY attribute word (color, shape, material, "ì‚¬ëŒ", "ê°ì²´", "ë¬¼ì²´"), you MUST use <ATT> tag
- ğŸš¨ MANDATORY: If Korean question ends with "~ì‚¬ëŒì€?" or "~ê°ì²´ëŠ”?" or "~ë¬¼ì²´ëŠ”?", you MUST include <ATT> tag
- ğŸš¨ MANDATORY: NEVER translate "í°ìƒ‰ ê°ì²´" as "white object" without <ATT> tags - it MUST be "<ATT>white object</ATT>"
- All tags have meaningful content inside them
- <choice> tag comes before "And provide..." phrase
- DO NOT use generic phrases like "in the image" for <POS> tag
- DOUBLE-CHECK: Before finalizing, verify that ALL attribute descriptions are wrapped in <ATT> tags"""
        else:
            # exo_data_sample.json í˜•ì‹ ì°¸ê³ 
            prompt = f"""Translate the following Korean question to English. You MUST follow this EXACT format:

CORRECT FORMAT:
[Question with <ATT>, <POS>, <REL> tags embedded naturally in the sentence] <choice>(a) option1, (b) option2, (c) option3, (d) option4</choice> And provide the bounding box coordinate of the region related to your answer.

CRITICAL TAG USAGE RULES:

1. <REL> tag - Use ONLY for RELATIONSHIP terms (distance, order, placement):
   - Examples: "farthest", "closest", "second-closest", "placed on the floor"
   - DO NOT use for objects or locations

2. <POS> tag - Use ONLY for POSITION/LOCATION information:
   - Examples: "in the center", "on the left side of", "in front of", "to the left side", "on the right side"
   - DO NOT use for object attributes or relationships
   - DO NOT use generic phrases like "in the image"

3. <ATT> tag - Use ONLY for ATTRIBUTES or TARGET GROUPS:
   - Examples: "red object", "square-shaped item", "among the items", "among the visible people", "edible food item", "white object", "round object"
   - Use for describing WHAT object/group is being asked about
   
ğŸš¨ CRITICAL - <ATT> TAG IS MANDATORY WHEN:
   - Korean question contains attribute words like: "í°ìƒ‰" (white), "ë¹¨ê°„ìƒ‰" (red), "ì›í˜•" (round), "ì •ì‚¬ê°í˜•" (square), "ì‚¬ëŒ" (person), "ê°ì²´" (object), "ë¬¼ì²´" (item), etc.
   - Korean question ends with "~ì‚¬ëŒì€?" (which person?), "~ê°ì²´ëŠ”?" (which object?), "~ë¬¼ì²´ëŠ”?" (which item?)
   - Korean question mentions specific attributes: "~ìƒ‰" (color), "~ëª¨ì–‘" (shape), "~ì¬ì§ˆ" (material)
   - ALWAYS wrap attribute descriptions in <ATT> tags, even if the question seems simple
   - WRONG: "which white object" (missing <ATT> tag)
   - CORRECT: "which <ATT>white object</ATT>"
   - WRONG: "which person" (missing <ATT> tag)
   - CORRECT: "which <ATT>person</ATT>" or "which <ATT>person in white shirt</ATT>"

Reference examples from exo_data_sample.json:
- "<REL>Second-closest</REL> to the refrigerator a countertop located <POS>in the center</POS> of the image, which object is it <ATT>among the items</ATT>? <choice>(a) sink, (b) vase, (c) orange bag, (d) rightmost red chair</choice> And provide the bounding box coordinate of the region related to your answer."
- "Which <ATT>square-shaped item</ATT> is <REL>placed on the floor</REL> <POS>in front of</POS> the brown-haired man sitting on the sofa? <choice>(a) handbag, (b) coke, (c) laptop, (d) cell phone</choice> And provide the bounding box coordinate of the region related to your answer."

Korean question: {question_ko}

Translate to English following the EXACT format above. Make sure:
- <REL> is used ONLY for relationship terms (farthest, closest, etc.)
- <POS> is used ONLY for position/location information (in the center, on the left side, etc.)
- <ATT> is used ONLY for attributes or target groups (red object, white object, among the items, person, etc.)
- ğŸš¨ MANDATORY: If Korean question contains ANY attribute word (color, shape, material, "ì‚¬ëŒ", "ê°ì²´", "ë¬¼ì²´"), you MUST use <ATT> tag
- ğŸš¨ MANDATORY: If Korean question ends with "~ì‚¬ëŒì€?" or "~ê°ì²´ëŠ”?" or "~ë¬¼ì²´ëŠ”?", you MUST include <ATT> tag
- ğŸš¨ MANDATORY: NEVER translate "í°ìƒ‰ ê°ì²´" as "white object" without <ATT> tags - it MUST be "<ATT>white object</ATT>"
- All tags have meaningful content inside them
- <choice> tag comes before "And provide..." phrase
- DO NOT use generic phrases like "in the image" for <POS> tag
- DOUBLE-CHECK: Before finalizing, verify that ALL attribute descriptions are wrapped in <ATT> tags"""
        
        # view_typeì— ë”°ë¼ ë‹¤ë¥¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì‚¬ìš©
        if view_type == 'ego':
            system_message = "You are a professional translator specializing in VQA (Visual Question Answering) EGO-CENTRIC questions. CRITICAL RULES: 1) Use 'From the perspective of ~' for '~ê´€ì ì—ì„œ', 2) Use 'When I'm ~' for 'ë‚´ê°€', 3) <REL> tag ONLY for relationship terms (farthest, closest, etc.), 4) <POS> tag ONLY for position/location from person's perspective (on the left side, on the right side, etc.), 5) <ATT> tag ONLY for attributes/target groups (round object, green object, white object, person, etc.), 6) ğŸš¨ MANDATORY: If Korean contains ANY attribute word (color, shape, material, 'ì‚¬ëŒ', 'ê°ì²´', 'ë¬¼ì²´'), you MUST use <ATT> tag, 7) ğŸš¨ MANDATORY: If Korean ends with '~ì‚¬ëŒì€?' or '~ê°ì²´ëŠ”?', you MUST include <ATT> tag, 8) Tags MUST contain actual meaningful content, 9) Format: [Question with tags] <choice>...</choice> And provide..., 10) DO NOT use generic phrases like 'in the image' for <POS> tag, 11) DOUBLE-CHECK: Verify ALL attribute descriptions are wrapped in <ATT> tags."
        else:
            system_message = "You are a professional translator specializing in VQA (Visual Question Answering) questions. CRITICAL RULES: 1) <REL> tag ONLY for relationship terms (farthest, closest, etc.), 2) <POS> tag ONLY for position/location (in the center, on the left side, etc.), 3) <ATT> tag ONLY for attributes/target groups (red object, white object, among the items, person, etc.), 4) ğŸš¨ MANDATORY: If Korean contains ANY attribute word (color, shape, material, 'ì‚¬ëŒ', 'ê°ì²´', 'ë¬¼ì²´'), you MUST use <ATT> tag, 5) ğŸš¨ MANDATORY: If Korean ends with '~ì‚¬ëŒì€?' or '~ê°ì²´ëŠ”?', you MUST include <ATT> tag, 6) Tags MUST contain actual meaningful content, 7) Format: [Question with tags] <choice>...</choice> And provide..., 8) DO NOT use generic phrases like 'in the image' for <POS> tag, 9) DOUBLE-CHECK: Verify ALL attribute descriptions are wrapped in <ATT> tags."
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        translated_question = response.choices[0].message.content.strip()
        
        # íƒœê·¸ ê²€ì¦
        if '<ATT>' not in translated_question and '<POS>' not in translated_question and '<REL>' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must include at least one of <ATT>, <POS>, or <REL> tags'}), 400
        
        # ATT íƒœê·¸ ëˆ„ë½ ê²€ì¦ ê°•í™”: í•œêµ­ì–´ ì§ˆë¬¸ì— ì†ì„± ë‹¨ì–´ê°€ ìˆëŠ”ë° ATT íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°
        attribute_keywords_ko = ['í°ìƒ‰', 'ë¹¨ê°„ìƒ‰', 'íŒŒë€ìƒ‰', 'ì´ˆë¡ìƒ‰', 'ê²€ì€ìƒ‰', 'ë…¸ë€ìƒ‰', 'ì›í˜•', 'ì •ì‚¬ê°í˜•', 'ì§ì‚¬ê°í˜•', 'ì‚¬ëŒ', 'ê°ì²´', 'ë¬¼ì²´', 'ìƒ‰', 'ëª¨ì–‘', 'ì¬ì§ˆ']
        question_has_attribute = any(keyword in question_ko for keyword in attribute_keywords_ko)
        if question_has_attribute and '<ATT>' not in translated_question:
            return jsonify({
                'success': False, 
                'error': f'ATT tag is missing! Korean question contains attribute words but translation lacks <ATT> tag. Please ensure all attribute descriptions are wrapped in <ATT> tags. Translation: {translated_question[:200]}...'
            }), 400
        
        if '<choice>' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must include <choice> tag'}), 400
        
        if 'And provide the bounding box coordinate of the region related to your answer.' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must end with the required phrase'}), 400
        
        return jsonify({
            'success': True,
            'translated_question': translated_question
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/translate/choices', methods=['POST'])
def translate_choices():
    """Translate Korean choices to English and format as <choice> tag."""
    data = request.json
    choice_a = data.get('choice_a', '').strip()
    choice_b = data.get('choice_b', '').strip()
    choice_c = data.get('choice_c', '').strip()
    choice_d = data.get('choice_d', '').strip()
    
    if not all([choice_a, choice_b, choice_c, choice_d]):
        return jsonify({'success': False, 'error': 'All choices are required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY environment variable not set'}), 500
        
        client = OpenAI(api_key=api_key)
        
        prompt = f"""Translate the following Korean multiple choice options to English. Use concise, intuitive adjective+noun or noun+noun format (NOT full sentences).

CRITICAL FORMATTING RULES:
- Use concise, intuitive format: adjective + noun or noun + noun
- Examples:
  * "a person in a black shirt" â†’ "black shirt person"
  * "a person wearing glasses" â†’ "glasses person"
  * "a cup on the table" â†’ "table cup" or "cup"
  * "a red chair" â†’ "red chair"
  * "a man with a blue t-shirt" â†’ "blue t-shirt man"
- DO NOT use full sentences like "a person who is wearing a black shirt"
- DO NOT use articles "a" or "the" unless necessary
- Keep it short and intuitive

Korean choices:
(a) {choice_a}
(b) {choice_b}
(c) {choice_c}
(d) {choice_d}

Translate each option to English and format as: <choice>(a) translated_a, (b) translated_b, (c) translated_c, (d) translated_d</choice>

Return only the formatted <choice> tag with translations."""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a translator specializing in concise, intuitive translations for multiple choice options. CRITICAL: Use adjective+noun or noun+noun format (e.g., 'black shirt person', 'glasses person'), NOT full sentences. Keep translations short and intuitive."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        translated_choices = response.choices[0].message.content.strip()
        
        # <choice> íƒœê·¸ ì¶”ì¶œ
        choice_match = re.search(r'<choice>(.*?)</choice>', translated_choices, re.IGNORECASE)
        if not choice_match:
            return jsonify({'success': False, 'error': 'Translation must include <choice> tag'}), 400
        
        choice_content = choice_match.group(1)
        # ê° ì„ íƒì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        choice_texts = {}
        for letter in ['a', 'b', 'c', 'd']:
            pattern = rf'\({letter}\)\s*([^,)]+)'
            match = re.search(pattern, choice_content, re.IGNORECASE)
            if match:
                choice_texts[letter] = match.group(1).strip()
        
        return jsonify({
            'success': True,
            'translated_choices': translated_choices,
            'choice_texts': choice_texts
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


# Gemini functions removed - using OpenAI only

def analyze_image_with_model(image_base64, model='openai', image_path=None):
    """ì´ë¯¸ì§€ ë¶„ì„ì„ ëª¨ë¸ë³„ë¡œ ìˆ˜í–‰í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    analysis_prompt = """Analyze this image in detail and extract specific visual features. Focus on:

1. **Objects with detailed attributes**: 
   - Color (e.g., "yellow cup", "red chair", "blue bag")
   - Size/shape (e.g., "large square table", "small round plate")
   - Material/texture (e.g., "wooden shelf", "glass window", "metal door")

2. **Spatial relationships and positions**:
   - Location (e.g., "book on the shelf", "cup on the table", "person in the corner")
   - Relative positions (e.g., "left side of the image", "center of the room", "right edge")
   - Orientation (e.g., "person facing right", "door opening left", "chair tilted")

3. **Detailed object descriptions**:
   - Specific features (e.g., "person wearing glasses", "book with red cover", "chair with armrests")
   - States/conditions (e.g., "open door", "closed window", "empty cup")
   - Interactions (e.g., "person holding cup", "book placed on shelf")

4. **Spatial context**:
   - Room/space type (e.g., "kitchen", "living room", "office")
   - Layout information (e.g., "countertop in center", "refrigerator on left side")
   - Distance relationships (e.g., "closest to camera", "farthest from door")

Provide a comprehensive but concise description that captures these detailed visual features. Format the output as structured text that can be used to understand spatial relationships and object attributes for VQA (Visual Question Answering) tasks."""
    
    if model == 'openai' or model == 'gpt':
        if not OPENAI_AVAILABLE:
            raise Exception('OpenAI library not installed. Install with: pip install openai')
        if not OPENAI_API_KEY:
            raise Exception('OPENAI_API_KEY is not set')
        
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": [{
                    "type": "text",
                    "text": analysis_prompt
                }, {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }]
            }],
            temperature=0.3,
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()
    
    else:
        raise Exception(f'Unknown model: {model}. Supported models: "openai", "gpt"')

@app.route('/api/analyze_image/<int:index>', methods=['GET'])
def analyze_image(index):
    """Analyze image using GPT-4o to extract detailed features."""
    if index >= len(annotator.image_ids):
        return jsonify({'error': 'Invalid index'}), 400
    
    image_id = annotator.image_ids[index]
    model = request.args.get('model', DEFAULT_MODEL).lower()
    
    # ìºì‹œ í™•ì¸ (ëª¨ë¸ë³„ ìºì‹œ í‚¤)
    cache_key = f"{image_id}_{model}"
    if cache_key in image_analysis_cache:
        return jsonify({
            'success': True,
            'image_id': image_id,
            'analysis': image_analysis_cache[cache_key],
            'cached': True,
            'model': model
        })
    
    try:
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° base64 ë³€í™˜
        image_info = annotator.coco.imgs[image_id]
        
        # Check existing annotations to determine view type
        existing_annotation = None
        for ann in annotator.annotations:
            if ann['image_id'] == image_id:
                existing_annotation = ann
                break
        
        view_type = 'exo'
        if existing_annotation:
            view_type = existing_annotation.get('view', 'exo')
        
        if view_type == 'ego':
            image_path = os.path.join(annotator.ego_images_folder, image_info['file_name'])
        else:
            image_path = os.path.join(annotator.exo_images_folder, image_info['file_name'])
        
        if not os.path.exists(image_path):
            alt_path_exo = os.path.join(annotator.exo_images_folder, image_info['file_name'])
            alt_path_ego = os.path.join(annotator.ego_images_folder, image_info['file_name'])
            if os.path.exists(alt_path_exo):
                image_path = alt_path_exo
            elif os.path.exists(alt_path_ego):
                image_path = alt_path_ego
            else:
                return jsonify({'success': False, 'error': f'Image not found: {image_info["file_name"]}'}), 404
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜ (ë¶„ì„ìš©ìœ¼ë¡œëŠ” ì›ë³¸ í¬ê¸° ì‚¬ìš©, ìµœëŒ€ 1024x1024ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)
        with Image.open(image_path) as img:
            original_width, original_height = img.size
            # Vision APIëŠ” ìµœëŒ€ 20MPê¹Œì§€ ì§€ì›í•˜ì§€ë§Œ, í† í° ì ˆì•½ì„ ìœ„í•´ ë¦¬ì‚¬ì´ì¦ˆ
            max_size = 1024
            if original_width > max_size or original_height > max_size:
                scale = min(max_size/original_width, max_size/original_height)
                new_width = int(original_width * scale)
                new_height = int(original_height * scale)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            buffer = BytesIO()
            img.save(buffer, format='JPEG', quality=85)
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        # ëª¨ë¸ë³„ ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰ (CLIP-2 í†µí•© ì§€ì›)
        analysis_result = analyze_image_with_model(img_base64, model, image_path)
        
        # ìºì‹œì— ì €ì¥ (ëª¨ë¸ë³„ í‚¤ ì‚¬ìš©)
        image_analysis_cache[cache_key] = analysis_result
        
        return jsonify({
            'success': True,
            'image_id': image_id,
            'analysis': analysis_result,
            'cached': False,
            'model': model
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/generate_question_and_choices', methods=['POST'])
def generate_question_and_choices():
    """Generate Korean question and choices using GPT-4o, after image analysis with GPT-4o."""
    data = request.json
    image_id = data.get('image_id', None)
    index = data.get('index', None)
    # ê¸°ë³¸ê°’ì€ DEFAULT_MODEL ì‚¬ìš©
    model = data.get('model', DEFAULT_MODEL).lower()
    
    if image_id is None and index is None:
        return jsonify({'success': False, 'error': 'image_id or index is required'}), 400
    
    try:
        # image_idê°€ ì—†ìœ¼ë©´ indexë¡œ ì°¾ê¸°
        if image_id is None:
            if index >= len(annotator.image_ids):
                return jsonify({'error': 'Invalid index'}), 400
            image_id = annotator.image_ids[index]
        
        # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ (ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©) - ìºì‹œ í™•ì¸ ë˜ëŠ” ì‹¤í–‰
        image_analysis = ""
        image_path = None  # image_path ì´ˆê¸°í™”
        cache_key = f"{image_id}_{model}"
        if cache_key in image_analysis_cache:
            image_analysis = image_analysis_cache[cache_key]
        else:
            # ì´ë¯¸ì§€ ë¶„ì„ API í˜¸ì¶œ (ìºì‹œì— ì—†ìœ¼ë©´ ì‹¤í–‰)
            # index ì°¾ê¸°
            if index is None:
                for idx, img_id in enumerate(annotator.image_ids):
                    if img_id == image_id:
                        index = idx
                        break
                if index is None:
                    return jsonify({'success': False, 'error': 'Image not found'}), 404
            
            # analyze_image í•¨ìˆ˜ ë¡œì§ ì¬ì‚¬ìš©
            image_info = annotator.coco.imgs[image_id]
            existing_annotation = None
            for ann in annotator.annotations:
                if ann['image_id'] == image_id:
                    existing_annotation = ann
                    break
            
            view_type = 'exo'
            if existing_annotation:
                view_type = existing_annotation.get('view', 'exo')
            
            if view_type == 'ego':
                image_path = os.path.join(annotator.ego_images_folder, image_info['file_name'])
            else:
                image_path = os.path.join(annotator.exo_images_folder, image_info['file_name'])
            
            if not os.path.exists(image_path):
                alt_path_exo = os.path.join(annotator.exo_images_folder, image_info['file_name'])
                alt_path_ego = os.path.join(annotator.ego_images_folder, image_info['file_name'])
                if os.path.exists(alt_path_exo):
                    image_path = alt_path_exo
                elif os.path.exists(alt_path_ego):
                    image_path = alt_path_ego
                else:
                    return jsonify({'success': False, 'error': f'Image not found: {image_info["file_name"]}'}), 404
            
            # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰ (GPT-4o-mini)
            with Image.open(image_path) as img:
                original_width, original_height = img.size
                max_size = 1024
                if original_width > max_size or original_height > max_size:
                    scale = min(max_size/original_width, max_size/original_height)
                    new_width = int(original_width * scale)
                    new_height = int(original_height * scale)
                    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                buffer = BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            # ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰
            image_analysis = analyze_image_with_model(img_base64, model, image_path)
            image_analysis_cache[cache_key] = image_analysis
        
        # 2ë‹¨ê³„: COCO ì–´ë…¸í…Œì´ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        ann_ids = annotator.coco.getAnnIds(imgIds=image_id)
        annotations = annotator.coco.loadAnns(ann_ids)
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´ êµ¬ì„±
        category_info = []
        for ann in annotations:
            cid = ann.get('category_id', None)
            name = annotator.category_id_to_name.get(int(cid), 'unknown') if cid is not None else 'unknown'
            bbox = ann.get('bbox', [])
            category_info.append({
                'category_name': name,
                'bbox': bbox
            })
        
        # ì£¼ìš” ê°ì²´ ëª©ë¡ ìƒì„±
        main_objects = list(set([cat['category_name'] for cat in category_info if cat['category_name'] != 'unknown']))[:10]
        
        # 3ë‹¨ê³„: ì§ˆë¬¸ ìƒì„± (OpenAIë§Œ ì‚¬ìš©)
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in config.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # 3-hop ì§ˆë¬¸ ìƒì„±: ATT, POS, RELì´ ëª¨ë‘ í¬í•¨ëœ ë³µì¡í•œ ì§ˆë¬¸
        question_generation_prompt = f"""ì´ë¯¸ì§€ì™€ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ VQA (Visual Question Answering) 3-hop ì§ˆë¬¸ì„ í•œê¸€ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ğŸš¨ **ì ˆëŒ€ í•„ìˆ˜ ê·œì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•¨**:

**STEP 1: ì´ë¯¸ì§€ ë‚´ìš© ì§ì ‘ í™•ì¸ ë° ATT ì†ì„± ê²€ì¦ (ì ˆëŒ€ í•„ìˆ˜)**

ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì§ì ‘ í™•ì¸í•˜ê³ , ì§ˆë¬¸ì— ì‚¬ìš©í•  ATT ì†ì„±ì´ ì‹¤ì œ ì´ë¯¸ì§€ì˜ ê°ì²´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.

ğŸš¨ **CRITICAL - ATT ì†ì„± ì •í™•ì„± ê²€ì¦ (ì ˆëŒ€ í•„ìˆ˜)**:
1. ì§ˆë¬¸ì—ì„œ ì‚¬ìš©í•  ATT ì†ì„±(ì˜ˆ: "ë¹¨ê°„ìƒ‰ ê°ì²´", "ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´", "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´")ì„ ë¨¼ì € ê²°ì •í•˜ì„¸ìš”.
2. ì´ë¯¸ì§€ë¥¼ ì§ì ‘ í™•ì¸í•˜ì—¬ í•´ë‹¹ ATT ì†ì„±ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ë“¤ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
3. ì˜ˆë¥¼ ë“¤ì–´, "í°ìƒ‰ ê°ì²´"ë¼ê³  ì§ˆë¬¸í•˜ë ¤ë©´ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ í°ìƒ‰ ê°ì²´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
4. ì˜ˆë¥¼ ë“¤ì–´, "ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜• ê°ì²´"ë¼ê³  ì§ˆë¬¸í•˜ë ¤ë©´ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜• ê°ì²´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
5. ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì†ì„±ì„ ATTë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤.

**ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ì§ˆë¬¸ì—ì„œ ì‚¬ìš©í•  ATT ì†ì„±ì´ ì‹¤ì œ ì´ë¯¸ì§€ì˜ ê°ì²´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ê°€?
- [ ] ATT ì†ì„±ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì†ì„±ì„ ATTë¡œ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ëŠ”ê°€?

**STEP 2: ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ 3-hop ì§ˆë¬¸ êµ¬ì¡° ìƒì„±**

ğŸš¨ **CRITICAL - ì§ˆë¬¸ ë³µì¡ë„ ë° ê³ ê¸‰ ì¶”ë¡  ìš”êµ¬ì‚¬í•­ (ì ˆëŒ€ í•„ìˆ˜)**:

ê° ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ATT(ì†ì„±), POS(ìœ„ì¹˜), REL(ê´€ê³„) ì„¸ ê°€ì§€ ìš”ì†Œë¥¼ ëª¨ë‘ í¬í•¨í•´ì•¼ í•˜ë©°, **ë‹¨ìˆœí•œ ì§ˆë¬¸ì€ ì ˆëŒ€ ê¸ˆì§€**ì…ë‹ˆë‹¤.

**âŒ ì ˆëŒ€ ê¸ˆì§€ - ë„ˆë¬´ ë‹¨ìˆœí•œ ì§ˆë¬¸ íŒ¨í„´**:
- "X ì˜¤ë¥¸ìª½ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„± ì¡°í•©)
- "X ìœ„ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„± ì¡°í•©)
- "X ì™¼ìª½ì— ìˆëŠ” ê°€ì¥ ë¨¼ Y ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„± ì¡°í•©)

**âœ… ë°˜ë“œì‹œ ì‚¬ìš© - ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸ íŒ¨í„´**:

1. **ì¤‘ì²©ëœ ì¡°ê±´ ì¡°í•©**:
   - "X <POS>ìœ„ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Zë¡œë¶€í„° <REL>ê°€ì¥ ë¨¼</REL> ê°ì²´"
   - "X <POS>ì™¼ìª½ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ì•ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ê°€ê¹Œìš´</REL> ê°ì²´"
   - "<ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ X <POS>ìœ„ì— ìˆëŠ”</POS> Zë¡œë¶€í„° <REL>ê°€ì¥ ë¨¼</REL> ê°ì²´"

2. **ë³µì¡í•œ ê¸°ì¤€ì ê³¼ ëŒ€ìƒì˜ ì¡°í•©**:
   - "X <POS>ìœ„ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT>ë¡œë¶€í„° <REL>ê°€ì¥ ë¨¼</REL> <ATT>Z ê°ì²´</ATT>"
   - "X <POS>ì•ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ì˜†ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ê°€ê¹Œìš´</REL> ê°ì²´"

3. **ì—¬ëŸ¬ ì¡°ê±´ì´ ë™ì‹œì— ì ìš©ë˜ëŠ” ì§ˆë¬¸**:
   - "<ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ X <POS>ìœ„ì—</POS> <REL>ë†“ì—¬ ìˆëŠ”</REL> Z <POS>ì•ì— ìˆëŠ”</POS> ê°ì²´"
   - "<ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ X <POS>ì˜†ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ë†’ì€</REL> ê°ì²´"

4. **ë³µì¡í•œ ê³µê°„ ê´€ê³„**:
   - "X <POS>ì•ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ë°˜ëŒ€í¸ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ë¨¼</REL> ê°ì²´"
   - "X <POS>ì¤‘ì•™ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ì˜†ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ê°€ê¹Œìš´</REL> ê°ì²´"

**ATT (ì†ì„±/ëŒ€ìƒ) ê·œì¹™ - CRITICAL: ì†ì„± ê¸°ë°˜ í‘œí˜„ë§Œ ì‚¬ìš©, êµ¬ì²´ì  ëª…ì‚¬ ê¸ˆì§€**:
- âŒ **ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ - êµ¬ì²´ì  ëª…ì‚¬**: "ì»µ", "ì ‘ì‹œ", "ì˜ì", "í…Œì´ë¸”" ë“±
- âœ… **ë°˜ë“œì‹œ ì‚¬ìš© - ì†ì„± ê¸°ë°˜ í‘œí˜„**:
  * "ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´" (ì»µ, ë³‘ ë“±)
  * "ë°ì€ ìƒ‰ìƒì˜ ê°ì²´" (ë°ì€ ìƒ‰ì˜ ë¬¼ì²´ë“¤)
  * "íŒŒí‹°ìš©í’ˆ ê°ì²´" (íŒŒí‹° ê´€ë ¨ ë¬¼ì²´ë“¤)
  * "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´" (ë¨¹ì„ ìˆ˜ ìˆëŠ” ê²ƒë“¤)
  * "ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜• ê°ì²´" (ì‚¬ê°í˜• ëª¨ì–‘)
  * "ë¹¨ê°„ìƒ‰ ê°ì²´", "í°ìƒ‰ ìƒ‰ìƒì˜ ê°ì²´" (ìƒ‰ìƒ ê¸°ë°˜)
  * "ë‚˜ë¬´ ì¬ì§ˆì˜ ê°ì²´" (ì¬ì§ˆ ê¸°ë°˜)

**POS (ìœ„ì¹˜) ê·œì¹™**:
- âŒ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€: "ì´ë¯¸ì§€ ì¤‘ì•™ì—", "ì´ë¯¸ì§€ ì™¼ìª½ì—" (ëª¨í˜¸í•¨)
- âœ… ë°˜ë“œì‹œ ì‚¬ìš©: "í…Œì´ë¸” ì¤‘ì•™ì—", "ì†ŒíŒŒ ì™¼ìª½ì—", "ì‹±í¬ëŒ€ ì˜¤ë¥¸ìª½ì—" (êµ¬ì²´ì  ê°ì²´ ê¸°ì¤€)
- **ìœ„ì¹˜ ë°˜ì „ ê·œì¹™**: ì‹¤ì œë¡œ "ì™¼ìª½"ì— ìˆìœ¼ë©´ ì§ˆë¬¸ì—ì„œëŠ” "ì˜¤ë¥¸ìª½"ìœ¼ë¡œ í‘œí˜„

**REL (ê´€ê³„) ê·œì¹™**:
- "ê°€ì¥ ê°€ê¹Œìš´", "ê°€ì¥ ë¨¼", "ë‘ ë²ˆì§¸ë¡œ ê°€ê¹Œìš´" ë“±

**ğŸš¨ CRITICAL - ì§ˆë¬¸ ë í‘œí˜„ ê·œì¹™ (ì ˆëŒ€ í•„ìˆ˜)**:
ì§ˆë¬¸ì€ ë°˜ë“œì‹œ "~ê°ì²´"ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤. "ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ê°™ì€ ì˜ë¬¸ì‚¬ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

- âŒ **ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€**:
  * "~ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?" (ì‚¬ëŒì„ ë¬»ëŠ” í˜•ì‹ ê¸ˆì§€)
  * "ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" (ëª¨í˜¸í•œ í‘œí˜„ ê¸ˆì§€)
  * "ê°€ì¥ ê°€ê¹Œìš´ ê²ƒì€?" (ATT ì†ì„± ë¯¸ëª…ì‹œ)
  * "ê°€ì¥ ë¨¼ ê²ƒì€?" (ATT ì†ì„± ë¯¸ëª…ì‹œ)
  * "~ê°ì²´ëŠ”?" ("ëŠ”?" ì‚¬ìš© ê¸ˆì§€)
  * "~ê°ì²´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ("ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš© ê¸ˆì§€)
  * "ë¬´ì—‡ì¸ê°€ìš”?" (ATT ì†ì„±ì´ ëª…ì‹œë˜ì§€ ì•Šì€ í˜•ì‹ ê¸ˆì§€)

- âœ… **ë°˜ë“œì‹œ ì‚¬ìš© - "~ê°ì²´"ë¡œ ëë‚˜ëŠ” í˜•ì‹**:
  * "ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜•ì˜ ê°ì²´"
  * "ì›í†µí˜• ë˜ëŠ” ì›í˜•ì˜ ê°ì²´"
  * "ë°ì€ ìƒ‰ìƒì˜ ê°ì²´"
  * "ë¬´ì±„ìƒ‰ ê°ì²´"
  * "ê¸ˆì† ì¬ì§ˆì˜ ê°ì²´"
  * "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´"
  * "ë¹¨ê°„ìƒ‰ ê°ì²´"
  * "ë‚˜ë¬´ ì¬ì§ˆì˜ ê°ì²´"

**ì§ˆë¬¸ í˜•ì‹ ì˜ˆì‹œ**:
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ ì›í˜• ë˜ëŠ” ì›í†µí˜•ì˜ ê°ì²´"
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "ì†ŒíŒŒ ì™¼ìª½ì— ìœ„ì¹˜í•œ ë°ì€ ìƒ‰ìƒì˜ ê°ì²´"
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "ì‹±í¬ëŒ€ ì˜¤ë¥¸ìª½ì— ìˆëŠ” ë¬´ì±„ìƒ‰ ê°ì²´"
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í¬í¬ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´"
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ì†ŒíŒŒ ì™¼ìª½ì— ìˆëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?" (ì‚¬ëŒì„ ë¬»ëŠ” í˜•ì‹, "ëŠ”?" ì‚¬ìš©)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" (ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš©)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ê°€ì¥ ê°€ê¹Œìš´ ê²ƒì€?" (ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ”?" ì‚¬ìš©)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ëŠ”?" ("ëŠ”?" ì‚¬ìš© ê¸ˆì§€)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ("ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš© ê¸ˆì§€)

**ì¤‘ìš”**: ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ATT ì†ì„±ì„ í¬í•¨í•œ "~ê°ì²´"ë¡œ ëë‚˜ì•¼ í•˜ë©°, "ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ê°™ì€ ì˜ë¬¸ì‚¬ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì§ˆë¬¸ì€ "~ê°ì²´"ë¡œ ëë‚˜ëŠ” ëª…ì‚¬êµ¬ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.

**STEP 3: ì†Œê±°ë²•ì„ ìœ„í•œ ì„ íƒì§€ ì„¤ê³„ ë° ê²€ì¦ (ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬)**

ğŸš¨ **CRITICAL - ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬ë¥¼ ìœ„í•œ ì„ íƒì§€ êµ¬ì„± (ì ˆëŒ€ í•„ìˆ˜)**:
- ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— **ìµœì†Œ 2ê°œ ì´ìƒ** ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
- ì´ë ‡ê²Œ í•´ì•¼ ë‹¤ë¥¸ AIê°€ ë¬¸ì œë¥¼ í’€ ë•Œ ë‹¨ìˆœíˆ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì •ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ê³ , ì¶”ê°€ì ì¸ ì¶”ë¡ (ìœ„ì¹˜, ê±°ë¦¬ ë“±)ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ 1 - ì˜¬ë°”ë¥¸ êµ¬ì„± (ê³ ê¸‰ ì¶”ë¡  ìš”êµ¬)**:
ì§ˆë¬¸: "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´ ì¤‘ì—ì„œ..."
ì„ íƒì§€:
- a: ì¼€ì´í¬ ì¡°ê° (ATT ì¡°ê±´ ë§Œì¡±, í•˜ì§€ë§Œ ë‹¤ë¥¸ ì¡°ê±´ ë¶ˆë§Œì¡±)
- b: ì¼€ì´í¬ ì¡°ê° (ATT ì¡°ê±´ ë§Œì¡±, í•˜ì§€ë§Œ ë‹¤ë¥¸ ì¡°ê±´ ë¶ˆë§Œì¡±) â† ë‹¤ë¥¸ ì¼€ì´í¬ ì¡°ê°
- c: í”¼ì (ATT ì¡°ê±´ ë§Œì¡±, í•˜ì§€ë§Œ ë‹¤ë¥¸ ì¡°ê±´ ë¶ˆë§Œì¡±)
- d: í–„ë²„ê±° (ì •ë‹µ: ATT ì¡°ê±´ ë§Œì¡± + ë‹¤ë¥¸ ëª¨ë“  ì¡°ê±´ ë§Œì¡±)

ì´ ê²½ìš° ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 4ê°œ(a, b, c, d ëª¨ë‘)ì´ë¯€ë¡œ ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ 2 - ì˜ëª»ëœ êµ¬ì„± (ë„ˆë¬´ ì‰¬ì›€)**:
ì§ˆë¬¸: "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´ ì¤‘ì—ì„œ..."
ì„ íƒì§€:
- a: ì»µ (ATT ì¡°ê±´ ë¶ˆë§Œì¡± - ì‹ìš© ë¶ˆê°€)
- b: ì ‘ì‹œ (ATT ì¡°ê±´ ë¶ˆë§Œì¡± - ì‹ìš© ë¶ˆê°€)
- c: í¬í¬ (ATT ì¡°ê±´ ë¶ˆë§Œì¡± - ì‹ìš© ë¶ˆê°€)
- d: ì¼€ì´í¬ ì¡°ê° (ì •ë‹µ: ATT ì¡°ê±´ ë§Œì¡±)

ì´ ê²½ìš° ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 1ê°œ(dë§Œ)ì´ë¯€ë¡œ ë„ˆë¬´ ì‰½ìŠµë‹ˆë‹¤. âŒ

**ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— ìµœì†Œ 2ê°œ ì´ìƒ ìˆëŠ”ê°€? (ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬)
- [ ] ê° ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë  ìˆ˜ ìˆëŠ”ê°€?
- [ ] ì„ íƒì§€ì— ë™ì¼í•œ ë¬¼ì²´ê°€ ì¤‘ë³µë˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ì„ íƒì§€ì˜ ëª¨ë“  ê°ì²´ê°€ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?

**STEP 4: ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€**

ğŸš¨ **CRITICAL - ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€ (ì ˆëŒ€ í•„ìˆ˜)**:
- ê° ì„ íƒì§€ëŠ” ë°˜ë“œì‹œ **ì„œë¡œ ë‹¤ë¥¸ ê°ì²´ ì¸ìŠ¤í„´ìŠ¤**ë¥¼ ê°€ë¦¬ì¼œì•¼ í•©ë‹ˆë‹¤.
- ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ ê°ì²´ë¼ë„, ì´ë¯¸ì§€ ë‚´ì—ì„œ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤(ë‹¤ë¥¸ bbox)ë¥¼ ê°€ë¦¬ì¼œì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆ: ì´ë¯¸ì§€ì— "ì»µ"ì´ 3ê°œ ìˆì–´ë„, ì„ íƒì§€ì— "ì»µ"ì´ 2ë²ˆ ë‚˜ì˜¤ë©´ ì•ˆ ë©ë‹ˆë‹¤. ê°ê° "ì™¼ìª½ ì»µ", "ì˜¤ë¥¸ìª½ ì»µ", "ì¤‘ì•™ ì»µ" ë“±ìœ¼ë¡œ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤.

**ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼**:
{image_analysis}

**COCO ê°ì²´ ì •ë³´ (bboxë¡œ ì‹ë³„ ê°€ëŠ¥í•œ ê°ì²´ë“¤)**:
- ì£¼ìš” ê°ì²´: {', '.join(main_objects) if main_objects else 'ì—†ìŒ'}
- ì´ ê°ì²´ ìˆ˜: {len(category_info)}
- ê° ê°ì²´ëŠ” ì´ë¯¸ì§€ ë‚´ bboxë¡œ ì •í™•íˆ ì‹ë³„ ê°€ëŠ¥í•¨

**ì¤‘ìš”**: ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì—ì„œ ì–¸ê¸‰ëœ ê°ì²´ë“¤ ì¤‘ì—ì„œ, COCO ì–´ë…¸í…Œì´ì…˜ì— ì¡´ì¬í•˜ëŠ” ê°ì²´ë§Œ ì„ íƒì§€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. ê°™ì€ ì¢…ë¥˜ì˜ ê°ì²´ê°€ ì—¬ëŸ¬ ê°œ ìˆìœ¼ë©´ ìƒ‰ìƒ, ìœ„ì¹˜, ì†ì„± ë“±ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”.

**ğŸš¨ CRITICAL - ì°¸ê³  ì˜ˆì‹œ (exo_data_sample.json, web_annotations_exo.json ìŠ¤íƒ€ì¼)**:

ë‹¤ìŒ ì˜ˆì‹œë“¤ì„ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ **ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ** ì§ˆë¬¸ê³¼ ì„ íƒì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”:

**ì˜ˆì‹œ 1** (exo_data_sample.json - ë³µì¡í•œ ì¡°ê±´ ì¡°í•©):
- ì§ˆë¬¸: "Which <ATT>edible food item</ATT> is the <REL>farthest</REL> from the fork <POS>on the left side of</POS> the table?"
- ì„ íƒì§€: (a) glass, (b) potato fries, (c) hamburger, (d) cell phone
- ê·¼ê±°: cell phoneì€ ì‹ìš© ë¶ˆê°€ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), glassë„ ì‹ìš© ë¶ˆê°€ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), potato friesëŠ” hamburgerë³´ë‹¤ ê°€ê¹Œì›€ (REL ì¡°ê±´ ë¶ˆë§Œì¡±), ë”°ë¼ì„œ hamburgerê°€ ì •ë‹µ
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´ + POS ì¡°ê±´ + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 2ê°œ(b, c) ìˆì–´ì„œ ë‹¨ìˆœíˆ ATTë§Œ í™•ì¸í•´ì„œëŠ” ì•ˆ ë¨

**ì˜ˆì‹œ 2** (exo_data_sample.json - ì¤‘ì²©ëœ ê³µê°„ ê´€ê³„):
- ì§ˆë¬¸: "Which <ATT>round and cylindrical object</ATT> is <REL>farthest</REL> from the person sitting <POS>on the right side of</POS> the dining table?"
- ì„ íƒì§€: (a) plate, (b) white cake, (c) rightmost coke, (d) vase
- ê·¼ê±°: plate, white cake, rightmost cokeëŠ” ëª¨ë‘ ê°€ê¹Œìš´ í¸ì´ì§€ë§Œ, vaseëŠ” í…Œì´ë¸” ë°˜ëŒ€í¸ì— ìœ„ì¹˜í•˜ì—¬ ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìŒ
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´ + POS ì¡°ê±´(ì‚¬ëŒì˜ ìœ„ì¹˜) + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 4ê°œ(a, b, c, d ëª¨ë‘) ìˆì–´ì„œ ê±°ë¦¬ ê³„ì‚°ì´ í•„ìš”í•¨

**ì˜ˆì‹œ 3** (exo_data_sample.json - ì—¬ëŸ¬ ì¡°ê±´ ë™ì‹œ ì ìš©):
- ì§ˆë¬¸: "Which <ATT>square-shaped item</ATT> is <REL>placed on the floor</REL> <POS>in front of</POS> the brown-haired man sitting on the sofa?"
- ì„ íƒì§€: (a) handbag, (b) coke, (c) laptop, (d) cell phone
- ê·¼ê±°: laptopê³¼ cell phoneì€ ì†ŒíŒŒ ìœ„ì— ìˆìŒ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), cokeëŠ” ì›í†µí˜•ì´ë¯€ë¡œ ì œì™¸ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), handbagë§Œ ë°”ë‹¥ì— ìˆê³  ì‚¬ê°í˜• ëª¨ì–‘ (ëª¨ë“  ì¡°ê±´ ë§Œì¡±)
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´ + REL ì¡°ê±´(ìœ„ì¹˜ ìƒíƒœ) + POS ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ê° ì„ íƒì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë¨ (ìœ„ì¹˜, í˜•íƒœ ë“±)

**ì˜ˆì‹œ 4** (web_annotations_exo.json - ë³µì¡í•œ ê¸°ì¤€ì ):
- ì§ˆë¬¸: "Which object is <REL>farthest</REL> from the <ATT>white object</ATT> <POS>on the left side of</POS> the child wearing a striped shirt in the center?"
- ì„ íƒì§€: (a) keyboard, (b) piano, (c) sofa, (d) plant
- ê·¼ê±°: sofaëŠ” ì•„ì´ ì˜¤ë¥¸ìª½ì— ìˆìŒ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), keyboardì™€ pianoëŠ” ë” ê°€ê¹Œì›€ (REL ì¡°ê±´ ë¶ˆë§Œì¡±), plantê°€ ê°€ì¥ ë©€ë¦¬ ìˆìŒ
- âœ… **ë³µì¡ë„**: ê¸°ì¤€ì ì´ "í°ìƒ‰ ê°ì²´"ì´ê³ , ê·¸ ê°ì²´ì˜ ìœ„ì¹˜ê°€ "ì•„ì´ ì™¼ìª½"ì´ë¼ëŠ” ì¤‘ì²©ëœ ì¡°ê±´
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ê¸°ì¤€ì ì„ ë¨¼ì € ì°¾ê³ , ê·¸ ê¸°ì¤€ì ìœ¼ë¡œë¶€í„° ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì•¼ í•¨

**ì˜ˆì‹œ 5** (web_annotations_exo.json - ë³µì¡í•œ ì†ì„± ì¡°í•©):
- ì§ˆë¬¸: "Which <ATT>object that can hold water</ATT> is the <REL>closest</REL> to the pizza placed in front of the woman <POS>on the left</POS>?"
- ì„ íƒì§€: (a) fork, (b) empty glass, (c) blue vase, (d) water glass
- ê·¼ê±°: forkëŠ” ë¬¼ì„ ë‹´ì„ ìˆ˜ ì—†ìŒ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), blue vaseì™€ water glassëŠ” ì˜¤ë¥¸ìª½ ì—¬ìì—ê²Œ ë” ê°€ê¹Œì›€ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), empty glassê°€ ì™¼ìª½ ì—¬ì ì• í”¼ìì— ê°€ì¥ ê°€ê¹Œì›€
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´(ê¸°ëŠ¥ì  ì†ì„±) + POS ì¡°ê±´(ì—¬ìì˜ ìœ„ì¹˜) + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 3ê°œ(b, c, d) ìˆì–´ì„œ ìœ„ì¹˜ì™€ ê±°ë¦¬ë¥¼ ëª¨ë‘ ê³ ë ¤í•´ì•¼ í•¨

**ì˜ˆì‹œ 6** (web_annotations_exo.json - ë³µì¡í•œ ê³µê°„ ê´€ê³„):
- ì§ˆë¬¸: "Which object <REL>farthest</REL> from the window <POS>on the table</POS> among the <ATT>square or rectangular objects</ATT>?"
- ì„ íƒì§€: (a) backpack, (b) laptop, (c) beige book, (d) blue bowl
- ê·¼ê±°: backpackì€ í…Œì´ë¸” ìœ„ì— ì—†ìŒ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), blue bowlì€ ì‚¬ê°í˜•ì´ ì•„ë‹˜ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), laptopì€ beige bookë³´ë‹¤ ì°½ë¬¸ì— ê°€ê¹Œì›€ (REL ì¡°ê±´ ë¶ˆë§Œì¡±), beige bookì´ ê°€ì¥ ë©€ë¦¬ ìˆìŒ
- âœ… **ë³µì¡ë„**: POS ì¡°ê±´ + ATT ì¡°ê±´ + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ê° ì„ íƒì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë˜ê³ , ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ ì¤‘ì—ì„œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì•¼ í•¨

**ğŸš¨ CRITICAL - ì„ íƒì§€ êµ¬ì„± ì›ì¹™ (ì ˆëŒ€ í•„ìˆ˜)**:

1. **ë‹¤ì–‘í•œ ì œì™¸ ì´ìœ **: ê° ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:
   - ATT ì¡°ê±´ ë¶ˆë§Œì¡± (ì†ì„±, í˜•íƒœ, ìƒ‰ìƒ ë“±)
   - POS ì¡°ê±´ ë¶ˆë§Œì¡± (ìœ„ì¹˜, ê³µê°„ ê´€ê³„ ë“±)
   - REL ì¡°ê±´ ë¶ˆë§Œì¡± (ê±°ë¦¬, ìˆœì„œ ë“±)
   - ì—¬ëŸ¬ ì¡°ê±´ ë™ì‹œ ë¶ˆë§Œì¡±

2. **ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ**: ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— ìµœì†Œ 2ê°œ ì´ìƒ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•´ì•¼ ë‹¨ìˆœíˆ ATT ì¡°ê±´ë§Œ í™•ì¸í•´ì„œëŠ” ì •ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ê³ , ì¶”ê°€ì ì¸ ì¶”ë¡ (POS, REL)ì´ í•„ìš”í•©ë‹ˆë‹¤.

3. **ì„ íƒì§€ ë‹¤ì–‘ì„±**: ì„ íƒì§€ëŠ” ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì™€ ì†ì„±ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
   - âŒ ë‚˜ìœ ì˜ˆ: "ë°ì€ ìƒ‰ìƒì˜ ì˜ì", "ë°ì€ ìƒ‰ìƒì˜ ë²¤ì¹˜", "ë°ì€ ìƒ‰ìƒì˜ ì‹íƒ", "ë°ì€ ìƒ‰ìƒì˜ ì“°ë ˆê¸°í†µ" (ëª¨ë‘ ê°™ì€ ì†ì„±)
   - âœ… ì¢‹ì€ ì˜ˆ: "glass", "potato fries", "hamburger", "cell phone" (ë‹¤ì–‘í•œ ì†ì„±ê³¼ ì¹´í…Œê³ ë¦¬)

**ì¤‘ìš”**: ìœ„ ì˜ˆì‹œë“¤ì„ ì°¸ê³ í•˜ì—¬:
1. **ë³µì¡í•œ ì§ˆë¬¸ êµ¬ì¡°**: ë‹¨ìˆœí•œ "X ì˜¤ë¥¸ìª½ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" í˜•ì‹ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
2. **ì¤‘ì²©ëœ ì¡°ê±´**: ì—¬ëŸ¬ ì¡°ê±´ì´ ë™ì‹œì— ì ìš©ë˜ëŠ” ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”
3. **ë‹¤ì–‘í•œ ì œì™¸ ì´ìœ **: ê° ì„ íƒì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë˜ë„ë¡ êµ¬ì„±í•˜ì„¸ìš”
4. **ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ**: ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•˜ë„ë¡ ì„ íƒì§€ë¥¼ êµ¬ì„±í•˜ì„¸ìš”

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ, ì •í™•íˆ 3ê°œë§Œ ìƒì„±)**:

ğŸš¨ **CRITICAL**: ëª¨ë“  ì§ˆë¬¸ì€ ë°˜ë“œì‹œ "~ê°ì²´"ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤. "ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ê°™ì€ ì˜ë¬¸ì‚¬ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "questions": [
    {{
      "question": "ì²« ë²ˆì§¸ 3-hop í•œê¸€ ì§ˆë¬¸ (ATTëŠ” ì†ì„± ê¸°ë°˜ í‘œí˜„, POSëŠ” êµ¬ì²´ì  ê°ì²´ ê¸°ì¤€, REL í¬í•¨, ì†Œê±°ë²• ê°€ëŠ¥í•œ ì„ íƒì§€ êµ¬ì„±, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ, ë°˜ë“œì‹œ '~ê°ì²´'ë¡œ ëë‚¨, 'ëŠ”?' ë˜ëŠ” 'ëŠ” ë¬´ì—‡ì¸ê°€ìš”?' ì‚¬ìš© ê¸ˆì§€)",
      "choices": {{
        "a": "ì„ íƒì§€ a (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "b": "ì„ íƒì§€ b (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "c": "ì„ íƒì§€ c (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "d": "ì„ íƒì§€ d (í•œê¸€, ì •ë‹µ, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ì¤‘ í•˜ë‚˜)"
      }},
      "correct_answer": "a"
    }},
    {{
      "question": "ë‘ ë²ˆì§¸ 3-hop í•œê¸€ ì§ˆë¬¸ (ì²« ë²ˆì§¸ì™€ ë‹¤ë¥¸ êµ¬ì¡°/ì¡°í•©, ATTëŠ” ì†ì„± ê¸°ë°˜ í‘œí˜„, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ, ë°˜ë“œì‹œ '~ê°ì²´'ë¡œ ëë‚¨, 'ëŠ”?' ë˜ëŠ” 'ëŠ” ë¬´ì—‡ì¸ê°€ìš”?' ì‚¬ìš© ê¸ˆì§€)",
      "choices": {{
        "a": "ì„ íƒì§€ a (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "b": "ì„ íƒì§€ b (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "c": "ì„ íƒì§€ c (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "d": "ì„ íƒì§€ d (í•œê¸€, ì •ë‹µ, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ì¤‘ í•˜ë‚˜)"
      }},
      "correct_answer": "b"
    }},
    {{
      "question": "ì„¸ ë²ˆì§¸ 3-hop í•œê¸€ ì§ˆë¬¸ (ì•ì˜ ë‘ ì§ˆë¬¸ê³¼ ë‹¤ë¥¸ êµ¬ì¡°/ì¡°í•©, ATTëŠ” ì†ì„± ê¸°ë°˜ í‘œí˜„, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ, ë°˜ë“œì‹œ '~ê°ì²´'ë¡œ ëë‚¨, 'ëŠ”?' ë˜ëŠ” 'ëŠ” ë¬´ì—‡ì¸ê°€ìš”?' ì‚¬ìš© ê¸ˆì§€)",
      "choices": {{
        "a": "ì„ íƒì§€ a (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "b": "ì„ íƒì§€ b (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "c": "ì„ íƒì§€ c (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "d": "ì„ íƒì§€ d (í•œê¸€, ì •ë‹µ, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ì¤‘ í•˜ë‚˜)"
      }},
      "correct_answer": "c"
    }}
  ]
}}

**ì§ˆë¬¸ í˜•ì‹ ì˜ˆì‹œ (ë°˜ë“œì‹œ ì°¸ê³ )**:

**âŒ ì ˆëŒ€ ê¸ˆì§€ - ë„ˆë¬´ ë‹¨ìˆœí•œ ì§ˆë¬¸**:
- "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ ì›í˜• ë˜ëŠ” ì›í†µí˜•ì˜ ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„±)
- "ì†ŒíŒŒ ì™¼ìª½ì— ìœ„ì¹˜í•œ ë°ì€ ìƒ‰ìƒì˜ ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„±)
- "ì‹±í¬ëŒ€ ì˜¤ë¥¸ìª½ì— ìˆëŠ” ë¬´ì±„ìƒ‰ ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„±)
- "ì†ŒíŒŒ ì™¼ìª½ì— ìˆëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?" (ê¸ˆì§€ - "ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?" ì‚¬ìš©)
- "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" (ê¸ˆì§€ - ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš©)
- "ê°€ì¥ ê°€ê¹Œìš´ ê²ƒì€?" (ê¸ˆì§€ - ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ”?" ì‚¬ìš©)

**âœ… ë°˜ë“œì‹œ ì‚¬ìš© - ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸**:
- "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í¬í¬ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´" (ATT + REL + ê¸°ì¤€ì )
- "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´ ì¤‘ì—ì„œ ì‚¬ëŒìœ¼ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´" (POS + ATT + REL)
- "ì†ŒíŒŒ ì™¼ìª½ì— ìˆëŠ” ë°ì€ ìƒ‰ìƒì˜ ê°ì²´ ì¤‘ì—ì„œ ì°½ë¬¸ìœ¼ë¡œë¶€í„° ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´" (POS + ATT + REL)
- "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í¬í¬ ì™¼ìª½ì— ìˆëŠ” ê°€ì¥ ë¨¼ ê°ì²´" (ATT + POS + REL)
- "í…Œì´ë¸” ì¤‘ì•™ì— ìˆëŠ” ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´ ì¤‘ì—ì„œ ì‚¬ëŒ ì•ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´" (POS + ATT + POS + REL)
- "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í…Œì´ë¸” ì™¼ìª½ì— ìˆëŠ” í¬í¬ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´" (ATT + POS + REL)

ğŸš¨ **ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìƒì„± ì „ ë°˜ë“œì‹œ í™•ì¸)**:

**ì§ˆë¬¸ ë³µì¡ë„ ê²€ì¦**:
- [ ] ì§ˆë¬¸ì´ ë‹¨ìˆœí•œ "X ì˜¤ë¥¸ìª½ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" í˜•ì‹ì´ ì•„ë‹Œê°€? (ì´ëŸ° í˜•ì‹ì€ ì ˆëŒ€ ê¸ˆì§€)
- [ ] ì§ˆë¬¸ì— ì¤‘ì²©ëœ ì¡°ê±´ì´ë‚˜ ë³µì¡í•œ ê³µê°„ ê´€ê³„ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
- [ ] ê° ì§ˆë¬¸ì— ATT, POS, RELì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆê³ , ì„œë¡œ ë³µì¡í•˜ê²Œ ì–½í˜€ìˆëŠ”ê°€?

**ì§ˆë¬¸ í˜•ì‹ ê²€ì¦**:
- [ ] **CRITICAL**: ì§ˆë¬¸ì´ "~ê°ì²´"ë¡œ ëë‚˜ëŠ”ê°€? ("ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "~ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?", "ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" í˜•ì‹ ê¸ˆì§€)
- [ ] ATT íƒœê·¸ì— êµ¬ì²´ì  ëª…ì‚¬("ì»µ", "ì ‘ì‹œ" ë“±)ê°€ ì•„ë‹Œ ì†ì„± ê¸°ë°˜ í‘œí˜„("ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´" ë“±)ì„ ì‚¬ìš©í–ˆëŠ”ê°€?
- [ ] ATT ì†ì„±ì´ ì‹¤ì œ ì´ë¯¸ì§€ì˜ ê°ì²´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ê°€?
- [ ] POS í‘œí˜„ì´ êµ¬ì²´ì  ê°ì²´ ê¸°ì¤€ì¸ê°€? ("ì´ë¯¸ì§€ ì¤‘ì•™" ëŒ€ì‹  "í…Œì´ë¸” ì¤‘ì•™" ë“±)
- [ ] ìœ„ì¹˜ ë°˜ì „ ê·œì¹™ì„ ì ìš©í–ˆëŠ”ê°€? (ì‹¤ì œ ì™¼ìª½ â†’ ì§ˆë¬¸ì—ì„œëŠ” ì˜¤ë¥¸ìª½)

**ì„ íƒì§€ êµ¬ì„± ê²€ì¦**:
- [ ] ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— ìµœì†Œ 2ê°œ ì´ìƒ ìˆëŠ”ê°€? (ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬)
- [ ] ê° ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë  ìˆ˜ ìˆëŠ”ê°€? (ATT ë¶ˆë§Œì¡±, POS ë¶ˆë§Œì¡±, REL ë¶ˆë§Œì¡± ë“±)
- [ ] ì„ íƒì§€ì— ë™ì¼í•œ ë¬¼ì²´ê°€ ì¤‘ë³µë˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ì„ íƒì§€ì˜ ëª¨ë“  ê°ì²´ê°€ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] ì„ íƒì§€ê°€ ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì™€ ì†ì„±ì„ í¬í•¨í•˜ê³  ìˆëŠ”ê°€? (ëª¨ë‘ ê°™ì€ ì†ì„±ì˜ ê°ì²´ê°€ ì•„ë‹Œê°€?)

**ì¤‘ìš”**: ì •í™•íˆ 3ê°œì˜ ì§ˆë¬¸ë§Œ ìƒì„±í•˜ê³ , ê° ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ìœ„ì˜ ëª¨ë“  ê·œì¹™ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""

        # RateLimitError ì²˜ë¦¬: ì¬ì‹œë„ ë¡œì§ í¬í•¨
        max_retries = 5
        retry_delay = 1  # ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        
        generation_response = None
        generated_content = None
        
        for attempt in range(max_retries):
            try:
                generation_response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {
                            "role": "system",
                            "content": "You are an expert VQA question generator specializing in complex, multi-hop reasoning questions. CRITICAL RULES: 1) Each question MUST include ATT (attribute), POS (position), REL (relationship) in a COMPLEX, INTERWOVEN manner - NOT simple patterns like 'X right side, closest Y object'. 2) Questions MUST require advanced reasoning with nested conditions, multiple spatial relationships, or complex attribute combinations. 3) Use ONLY objects that actually exist in the image. 4) Choices must be clearly distinguishable and diverse (use color, position: 'red cup', 'leftmost chair'). 5) For POS, use specific object references ('center of table', NOT 'center of image'). 6) Reverse left/right positions in questions. 7) Use ONLY objective attributes (color, shape, material) - NEVER subjective ('small', 'pretty'). 8) Ask about concrete objects, NOT abstract properties. 9) At least 2 choices MUST satisfy the ATT condition to require advanced reasoning. 10) Each choice should be excluded for DIFFERENT reasons (ATT failure, POS failure, REL failure, etc.). 11) Generate exactly 3 questions with DIFFERENT complex structures. Return valid JSON."
                        },
                        {
                            "role": "user",
                            "content": question_generation_prompt
                        }
                    ],
                    temperature=0.5,
                    max_tokens=2000,
                    response_format={"type": "json_object"}
                )
                
                generated_content = generation_response.choices[0].message.content.strip()
                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
                
            except RateLimitError as e:
                if attempt < max_retries - 1:
                    # retry_after ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ exponential backoff
                    wait_time = getattr(e, 'retry_after', None)
                    if wait_time is None:
                        wait_time = retry_delay * (2 ** attempt)  # exponential backoff
                    else:
                        wait_time = float(wait_time) + 1  # retry_afterì— 1ì´ˆ ì¶”ê°€ ì—¬ìœ 
                    
                    print(f"[WARN] Rate limit reached. Waiting {wait_time:.2f} seconds before retry {attempt + 1}/{max_retries}...")
                    import time
                    time.sleep(wait_time)
                    continue
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ ë°˜í™˜
                    return jsonify({
                        'success': False,
                        'error': f'Rate limit exceeded after {max_retries} retries. Please try again later or reduce parallel workers.'
                    }), 429
            except Exception as e:
                # RateLimitErrorê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ë°˜í™˜
                import traceback
                traceback.print_exc()
                return jsonify({'success': False, 'error': f'OpenAI question generation failed: {str(e)}'}), 500
        
        if generated_content is None:
            return jsonify({
                'success': False,
                'error': 'Failed to generate questions after retries'
            }), 500
        
        # JSON íŒŒì‹±
        try:
            import json
            generated_data = json.loads(generated_content)
            questions = generated_data.get('questions', [])
            
            if not questions:
                return jsonify({'success': False, 'error': 'No questions generated'}), 500
            
            # ì •í™•íˆ 3ê°œë§Œ ë°˜í™˜ (ë” ë§ìœ¼ë©´ ì•ì˜ 3ê°œë§Œ)
            if len(questions) > 3:
                questions = questions[:3]
            elif len(questions) < 3:
                return jsonify({'success': False, 'error': f'Expected 3 questions but got {len(questions)}'}), 500
            
            return jsonify({
                'success': True,
                'image_id': image_id,
                'questions': questions
            })
        except json.JSONDecodeError as e:
            return jsonify({'success': False, 'error': f'Failed to parse JSON: {str(e)}', 'raw_response': generated_content}), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'OpenAI question generation failed: {str(e)}'}), 500

@app.route('/api/translate/question_and_choices', methods=['POST'])
def translate_question_and_choices():
    """Translate Korean question and choices to English together using GPT-5, with image analysis context."""
    data = request.json
    question_ko = data.get('question_ko', '').strip()
    choice_a = data.get('choice_a', '').strip()
    choice_b = data.get('choice_b', '').strip()
    choice_c = data.get('choice_c', '').strip()
    choice_d = data.get('choice_d', '').strip()
    image_id = data.get('image_id', None)  # ì´ë¯¸ì§€ ID ì¶”ê°€
    view_type = data.get('view_type', 'exo')  # 'exo' or 'ego'
    
    if not question_ko:
        return jsonify({'success': False, 'error': 'Question (Korean) is required'}), 400
    
    if not all([choice_a, choice_b, choice_c, choice_d]):
        return jsonify({'success': False, 'error': 'All choices are required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ìºì‹œì—ì„œë§Œ í™•ì¸)
        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì´ë¯¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìºì‹œë§Œ í™•ì¸
        # ìºì‹œ í‚¤ëŠ” "image_id_model" í˜•ì‹ì´ë¯€ë¡œ ëª¨ë“  ëª¨ë¸ì˜ ìºì‹œë¥¼ í™•ì¸
        image_analysis = ""
        if image_id:
            # ê¸°ë³¸ ëª¨ë¸ë¶€í„° í™•ì¸
            for model_name in [DEFAULT_MODEL, 'openai']:
                cache_key = f"{image_id}_{model_name}"
                if cache_key in image_analysis_cache:
                    image_analysis = image_analysis_cache[cache_key]
                    break
        
        # Questionê³¼ Choicesë¥¼ í•¨ê»˜ ë²ˆì—­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ (ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í¬í•¨)
        image_context = ""
        if image_analysis:
            image_context = f"""

IMAGE ANALYSIS CONTEXT:
{image_analysis}

Use this image analysis to better understand the context and spatial relationships mentioned in the Korean question. The analysis includes detailed features like colors, positions, orientations, and spatial relationships of objects in the image. Use this information to create more accurate <ATT>, <POS>, and <REL> tags that match the actual visual content."""
        
        # view_typeì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if view_type == 'ego':
            prompt = f"""Translate the following Korean question and multiple choice options to English. You MUST follow this EXACT format for EGO-CENTRIC questions:{image_context}

CORRECT FORMAT FOR EGO-CENTRIC QUESTIONS:
[Question with <ATT>, <POS>, <REL> tags embedded naturally in the sentence] <choice>(a) option1, (b) option2, (c) option3, (d) option4</choice> And provide the bounding box coordinate of the region related to your answer.

CRITICAL - EGO-CENTRIC QUESTION STARTING PHRASES:
1. If the Korean question contains "~ê´€ì ì—ì„œ" (from the perspective of ~):
   â†’ Translate to: "From the perspective of [person/object], ..."
   Example: "ì‘ì€ ì†Œë…€ì˜ ê´€ì ì—ì„œ" â†’ "From the perspective of the little girl, ..."

2. If the Korean question contains "ë‚´ê°€" or "I'm" (when I am in the image):
   â†’ Translate to: "When I'm [action/position], ..."
   Examples:
   - "ë‚´ê°€ ì†ŒíŒŒ ì˜¤ë¥¸ìª½ì— ì•‰ì•„ ìˆì„ ë•Œ" â†’ "When I'm sitting on the right side of the sofa, ..."
   - "ë‚´ê°€ ì˜ìì— ì•‰ì•„ ìˆì„ ë•Œ" â†’ "When I'm sitting on the chair, ..."
   - "ë‚´ê°€ í…Œì´ë¸” ì•ì— ì„œ ìˆì„ ë•Œ" â†’ "When I'm standing in front of the table, ..."

CRITICAL TAG USAGE RULES:

1. <REL> tag - Use ONLY for RELATIONSHIP terms (distance, order, placement):
   - Examples: "farthest", "closest", "second-closest", "highest in position"
   - DO NOT use for objects or locations

2. <POS> tag - Use ONLY for POSITION/LOCATION information from the perspective:
   - Examples: "on the left side", "on the right side", "in front of", "behind", "to the left of", "to the right of"
   - DO NOT use for object attributes or relationships
   - DO NOT use generic phrases like "in the image"
   - Remember: In ego-centric questions, "left/right" are from the person's perspective

3. <ATT> tag - Use ONLY for ATTRIBUTES or TARGET GROUPS:
   - Examples: "round object", "green object", "white object", "rectangular object", "party item", "furry creature"
   - Use for describing WHAT object/group is being asked about
   
ğŸš¨ CRITICAL - <ATT> TAG IS MANDATORY WHEN:
   - Korean question contains attribute words like: "í°ìƒ‰" (white), "ë¹¨ê°„ìƒ‰" (red), "ì›í˜•" (round), "ì •ì‚¬ê°í˜•" (square), "ì‚¬ëŒ" (person), "ê°ì²´" (object), "ë¬¼ì²´" (item), etc.
   - Korean question ends with "~ì‚¬ëŒì€?" (which person?), "~ê°ì²´ëŠ”?" (which object?), "~ë¬¼ì²´ëŠ”?" (which item?)
   - Korean question mentions specific attributes: "~ìƒ‰" (color), "~ëª¨ì–‘" (shape), "~ì¬ì§ˆ" (material)
   - ALWAYS wrap attribute descriptions in <ATT> tags, even if the question seems simple
   - WRONG: "which white object" (missing <ATT> tag)
   - CORRECT: "which <ATT>white object</ATT>"
   - WRONG: "which person" (missing <ATT> tag)
   - CORRECT: "which <ATT>person</ATT>" or "which <ATT>person in white shirt</ATT>"

4. GENERAL RULES:
   - Tags MUST contain actual meaningful content (NOT empty like <ATT></ATT>)
   - Tags should be embedded naturally within the question sentence, not at the end
   - The <choice> tag MUST come BEFORE "And provide..." phrase
   - DO NOT use generic phrases like "in the image" for <POS> tag
   - If a phrase contains both attribute and location, split them appropriately

Reference examples from ego_data_sample.json:

Example 1: "From the perspective of the little girl standing in front of the man, which <ATT>party item</ATT> is <REL>farthest</REL> and located <POS>to the right</POS> of her? <choice>(a) cake, (b) camera, (c) party plate, (d) flower</choice> And provide the bounding box coordinate of the region related to your answer."

Example 2: "When I'm sitting on the right side of the large sofa, which <ATT>square or rectangular object</ATT> on the <POS>right side of the room</POS> is <REL>farthest from me</REL>? <choice>(a) fan, (b) large bottle, (c) shoe, (d) tv</choice> And provide the bounding box coordinate of the region related to your answer."

Example 3: "From the perspective of the woman, which <ATT>silver object</ATT> <POS>to the right of</POS> her is <REL>closest to her</REL>? <choice>(a) fork, (b) knife, (c) spoon, (d) wine glass</choice> And provide the bounding box coordinate of the region related to your answer."

Korean question: {question_ko}

Korean choices:
(a) {choice_a}
(b) {choice_b}
(c) {choice_c}
(d) {choice_d}

CRITICAL - Choice Translation Format:
- Use concise, intuitive adjective+noun or noun+noun format (NOT full sentences)
- Examples:
  * "a person in a black shirt" â†’ "black shirt person"
  * "a person wearing glasses" â†’ "glasses person"
  * "a cup on the table" â†’ "table cup" or "cup"
  * "a red chair" â†’ "red chair"
  * "a man with a blue t-shirt" â†’ "blue t-shirt man"
- DO NOT use full sentences like "a person who is wearing a black shirt"
- DO NOT use articles "a" or "the" unless necessary
- Keep choices short and intuitive

Translate the Korean question and choices to English following the EXACT format above. Make sure:
- Use "From the perspective of ~" if Korean contains "~ê´€ì ì—ì„œ"
- Use "When I'm ~" if Korean contains "ë‚´ê°€" or "I'm"
- <REL> is used ONLY for relationship terms (farthest, closest, etc.)
- <POS> is used ONLY for position/location information from the person's perspective (on the left side, on the right side, etc.)
- <ATT> is used ONLY for attributes or target groups (round object, green object, white object, person, etc.)
- ğŸš¨ MANDATORY: If Korean question contains ANY attribute word (color, shape, material, "ì‚¬ëŒ", "ê°ì²´", "ë¬¼ì²´"), you MUST use <ATT> tag
- ğŸš¨ MANDATORY: If Korean question ends with "~ì‚¬ëŒì€?" or "~ê°ì²´ëŠ”?" or "~ë¬¼ì²´ëŠ”?", you MUST include <ATT> tag
- ğŸš¨ MANDATORY: NEVER translate "í°ìƒ‰ ê°ì²´" as "white object" without <ATT> tags - it MUST be "<ATT>white object</ATT>"
- All tags have meaningful content inside them
- Tags are naturally embedded in the question sentence
- <choice> tag comes before "And provide..." phrase
- DO NOT use generic phrases like "in the image" for <POS> tag
- Choices are in concise adjective+noun or noun+noun format
- DOUBLE-CHECK: Before finalizing, verify that ALL attribute descriptions are wrapped in <ATT> tags"""
        else:
            prompt = f"""Translate the following Korean question and multiple choice options to English. You MUST follow this EXACT format:{image_context}

CORRECT FORMAT:
[Question with <ATT>, <POS>, <REL> tags embedded naturally in the sentence] <choice>(a) option1, (b) option2, (c) option3, (d) option4</choice> And provide the bounding box coordinate of the region related to your answer.

CRITICAL TAG USAGE RULES:

1. <REL> tag - Use ONLY for RELATIONSHIP terms (distance, order, placement):
   - Examples: "farthest", "closest", "second-closest", "placed on the floor"
   - DO NOT use for objects or locations
   - CORRECT: "Which object is <REL>farthest</REL> from..."
   - WRONG: "<REL>flag in the center</REL>" (this should be <POS>)

2. <POS> tag - Use ONLY for POSITION/LOCATION information:
   - Examples: "in the center", "on the left side of", "in front of", "to the left side", "on the right side", "around the dining table"
   - DO NOT use for object attributes or relationships
   - CORRECT: "...flag <POS>in the center of the table</POS>"
   - WRONG: "<POS>in the image</POS>" (too generic, not meaningful)
   - WRONG: "<ATT>flag in the center of the table</ATT>" (location info should be <POS>)

3. <ATT> tag - Use ONLY for ATTRIBUTES or TARGET GROUPS:
   - Examples: "red object", "square-shaped item", "among the items", "among the visible people", "edible food item", "object that can hold water", "non-edible item", "white object", "round object", "person"
   - Use for describing WHAT object/group is being asked about
   - CORRECT: "Which <ATT>red object</ATT> is..."
   - CORRECT: "<ATT>Among the items</ATT> on the table..."
   - WRONG: "<ATT>flag in the center of the table</ATT>" (contains location, should split: flag <POS>in the center of the table</POS>)
   
ğŸš¨ CRITICAL - <ATT> TAG IS MANDATORY WHEN:
   - Korean question contains attribute words like: "í°ìƒ‰" (white), "ë¹¨ê°„ìƒ‰" (red), "ì›í˜•" (round), "ì •ì‚¬ê°í˜•" (square), "ì‚¬ëŒ" (person), "ê°ì²´" (object), "ë¬¼ì²´" (item), etc.
   - Korean question ends with "~ì‚¬ëŒì€?" (which person?), "~ê°ì²´ëŠ”?" (which object?), "~ë¬¼ì²´ëŠ”?" (which item?)
   - Korean question mentions specific attributes: "~ìƒ‰" (color), "~ëª¨ì–‘" (shape), "~ì¬ì§ˆ" (material)
   - ALWAYS wrap attribute descriptions in <ATT> tags, even if the question seems simple
   - WRONG: "which white object" (missing <ATT> tag)
   - CORRECT: "which <ATT>white object</ATT>"
   - WRONG: "which person" (missing <ATT> tag)
   - CORRECT: "which <ATT>person</ATT>" or "which <ATT>person in white shirt</ATT>"

4. GENERAL RULES:
   - Tags MUST contain actual meaningful content (NOT empty like <ATT></ATT>)
   - Tags should be embedded naturally within the question sentence, not at the end
   - The <choice> tag MUST come BEFORE "And provide..." phrase
   - DO NOT use generic phrases like "in the image" for <POS> tag
   - If a phrase contains both attribute and location, split them appropriately

Reference examples from exo_data_sample.json:

Example 1: "<REL>Second-closest</REL> to the refrigerator a countertop located <POS>in the center</POS> of the image, which object is it <ATT>among the items</ATT>? <choice>(a) sink, (b) vase, (c) orange bag, (d) rightmost red chair</choice> And provide the bounding box coordinate of the region related to your answer."

Example 2: "Which <ATT>square-shaped item</ATT> is <REL>placed on the floor</REL> <POS>in front of</POS> the brown-haired man sitting on the sofa? <choice>(a) handbag, (b) coke, (c) laptop, (d) cell phone</choice> And provide the bounding box coordinate of the region related to your answer."

Example 3: "Which <ATT>round and cylindrical object</ATT> is <REL>farthest</REL> from the person sitting <POS>on the right side of</POS> the dining table? <choice>(a) plate, (b) white cake, (c) rightmost coke, (d) vase</choice> And provide the bounding box coordinate of the region related to your answer."

Example 4: "Which <ATT>edible food item</ATT> is the <REL>farthest</REL> from the fork <POS>on the left side of</POS> the table? <choice>(a) glass, (b) potato fries, (c) hamburger, (d) cell phone</choice> And provide the bounding box coordinate of the region related to your answer."

Korean question: {question_ko}

Korean choices:
(a) {choice_a}
(b) {choice_b}
(c) {choice_c}
(d) {choice_d}

CRITICAL - Choice Translation Format:
- Use concise, intuitive adjective+noun or noun+noun format (NOT full sentences)
- Examples:
  * "a person in a black shirt" â†’ "black shirt person"
  * "a person wearing glasses" â†’ "glasses person"
  * "a cup on the table" â†’ "table cup" or "cup"
  * "a red chair" â†’ "red chair"
  * "a man with a blue t-shirt" â†’ "blue t-shirt man"
- DO NOT use full sentences like "a person who is wearing a black shirt"
- DO NOT use articles "a" or "the" unless necessary
- Keep choices short and intuitive

Translate the Korean question and choices to English following the EXACT format above. Make sure:
- <REL> is used ONLY for relationship terms (farthest, closest, etc.)
- <POS> is used ONLY for position/location information (in the center, on the left side, etc.)
- <ATT> is used ONLY for attributes or target groups (red object, white object, among the items, person, etc.)
- ğŸš¨ MANDATORY: If Korean question contains ANY attribute word (color, shape, material, "ì‚¬ëŒ", "ê°ì²´", "ë¬¼ì²´"), you MUST use <ATT> tag
- ğŸš¨ MANDATORY: If Korean question ends with "~ì‚¬ëŒì€?" or "~ê°ì²´ëŠ”?" or "~ë¬¼ì²´ëŠ”?", you MUST include <ATT> tag
- ğŸš¨ MANDATORY: NEVER translate "í°ìƒ‰ ê°ì²´" as "white object" without <ATT> tags - it MUST be "<ATT>white object</ATT>"
- All tags have meaningful content inside them
- Tags are naturally embedded in the question sentence
- <choice> tag comes before "And provide..." phrase
- DO NOT use generic phrases like "in the image" for <POS> tag
- Choices are in concise adjective+noun or noun+noun format
- DOUBLE-CHECK: Before finalizing, verify that ALL attribute descriptions are wrapped in <ATT> tags"""
        
        # view_typeì— ë”°ë¼ ë‹¤ë¥¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì‚¬ìš©
        if view_type == 'ego':
            system_message = "You are a professional translator specializing in VQA (Visual Question Answering) EGO-CENTRIC questions. CRITICAL RULES: 1) Use 'From the perspective of ~' for '~ê´€ì ì—ì„œ', 2) Use 'When I'm ~' for 'ë‚´ê°€', 3) <REL> tag ONLY for relationship terms (farthest, closest, etc.), 4) <POS> tag ONLY for position/location from person's perspective (on the left side, on the right side, etc.), 5) <ATT> tag ONLY for attributes/target groups (round object, green object, etc.), 6) Tags MUST contain actual meaningful content, 7) Format: [Question with tags] <choice>...</choice> And provide... (choice tag BEFORE 'And provide' phrase), 8) DO NOT use generic phrases like 'in the image' for <POS> tag, 9) Choices MUST be in concise adjective+noun or noun+noun format (e.g., 'black shirt person', 'glasses person'), NOT full sentences."
        else:
            system_message = "You are a professional translator specializing in VQA (Visual Question Answering) questions. CRITICAL RULES: 1) <REL> tag ONLY for relationship terms (farthest, closest, etc.), 2) <POS> tag ONLY for position/location (in the center, on the left side, etc.), 3) <ATT> tag ONLY for attributes/target groups (red object, among the items, etc.), 4) Tags MUST contain actual meaningful content, 5) Format: [Question with tags] <choice>...</choice> And provide... (choice tag BEFORE 'And provide' phrase), 6) DO NOT use generic phrases like 'in the image' for <POS> tag, 7) Choices MUST be in concise adjective+noun or noun+noun format (e.g., 'black shirt person', 'glasses person'), NOT full sentences."
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        translated_question = response.choices[0].message.content.strip()
        
        # íƒœê·¸ ê²€ì¦ - ë¹ˆ íƒœê·¸ í™•ì¸ (ë‚´ìš©ì´ ìˆëŠ” íƒœê·¸ë§Œ ìœ íš¨)
        has_valid_att = bool(re.search(r'<ATT>[^<]+</ATT>', translated_question, re.IGNORECASE))
        has_valid_pos = bool(re.search(r'<POS>[^<]+</POS>', translated_question, re.IGNORECASE))
        has_valid_rel = bool(re.search(r'<REL>[^<]+</REL>', translated_question, re.IGNORECASE))
        
        if not (has_valid_att or has_valid_pos or has_valid_rel):
            return jsonify({'success': False, 'error': 'Translation must include at least one of <ATT>, <POS>, or <REL> tags with actual content inside them'}), 400
        
        # ATT íƒœê·¸ ëˆ„ë½ ê²€ì¦ ê°•í™”: í•œêµ­ì–´ ì§ˆë¬¸ì— ì†ì„± ë‹¨ì–´ê°€ ìˆëŠ”ë° ATT íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°
        attribute_keywords_ko = ['í°ìƒ‰', 'ë¹¨ê°„ìƒ‰', 'íŒŒë€ìƒ‰', 'ì´ˆë¡ìƒ‰', 'ê²€ì€ìƒ‰', 'ë…¸ë€ìƒ‰', 'ì›í˜•', 'ì •ì‚¬ê°í˜•', 'ì§ì‚¬ê°í˜•', 'ì‚¬ëŒ', 'ê°ì²´', 'ë¬¼ì²´', 'ìƒ‰', 'ëª¨ì–‘', 'ì¬ì§ˆ']
        question_has_attribute = any(keyword in question_ko for keyword in attribute_keywords_ko)
        if question_has_attribute and not has_valid_att:
            return jsonify({
                'success': False, 
                'error': f'ATT tag is missing! Korean question contains attribute words but translation lacks <ATT> tag. Please ensure all attribute descriptions are wrapped in <ATT> tags. Translation: {translated_question[:200]}...'
            }), 400
        
        if '<choice>' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must include <choice> tag'}), 400
        
        # "And provide..." ë¬¸êµ¬ê°€ <choice> íƒœê·¸ ë’¤ì— ìˆëŠ”ì§€ í™•ì¸
        choice_match = re.search(r'<choice>.*?</choice>', translated_question, re.IGNORECASE | re.DOTALL)
        if choice_match:
            choice_end_pos = choice_match.end()
            if 'And provide the bounding box coordinate of the region related to your answer.' not in translated_question[choice_end_pos:]:
                return jsonify({'success': False, 'error': 'The phrase "And provide the bounding box coordinate..." must come AFTER the <choice> tag'}), 400
        else:
            if 'And provide the bounding box coordinate of the region related to your answer.' not in translated_question:
                return jsonify({'success': False, 'error': 'Translation must include the required ending phrase'}), 400
        
        # <choice> íƒœê·¸ì—ì„œ ê° ì„ íƒì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        choice_match = re.search(r'<choice>(.*?)</choice>', translated_question, re.IGNORECASE)
        choice_texts = {}
        if choice_match:
            choice_content = choice_match.group(1)
            for letter in ['a', 'b', 'c', 'd']:
                pattern = rf'\({letter}\)\s*([^,)]+)'
                match = re.search(pattern, choice_content, re.IGNORECASE)
                if match:
                    choice_texts[letter] = match.group(1).strip()
        
        # ë²ˆì—­ ê²°ê³¼ì—ì„œ ì•ë’¤ ëŒ€ê´„í˜¸ ì œê±°
        cleaned_question = translated_question.strip()
        # ì•ì˜ ëŒ€ê´„í˜¸ ì œê±° (ì˜ˆ: "[Question text..." -> "Question text...")
        if cleaned_question.startswith('[') and cleaned_question.endswith(']'):
            # ì „ì²´ê°€ ëŒ€ê´„í˜¸ë¡œ ê°ì‹¸ì ¸ ìˆëŠ” ê²½ìš°ë§Œ ì œê±°
            cleaned_question = cleaned_question[1:-1].strip()
        elif cleaned_question.startswith('['):
            # ì•ì—ë§Œ ëŒ€ê´„í˜¸ê°€ ìˆëŠ” ê²½ìš° ì œê±°
            cleaned_question = re.sub(r'^\[+\s*', '', cleaned_question).strip()
        
        # "?" ë’¤ì˜ "]" ì œê±°
        cleaned_question = re.sub(r'\?\s*\]+\s*', '? ', cleaned_question)
        # ë¬¸ì¥ ëì˜ "]" ì œê±° (choice íƒœê·¸ ì•)
        cleaned_question = re.sub(r'\]+\s*(?=<choice>)', ' ', cleaned_question, flags=re.IGNORECASE)
        
        return jsonify({
            'success': True,
            'translated_question': cleaned_question,
            'choice_texts': choice_texts
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/translate/rationale', methods=['POST'])
def translate_rationale():
    """Translate Korean rationale to English with image analysis context."""
    data = request.json
    rationale_ko = data.get('rationale_ko', '').strip()
    image_id = data.get('image_id', None)
    view_type = data.get('view_type', 'exo')  # 'exo' or 'ego'
    
    if not rationale_ko:
        return jsonify({'success': False, 'error': 'Rationale (Korean) is required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ìºì‹œì—ì„œ)
        # ìºì‹œ í‚¤ëŠ” "image_id_model" í˜•ì‹ì´ë¯€ë¡œ ëª¨ë“  ëª¨ë¸ì˜ ìºì‹œë¥¼ í™•ì¸
        image_analysis = ""
        if image_id:
            # ê¸°ë³¸ ëª¨ë¸ë¶€í„° í™•ì¸
            for model_name in [DEFAULT_MODEL, 'openai']:
                cache_key = f"{image_id}_{model_name}"
                if cache_key in image_analysis_cache:
                    image_analysis = image_analysis_cache[cache_key]
                    break
        
        # Questionê³¼ Response ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì†Œê±°ë²• í˜•ì‹ì„ ìœ„í•´)
        question = data.get('question', '').strip()
        response = data.get('response', '').strip()  # ì˜ˆ: "(b) vase"
        
        # view íƒ€ì…ì— ë”°ë¼ ì‹œì‘ ë¬¸êµ¬ ê²°ì •
        question_type = "exo-centric" if view_type == 'exo' else "ego-centric"
        
        # ì´ë¯¸ì§€ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
        image_context = ""
        if image_analysis:
            image_context = f"""

IMAGE ANALYSIS CONTEXT:
{image_analysis}

Use this image analysis to better understand the visual context and spatial relationships when translating the rationale."""
        
        # ì†Œê±°ë²• í˜•ì‹ ê°€ì´ë“œ
        elimination_guide = ""
        if question and response:
            # Responseì—ì„œ ì •ë‹µ ì¶”ì¶œ (ì˜ˆ: "(b) vase" -> "b")
            response_match = re.search(r'\(([a-d])\)', response, re.IGNORECASE)
            if response_match:
                correct_answer = response_match.group(1).lower()
                # Choice íƒœê·¸ì—ì„œ ëª¨ë“  ì„ íƒì§€ ì¶”ì¶œ
                choice_match = re.search(r'<choice>(.*?)</choice>', question, re.IGNORECASE)
                if choice_match:
                    choice_content = choice_match.group(1)
                    choices = {}
                    for letter in ['a', 'b', 'c', 'd']:
                        pattern = rf'\({letter}\)\s*([^,)]+)'
                        match = re.search(pattern, choice_content, re.IGNORECASE)
                        if match:
                            choices[letter] = match.group(1).strip()
                    
                    elimination_guide = f"""

ELIMINATION METHOD FORMAT:
The rationale must follow an elimination method format:
1. Start with "The question is {question_type}:"
2. Explain why each incorrect choice (a, b, c, d) is excluded, EXCEPT for the correct answer ({correct_answer})
3. For each incorrect choice, state why it doesn't match the question criteria
4. Finally, explain why the correct answer ({correct_answer}: {choices.get(correct_answer, '')}) is the right choice
5. End with "Therefore [correct answer] is [the answer/description]." - DO NOT add any additional explanation after "Therefore" sentence
6. CRITICAL: After "Therefore" statement, do NOT add phrases like "as it is...", "because it is...", "since it is...", or any additional descriptive clauses

Example format:
"The question is {question_type}: [Choice a] is excluded because [reason]. [Choice b] is excluded because [reason]. [Choice c] is excluded because [reason]. Therefore [correct answer] is [the answer/description]."

WRONG examples (DO NOT include):
- "Therefore the sandwich is correct, as it is the closest edible object to the wine glass on the table in the restaurant."
- "Therefore the vase is correct because it is the farthest object from the boy."

CORRECT examples:
- "Therefore the sandwich is correct."
- "Therefore the vase is the farthest object from the boy, making the vase correct."

Current question: {question}
Correct answer: {response}
"""
        
        # view_typeì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if view_type == 'ego':
            # ego_data_sample.json í˜•ì‹ ì°¸ê³ 
            prompt = f"""Translate the following Korean rationale to English. Follow these CRITICAL requirements for EGO-CENTRIC rationales:{image_context}{elimination_guide}

REQUIREMENTS FOR EGO-CENTRIC RATIONALES:
1. The rationale MUST start with "The question is ego-centric:"
2. Use elimination method format: explain why incorrect choices are excluded, then explain why the correct answer is right
3. The translation must be at least 2 sentences long
4. Make it natural, grammatically correct, and detailed
5. Use the image analysis context to create accurate descriptions of spatial relationships and object positions FROM THE PERSON'S PERSPECTIVE
6. DO NOT include any bounding box coordinates (x1, y1, x2, y2) or coordinate information in the rationale
7. When the Korean rationale mentions choice letters (a, b, c, d), translate them to the corresponding English choice text from the question
8. CRITICAL: End the rationale with a simple "Therefore" statement. DO NOT add additional explanatory clauses after "Therefore" such as "as it is...", "because it is...", "since it is...", or any descriptive phrases that repeat information already stated
9. IMPORTANT: When describing spatial relationships, always clarify the perspective (e.g., "From the person's perspective, the right side corresponds to the left side of the image")

Reference examples from ego_data_sample.json:

Example 1: "The question is ego-centric: The little girl in front of the man has her right side corresponding to the left side of the image. The cake and the camera are positioned in front of her, and the party plate is on her left side. Therefore, the flower is the farthest among the party items."

Example 2: "The question is ego-centric: From the person's perspective, sitting on the right side of the large sofa corresponds to sitting on the left side of the large sofa in the image, and the person's right side aligns with the left side of the image. The large bottle and shoe are located on the person's left side, while the fan is on the right but is not a square-shaped object. Therefore, the TV is the correct answer."

Example 3: "The question is ego-centric: From the woman's perspective, her right side corresponds to the left side of the image. The fork and knife are located on her left side, so they can be excluded. The wine glass, while positioned on the correct side, is made of glass and not a silver object. Therefore, the correct answer is the spoon."

Korean rationale: {rationale_ko}

Translate to English following the format and style of ego_data_sample.json examples."""
        else:
            # exo_data_sample.json í˜•ì‹ ì°¸ê³ 
            prompt = f"""Translate the following Korean rationale to English. Follow these CRITICAL requirements:{image_context}{elimination_guide}

REQUIREMENTS:
1. The rationale MUST start with "The question is exo-centric:"
2. Use elimination method format: explain why incorrect choices are excluded, then explain why the correct answer is right
3. The translation must be at least 2 sentences long
4. Make it natural, grammatically correct, and detailed
5. Use the image analysis context to create accurate descriptions of spatial relationships and object positions
6. DO NOT include any bounding box coordinates (x1, y1, x2, y2) or coordinate information in the rationale
7. When the Korean rationale mentions choice letters (a, b, c, d), translate them to the corresponding English choice text from the question
8. CRITICAL: End the rationale with a simple "Therefore" statement. DO NOT add additional explanatory clauses after "Therefore" such as "as it is...", "because it is...", "since it is...", or any descriptive phrases that repeat information already stated

Reference examples from exo_data_sample.json:

Example 1: "The question is exo-centric: The sink is placed immediately adjacent to the refrigerator, making it the closest. The vase sits slightly forward on the counter, farther than the sink but clearly closer than the orange bag at the far right edge and the red chair in the front seating area. Therefore the vase is second-closest."

Example 2: "The question is exo-centric: The laptop and the cell phone are located on the sofa near the brown-haired man, while the handbag is placed on the floor near his feet. The coke bottle is also on the floor, but it is cylindrical, not square-shaped. Therefore the handbag is the only square-shaped object on the floor."

Korean rationale: {rationale_ko}

Translate to English following the format and style of exo_data_sample.json examples."""
        
        # Choice ì •ë³´ë¥¼ rationale ë²ˆì—­ì— í™œìš©í•˜ê¸° ìœ„í•œ ë§¤í•‘ ìƒì„±
        choice_mapping = ""
        if question and response:
            choice_match = re.search(r'<choice>(.*?)</choice>', question, re.IGNORECASE)
            if choice_match:
                choice_content = choice_match.group(1)
                choices = {}
                for letter in ['a', 'b', 'c', 'd']:
                    pattern = rf'\({letter}\)\s*([^,)]+)'
                    match = re.search(pattern, choice_content, re.IGNORECASE)
                    if match:
                        choices[letter] = match.group(1).strip()
                
                if choices:
                    choice_mapping = f"""

CHOICE MAPPING (for translating choice letters in Korean rationale):
When the Korean rationale mentions choice letters (a, b, c, d) or Korean choice text, translate them to the corresponding English choice:
{', '.join([f'({k}) {v}' for k, v in choices.items()])}

For example, if the Korean rationale says "(d) í¬í¬" or just "d" or "í¬í¬", translate it to "fork" (which is choice (d) fork).
"""
        
        # í”„ë¡¬í”„íŠ¸ì— choice ë§¤í•‘ ì¶”ê°€
        enhanced_prompt = prompt + choice_mapping
        
        translated_rationale = ""
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"You are a professional translator specializing in VQA (Visual Question Answering) rationales. Always start with 'The question is {question_type}:' and use elimination method format with at least 2 sentences. Never include bounding box coordinates. When Korean rationale mentions choice letters (a, b, c, d) or Korean choice text, translate them to the corresponding English choice text. CRITICAL: End with a simple 'Therefore' statement - do NOT add additional explanatory clauses like 'as it is...', 'because it is...', or 'since it is...' after the 'Therefore' sentence."},
                    {"role": "user", "content": enhanced_prompt}
                ],
                temperature=0.3,
                max_tokens=400
            )
            
            translated_rationale = response.choices[0].message.content.strip()
        except Exception as api_error:
            print(f"[ERROR] API error in rationale translation: {type(api_error).__name__}: {str(api_error)}")
            import traceback
            traceback.print_exc()
            return jsonify({'success': False, 'error': f'Translation API error: {str(api_error)}'}), 500
        
        if not translated_rationale:
            return jsonify({'success': False, 'error': 'Translation returned empty result'}), 500
        
        # ì‹œì‘ ë¬¸êµ¬ ê²€ì¦
        if not translated_rationale.startswith(f"The question is {question_type}:"):
            # ìë™ìœ¼ë¡œ ì‹œì‘ ë¬¸êµ¬ ì¶”ê°€
            translated_rationale = f"The question is {question_type}: {translated_rationale}"
        
        # bounding box ì¢Œí‘œ ì œê±° (x1, y1, x2, y2 ë˜ëŠ” [x, y, w, h] í˜•ì‹)
        translated_rationale = re.sub(r'\[?\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*\]?', '', translated_rationale)
        translated_rationale = re.sub(r'bounding box[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
        translated_rationale = re.sub(r'bbox[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
        translated_rationale = re.sub(r'coordinate[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
        translated_rationale = re.sub(r'\(x\d+.*?y\d+.*?\)', '', translated_rationale, flags=re.IGNORECASE)
        
        # "Therefore" ë¬¸ì¥ ë’¤ì˜ ì¶”ê°€ ì„¤ëª… ì œê±° (as it is, because it is, since it is ë“±)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ", as it is", ", because it is", ", since it is" ê°™ì€ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì œê±°
        translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s*(as|because|since)\s+it\s+is[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ì¶”ê°€ ë¬¸ì¥ì´ ìˆê³ , ê·¸ê²ƒì´ "as it is", "because it is", "since it is"ë¡œ ì‹œì‘í•˜ë©´ ì œê±°
        translated_rationale = re.sub(r'(Therefore[^.]*\.)\s+((As|Because|Since)\s+it\s+is[^.]*?\.)', r'\1', translated_rationale, flags=re.IGNORECASE)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ", as" ë˜ëŠ” ", because" ë˜ëŠ” ", since"ë¡œ ì‹œì‘í•˜ëŠ” ì¶”ê°€ ì„¤ëª…ì´ ìˆìœ¼ë©´ ì œê±°
        translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s+(as|because|since)\s+[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
        # "Therefore" ë¬¸ì¥ì„ ì°¾ì•„ì„œ ê·¸ ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œê¹Œì§€ë§Œ ë‚¨ê¸°ê³ , ê·¸ ë’¤ì˜ ëª¨ë“  ì¶”ê°€ ì„¤ëª… ì œê±° (ë” ì•ˆì „í•œ ë°©ë²•)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ë‚˜ì˜¤ëŠ” ", as it is..." ê°™ì€ ëª¨ë“  ì¶”ê°€ ì„¤ëª… ì œê±°
        therefore_match = re.search(r'(Therefore[^.]*?\.)', translated_rationale, re.IGNORECASE)
        if therefore_match:
            therefore_end = therefore_match.end()
            # "Therefore" ë¬¸ì¥ ë’¤ì— ", as", ", because", ", since" ê°™ì€ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì œê±°
            remaining = translated_rationale[therefore_end:].strip()
            if remaining:
                # ", as it is", ", because it is", ", since it is" ê°™ì€ íŒ¨í„´ ì œê±°
                remaining = re.sub(r'^,\s*(as|because|since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                # "As it is", "Because it is", "Since it is" ê°™ì€ íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ ì œê±°
                remaining = re.sub(r'^(As|Because|Since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                # ", as", ", because", ", since" ê°™ì€ íŒ¨í„´ ì œê±°
                remaining = re.sub(r'^,\s+(as|because|since)\s+[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                translated_rationale = translated_rationale[:therefore_end] + (' ' + remaining if remaining else '')
        
        translated_rationale = re.sub(r'\s+', ' ', translated_rationale).strip()
        
        # ë¬¸ì¥ ìˆ˜ í™•ì¸ (ìµœì†Œ 2ë¬¸ì¥)
        sentences = [s.strip() for s in translated_rationale.split('.') if s.strip()]
        sentence_count = len(sentences)
        
        if sentence_count < 2:
            # 2ë¬¸ì¥ ì´ìƒìœ¼ë¡œ í™•ì¥
            additional_prompt = f"""The following rationale is too short. Expand it to at least 2 sentences while maintaining the elimination method format. Do NOT include any bounding box coordinates or coordinate information:

Current rationale: {translated_rationale}

Expand it to at least 2 sentences, keeping the same format and style."""
            
            additional_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a professional translator. Expand the rationale to at least 2 sentences while maintaining the elimination method format. Never include bounding box coordinates."},
                    {"role": "user", "content": additional_prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            translated_rationale = additional_response.choices[0].message.content.strip()
            # ë‹¤ì‹œ bounding box ì¢Œí‘œ ì œê±°
            translated_rationale = re.sub(r'\[?\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*\]?', '', translated_rationale)
            translated_rationale = re.sub(r'bounding box[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'bbox[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'coordinate[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'\(x\d+.*?y\d+.*?\)', '', translated_rationale, flags=re.IGNORECASE)
            # "Therefore" ë¬¸ì¥ ë’¤ì˜ ì¶”ê°€ ì„¤ëª… ì œê±°
            translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s*(as|because|since)\s+it\s+is[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'(Therefore[^.]*\.)\s+((As|Because|Since)\s+it\s+is[^.]*?\.)', r'\1', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s+(as|because|since)\s+[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
            # "Therefore" ë¬¸ì¥ì„ ì°¾ì•„ì„œ ê·¸ ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œê¹Œì§€ë§Œ ë‚¨ê¸°ê³ , ê·¸ ë’¤ì˜ ëª¨ë“  ì¶”ê°€ ì„¤ëª… ì œê±°
            therefore_match = re.search(r'(Therefore[^.]*?\.)', translated_rationale, re.IGNORECASE)
            if therefore_match:
                therefore_end = therefore_match.end()
                remaining = translated_rationale[therefore_end:].strip()
                if remaining:
                    remaining = re.sub(r'^,\s*(as|because|since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                    remaining = re.sub(r'^(As|Because|Since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                    remaining = re.sub(r'^,\s+(as|because|since)\s+[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                    translated_rationale = translated_rationale[:therefore_end] + (' ' + remaining if remaining else '')
            translated_rationale = re.sub(r'\s+', ' ', translated_rationale).strip()
        
        return jsonify({
            'success': True,
            'translated_rationale': translated_rationale
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/review_translation', methods=['POST'])
def review_translation():
    """Review translated question, response, and rationale using GPT-5 for grammar and unnecessary phrases."""
    data = request.json
    question = data.get('question', '').strip()
    response = data.get('response', '').strip()
    rationale = data.get('rationale', '').strip()
    
    if not question and not rationale:
        return jsonify({'success': False, 'error': 'Question or Rationale is required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ê²€ìˆ˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        review_prompt = f"""Review the following English translations for a VQA (Visual Question Answering) task. Check for:
1. Grammar errors and awkward phrasing
2. Unnecessary phrases or redundant words
3. Naturalness and clarity
4. Consistency with VQA format requirements

Question:
{question if question else '(empty)'}

Response:
{response if response else '(empty)'}

Rationale:
{rationale if rationale else '(empty)'}

CRITICAL INSTRUCTIONS:
- If the texts are grammatically correct, natural, and have no unnecessary phrases, respond with ONLY: "OK"
- If there are ANY issues that need revision, you MUST provide the response in EXACTLY this format (do not deviate):

=== Issues Found ===
[Here, explain in detail:
1. Which specific sentences are unnatural or have grammar errors
2. What the errors are (e.g., "The phrase 'X' is awkward because...")
3. What unnecessary phrases exist (e.g., "The word 'Y' is redundant")
4. How to fix each issue (e.g., "Change 'X' to 'Y' for better clarity")
Be very specific and detailed. Point out exact sentences and words that need fixing.]

=== Question (ìˆ˜ì •) ===
[If Question needs revision, provide the corrected version here. If Question is fine, write "(No changes needed)"]

=== Rationale (ìˆ˜ì •) ===
[If Rationale needs revision, provide the corrected version here. If Rationale is fine, write "(No changes needed)"]

IMPORTANT:
- You MUST always include the "=== Issues Found ===" section when there are any issues
- Be specific: mention exact sentence numbers, phrases, or words that are problematic
- Explain WHY each issue is a problem and HOW to fix it
- If everything is perfect, respond with ONLY "OK" (nothing else)"""
        
        review_result = None
        review_response = None
        
        try:
            # GPT-4o-mini ì‚¬ìš©
            review_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a professional English grammar and style reviewer for VQA (Visual Question Answering) tasks. Review texts for grammar, naturalness, and unnecessary phrases."},
                    {"role": "user", "content": review_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
        except Exception as api_error:
            print(f"[ERROR] GPT-4o-mini API error: {type(api_error).__name__}: {str(api_error)}")
            import traceback
            traceback.print_exc()
            return jsonify({
                'success': False,
                'error': f'Review API error: {str(api_error)}'
            }), 500
        
        # ì‘ë‹µ ê²€ì¦
        if not review_response:
            print(f"[ERROR] review_response is None")
            return jsonify({
                'success': False,
                'error': 'Failed to get response from GPT API'
            }), 500
        
        if not review_response.choices or len(review_response.choices) == 0:
            print(f"[ERROR] review_response.choices is empty")
            return jsonify({
                'success': False,
                'error': 'GPT API returned empty choices'
            }), 500
        
        if not review_response.choices[0].message or not review_response.choices[0].message.content:
            print(f"[ERROR] review_response.choices[0].message.content is empty")
            return jsonify({
                'success': False,
                'error': 'GPT API returned empty content'
            }), 500
        
        review_result = review_response.choices[0].message.content.strip()
        
        if not review_result or len(review_result) == 0:
            print(f"[ERROR] review_result is empty after strip")
            return jsonify({
                'success': False,
                'error': 'GPT API returned empty result'
            }), 500
        
        # "OK"ì¸ì§€ í™•ì¸
        review_upper = review_result.upper().strip()
        
        # OK ì²´í¬: ë‹¤ì–‘í•œ í˜•ì‹ì˜ OK ì¸ì‹
        # 1. ì •í™•íˆ "OK"
        # 2. "OK"ë¡œ ì‹œì‘í•˜ê³  ì§§ì€ ê²½ìš° (ì˜ˆ: "OK.", "OK\n", "OK ", "OKAY")
        # 3. "OK"ë§Œ í¬í•¨í•˜ê³  ë‹¤ë¥¸ ë‚´ìš©ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš°
        is_ok = False
        
        if review_upper == "OK":
            is_ok = True
        elif review_upper.startswith("OK") and len(review_upper) <= 20:
            # "OK"ë¡œ ì‹œì‘í•˜ê³  ì§§ì€ ê²½ìš°
            # "OK.", "OK\n", "OK ", "OKAY", "OK -", "OK:" ë“± í—ˆìš©
            remaining = review_upper[2:].strip()
            if not remaining or remaining in [".", ":", "-", " ", "\n", "\r", "\r\n"] or remaining.startswith(".") or remaining.startswith(":") or remaining.startswith("-"):
                is_ok = True
        elif "OK" in review_upper and len(review_upper) <= 30:
            # "OK"ê°€ í¬í•¨ë˜ì–´ ìˆê³  ì „ì²´ê°€ ì§§ì€ ê²½ìš° (ì˜ˆ: "The text is OK")
            # í•˜ì§€ë§Œ ë„ˆë¬´ ê¸´ ì„¤ëª…ì´ ìˆìœ¼ë©´ OKê°€ ì•„ë‹˜
            ok_index = review_upper.find("OK")
            before_ok = review_upper[:ok_index].strip()
            after_ok = review_upper[ok_index+2:].strip()
            # OK ì•ë’¤ë¡œ ì¤‘ìš”í•œ ë‚´ìš©ì´ ê±°ì˜ ì—†ìœ¼ë©´ OKë¡œ ê°„ì£¼
            if len(before_ok) <= 15 and len(after_ok) <= 10:
                is_ok = True
        
        if is_ok:
            return jsonify({
                'success': True,
                'needs_revision': False,
                'message': 'ê²€ìˆ˜ í†µê³¼',
                'review_notes': review_result
            })
        else:
            # ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš°
            revised_question = None
            revised_rationale = None
            issues_found = None
            
            # review_notesëŠ” í•­ìƒ ì±„ì›Œì•¼ í•¨ (ì´ë¯¸ ìœ„ì—ì„œ ê²€ì¦í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì²´í¬ë§Œ)
            if not review_result or len(review_result.strip()) == 0:
                print(f"[ERROR] review_result is empty in else block (should not happen)")
                return jsonify({
                    'success': False,
                    'error': 'Review result is empty'
                }), 500
            
            # === Issues Found === ë¶€ë¶„ ì¶”ì¶œ (ë” ìœ ì—°í•œ íŒ¨í„´)
            # íŒ¨í„´ 1: ì •í™•í•œ í˜•ì‹
            issues_match = re.search(r'=== Issues Found ===\s*([\s\S]*?)(?=\n\n=== Question|=== Rationale|=== Response|$)', review_result, re.IGNORECASE)
            if issues_match:
                issues_found = issues_match.group(1).strip()
            else:
                # íŒ¨í„´ 2: "Issues Found" ë˜ëŠ” "Issues:" ê°™ì€ ë³€í˜•
                issues_match2 = re.search(r'(?:Issues Found|Issues:|Problems:|Issues to fix):?\s*([\s\S]*?)(?=\n\n=== Question|=== Rationale|=== Response|$)', review_result, re.IGNORECASE)
                if issues_match2:
                    issues_found = issues_match2.group(1).strip()
                else:
                    # íŒ¨í„´ 3: Issues Foundê°€ ì—†ìœ¼ë©´ ì‘ë‹µì˜ ì²˜ìŒ ë¶€ë¶„ì„ Issuesë¡œ ì‚¬ìš© (Question/Rationale ì„¹ì…˜ ì „ê¹Œì§€)
                    before_question = re.search(r'^([\s\S]*?)(?=\n\n=== Question|=== Rationale|=== Response)', review_result, re.IGNORECASE)
                    if before_question and not review_result.startswith("==="):
                        # OKê°€ ì•„ë‹ˆê³  ì„¹ì…˜ í—¤ë”ê°€ ì—†ëŠ” ê²½ìš°, ì „ì²´ë¥¼ Issuesë¡œ ê°„ì£¼
                        issues_found = before_question.group(1).strip()
            
            # Issues Foundê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì˜ ì¼ë¶€ë¥¼ ì‚¬ìš©
            if not issues_found or len(issues_found) < 10:
                # Question/Rationale ì„¹ì…˜ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ Issuesë¡œ ì‚¬ìš©
                temp_result = review_result
                temp_result = re.sub(r'=== Question.*?===.*?(?=\n\n=== Rationale|$)', '', temp_result, flags=re.IGNORECASE | re.DOTALL)
                temp_result = re.sub(r'=== Rationale.*?===.*?$', '', temp_result, flags=re.IGNORECASE | re.DOTALL)
                temp_result = temp_result.strip()
                if temp_result and len(temp_result) > 10:
                    issues_found = temp_result
            
            # === Question (ìˆ˜ì •) === ë¶€ë¶„ ì¶”ì¶œ
            question_match = re.search(r'=== Question \(ìˆ˜ì •\) ===\s*([\s\S]*?)(?=\n\n=== Rationale|=== Response|$)', review_result, re.IGNORECASE)
            if question_match:
                revised_question = question_match.group(1).strip()
                # "(No changes needed)" ì²´í¬
                if revised_question.upper().strip() == "(NO CHANGES NEEDED)":
                    revised_question = None
            
            # === Rationale (ìˆ˜ì •) === ë¶€ë¶„ ì¶”ì¶œ
            rationale_match = re.search(r'=== Rationale \(ìˆ˜ì •\) ===\s*([\s\S]*?)$', review_result, re.IGNORECASE)
            if rationale_match:
                revised_rationale = rationale_match.group(1).strip()
                # "(No changes needed)" ì²´í¬
                if revised_rationale.upper().strip() == "(NO CHANGES NEEDED)":
                    revised_rationale = None
            
            # ìµœì¢… ê²€ì¦: Issues Foundê°€ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì„ Issuesë¡œ ì‚¬ìš©
            if not issues_found or len(issues_found) < 10:
                # Questionê³¼ Rationaleì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€
                full_text = review_result
                if revised_question:
                    full_text = re.sub(r'=== Question.*?===\s*' + re.escape(revised_question), '', full_text, flags=re.IGNORECASE | re.DOTALL)
                if revised_rationale:
                    full_text = re.sub(r'=== Rationale.*?===\s*' + re.escape(revised_rationale), '', full_text, flags=re.IGNORECASE | re.DOTALL)
                full_text = re.sub(r'=== .*? ===', '', full_text).strip()
                if full_text and len(full_text) > 10:
                    issues_found = full_text
            
            # ìµœì¢… ê²€ì¦: Issues Foundê°€ ì—¬ì „íˆ ì—†ê³ , Question/Rationaleë„ ì—†ìœ¼ë©´
            # ì „ì²´ ì‘ë‹µì„ Issues Foundë¡œ ì‚¬ìš©
            if (not issues_found or len(issues_found) < 10) and not revised_question and not revised_rationale:
                issues_found = review_result
            
            # ìµœì¢… ì‘ë‹µ êµ¬ì„±
            response_data = {
                'success': True,
                'needs_revision': True,
                'revised_question': revised_question,
                'revised_rationale': revised_rationale,
                'issues_found': issues_found,
                'review_notes': review_result
            }
            
            return jsonify(response_data)
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/save', methods=['POST'])
def save_annotation():
    """Save annotation data to JSON file."""
    data = request.json
    
    # Validation: Check required fields (bboxëŠ” ì„ íƒì‚¬í•­)
    required_fields = ['question', 'response', 'view']
    missing_fields = []
    
    for field in required_fields:
        if field == 'view':
            if not data.get(field) or data.get(field).strip() == '':
                missing_fields.append('view')
        else:
            if not data.get(field) or data.get(field).strip() == '':
                missing_fields.append(field)
    
    if missing_fields:
        return jsonify({
            'error': 'Missing required fields',
            'missing_fields': missing_fields,
            'message': f'Please fill in: {", ".join(missing_fields)}'
        }), 400
    
    # Get image info
    image_id = data['image_id']
    image_info = annotator.coco.imgs[image_id]
    view_type = data['view']
    
    # image_path ìƒì„±: "/íŒŒì¼ëª…" í˜•ì‹
    image_filename = image_info['file_name']
    relative_image_path = f"/{image_filename}"
    
    # bbox ì²˜ë¦¬: bboxê°€ ìˆìœ¼ë©´ ì²˜ë¦¬, ì—†ìœ¼ë©´ None (ì„ íƒì‚¬í•­)
    # bbox ì¢Œí‘œë¥¼ ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ë¡œ í†µì¼
    selected_bboxes = data.get('selected_bboxes', [])
    if selected_bboxes and len(selected_bboxes) > 0:
        # ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ë¡œ í†µì¼
        def round_bbox(bbox):
            if isinstance(bbox, (list, tuple)) and len(bbox) >= 4:
                return [round(float(coord), 2) if isinstance(coord, (int, float)) else coord for coord in bbox]
            return bbox
        
        rounded_bboxes = [round_bbox(bbox) for bbox in selected_bboxes]
        
        if len(rounded_bboxes) == 1:
            # ë‹¨ì¼ bboxì¸ ê²½ìš° ë°°ì—´ë¡œ ê°ì‹¸ì§€ ì•Šê³  ì§ì ‘ ì €ì¥
            bbox_value = rounded_bboxes[0]
        else:
            # ì—¬ëŸ¬ bboxì¸ ê²½ìš° ë°°ì—´ë¡œ ì €ì¥
            bbox_value = rounded_bboxes
    else:
        # bboxê°€ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì €ì¥
        bbox_value = None
    
    annotation = {
        'image_id': data['image_id'],
        'image_path': relative_image_path,  # ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½
        'image_resolution': f"{image_info['width']}x{image_info['height']}",  # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (web_annotations_exo.json, web_annotations_ego.jsonì—ë§Œ ì €ì¥)
        'question': data['question'],
        'response': data['response'],
        'rationale': data.get('rationale', ''),
        'question_ko': data.get('question_ko', ''),  # í•œê¸€ ì§ˆë¬¸ ì¶”ê°€
        'rationale_ko': data.get('rationale_ko', ''),  # í•œê¸€ ê·¼ê±° ì¶”ê°€
        'view': view_type,
        'bbox': bbox_value  # ë‹¨ì¼ bboxëŠ” ë°°ì—´ë¡œ ê°ì‹¸ì§€ ì•ŠìŒ
    }
    
    # view íƒ€ì…ì— ë”°ë¼ í•´ë‹¹ íŒŒì¼ ê²½ë¡œ ì„ íƒ
    output_path = annotator.output_json_path_exo if view_type == 'exo' else annotator.output_json_path_ego
    other_output_path = annotator.output_json_path_ego if view_type == 'exo' else annotator.output_json_path_exo
    
    # íŒŒì¼ ì ê¸ˆì„ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ì ‘ê·¼ ë°©ì§€ (ì¤‘ë³µ ë°ì´í„° ë°©ì§€)
    lock = file_locks[view_type]
    
    with lock:  # ì ê¸ˆ íšë“ (ë‹¤ë¥¸ ì‘ì—…ìê°€ ì €ì¥ ì¤‘ì´ë©´ ëŒ€ê¸°)
        # í•´ë‹¹ view íƒ€ì…ì˜ annotations ë¡œë“œ (ì ê¸ˆ ë‚´ì—ì„œ ë‹¤ì‹œ ì½ì–´ ìµœì‹  ë°ì´í„° ë³´ì¥)
        view_annotations = []
        if os.path.exists(output_path):
            try:
                with open(output_path, 'r', encoding='utf-8') as f:
                    view_annotations = json.load(f)
            except (FileNotFoundError, json.JSONDecodeError):
                view_annotations = []
        
        # ì¤‘ë³µ ì²´í¬: ê°™ì€ image_idê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        found = False
        for i, ann in enumerate(view_annotations):
            if ann.get('image_id') == data['image_id']:
                view_annotations[i] = annotation  # ë®ì–´ì“°ê¸°
                found = True
                break
        
        if not found:
            # ì¤‘ë³µ í™•ì¸: í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë°©ì§€
            if not any(ann.get('image_id') == data['image_id'] for ann in view_annotations):
                view_annotations.append(annotation)  # ìƒˆë¡œ ì¶”ê°€
            else:
                # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì—…ë°ì´íŠ¸
                for i, ann in enumerate(view_annotations):
                    if ann.get('image_id') == data['image_id']:
                        view_annotations[i] = annotation
                        found = True
                        break
        
        # ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ ì²˜ë¦¬ (ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ë„ ì ê¸ˆ í•„ìš”)
        other_lock = file_locks['ego' if view_type == 'exo' else 'exo']
        with other_lock:
            other_view_annotations = []
            if os.path.exists(other_output_path):
                try:
                    with open(other_output_path, 'r', encoding='utf-8') as f:
                        other_view_annotations = json.load(f)
                except (FileNotFoundError, json.JSONDecodeError):
                    other_view_annotations = []
            
            # ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ì—ì„œ ê°™ì€ image_id ì œê±°
            other_view_annotations = [ann for ann in other_view_annotations if ann.get('image_id') != data['image_id']]
        
        # Save to file (ì›ìì  ì“°ê¸°: ì„ì‹œ íŒŒì¼ì— ì“°ê³  rename)
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
            
            # í˜„ì¬ view íƒ€ì… íŒŒì¼ ì €ì¥ (ì›ìì  ì“°ê¸°)
            json_str = json.dumps(view_annotations, indent=2, ensure_ascii=False)
            # bbox ë°°ì—´ì„ í•œ ì¤„ë¡œ ë³€ê²½: "bbox": [\n      ìˆ«ì,\n      ...\n    ] -> "bbox": [ìˆ«ì, ...]
            json_str = re.sub(
                r'"bbox":\s*\[\s*\n\s*([^\]]+?)\s*\n\s*\]',
                lambda m: f'"bbox": [{re.sub(r"\\s+", " ", m.group(1).strip())}]',
                json_str,
                flags=re.MULTILINE
            )
            
            # ì„ì‹œ íŒŒì¼ì— ì“°ê³  ì›ìì ìœ¼ë¡œ rename (ì¤‘ë³µ ë°©ì§€)
            temp_fd, temp_path = tempfile.mkstemp(dir=output_dir, suffix='.json.tmp', text=True)
            try:
                with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
                    f.write(json_str)
                # ì›ìì  ì“°ê¸°: ì„ì‹œ íŒŒì¼ì„ ìµœì¢… íŒŒì¼ë¡œ rename
                shutil.move(temp_path, output_path)
            except Exception:
                # ì‹¤íŒ¨ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
                try:
                    os.unlink(temp_path)
                except:
                    pass
                raise
            
            # ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ë„ ì €ì¥ (ê°™ì€ image_id ì œê±°ëœ ë²„ì „)
            if other_view_annotations != [] or os.path.exists(other_output_path):
                other_output_dir = os.path.dirname(other_output_path)
                if other_output_dir and not os.path.exists(other_output_dir):
                    os.makedirs(other_output_dir, exist_ok=True)
                
                other_json_str = json.dumps(other_view_annotations, indent=2, ensure_ascii=False)
                # bbox ë°°ì—´ì„ í•œ ì¤„ë¡œ ë³€ê²½
                other_json_str = re.sub(
                    r'"bbox":\s*\[\s*\n\s*([^\]]+?)\s*\n\s*\]',
                    lambda m: f'"bbox": [{re.sub(r"\\s+", " ", m.group(1).strip())}]',
                    other_json_str,
                    flags=re.MULTILINE
                )
                
                # ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ë„ ì›ìì  ì“°ê¸° (ë‹¤ì‹œ ì ê¸ˆ í•„ìš”)
                with other_lock:
                    other_temp_fd, other_temp_path = tempfile.mkstemp(dir=other_output_dir, suffix='.json.tmp', text=True)
                    try:
                        with os.fdopen(other_temp_fd, 'w', encoding='utf-8') as f:
                            f.write(other_json_str)
                        shutil.move(other_temp_path, other_output_path)
                    except Exception:
                        try:
                            os.unlink(other_temp_path)
                        except:
                            pass
                        raise
        
        except (IOError, OSError) as e:
            return jsonify({'error': f'Failed to save: {e}'}), 500
        
        # ì „ì²´ annotationsë„ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ë¡œë“œ ì‹œ ë°˜ì˜)
        annotator._reload_annotations()
        
        # Google Sheetsì— ì €ì¥ (ì‹¤íŒ¨í•´ë„ ë¡œì»¬ ì €ì¥ì€ ì„±ê³µí•œ ê²ƒìœ¼ë¡œ ì²˜ë¦¬)
        # worker_idëŠ” ìš”ì²­ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ configì—ì„œ ìë™ìœ¼ë¡œ ì‚¬ìš©
        worker_id = data.get('worker_id') or WORKER_ID
        sheets_success = False
        sheets_error = None
        revision_updated = False
        
        if google_sheets_client and worker_id:
            try:
                sheets_success = save_to_google_sheets(
                    worker_id=worker_id,
                    annotation=annotation,
                    image_info=image_info
                )
                if not sheets_success:
                    sheets_error = "Google Sheets ì €ì¥ ì‹¤íŒ¨ (ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜)"
                
                # ë¶ˆí†µ ìƒíƒœì´ê³  ìˆ˜ì •ì—¬ë¶€ê°€ ì•„ì§ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì—…ë°ì´íŠ¸
                # ê²€ìˆ˜ ìƒíƒœ í™•ì¸ì„ ìœ„í•´ ì‹œíŠ¸ì—ì„œ ì½ì–´ì˜¤ê¸°
                sheet_data = read_from_google_sheets(worker_id)
                print(f"[DEBUG] ì‹œíŠ¸ ë°ì´í„°ì—ì„œ Image ID {image_id} ê²€ìƒ‰ ì¤‘... (ì´ {len(sheet_data)}ê°œ í–‰)")
                for row in sheet_data:
                    row_image_id = row.get('Image ID', '') or row.get('image_id', '')
                    if str(row_image_id) == str(image_id):
                        review_status = row.get('ê²€ìˆ˜', '') or row.get('ê²€ìˆ˜ ìƒíƒœ', '')
                        revision_status = row.get('ìˆ˜ì •ì—¬ë¶€', '') or row.get('ìˆ˜ì • ì—¬ë¶€', '')
                        print(f"[DEBUG] Image ID {image_id} ë°œê²¬ - ê²€ìˆ˜: {review_status}, ìˆ˜ì •ì—¬ë¶€: {revision_status}")
                        if review_status == 'ë¶ˆí†µ' and revision_status != 'ìˆ˜ì •ì™„ë£Œ' and revision_status != 'ìˆ˜ì • ì™„ë£Œ':
                            # ìˆ˜ì •ì—¬ë¶€ ì—´ ì—…ë°ì´íŠ¸
                            print(f"[DEBUG] ìˆ˜ì •ì—¬ë¶€ ì—…ë°ì´íŠ¸ ì‹œë„ ì¤‘...")
                            revision_updated = update_revision_status(worker_id, image_id, 'ìˆ˜ì •ì™„ë£Œ')
                            if revision_updated:
                                print(f"[INFO] Image ID {image_id}ì˜ ìˆ˜ì •ì—¬ë¶€ë¥¼ 'ìˆ˜ì •ì™„ë£Œ'ë¡œ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
                            else:
                                print(f"[WARN] Image ID {image_id}ì˜ ìˆ˜ì •ì—¬ë¶€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                        else:
                            print(f"[DEBUG] ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš” - ê²€ìˆ˜: {review_status}, ìˆ˜ì •ì—¬ë¶€: {revision_status}")
                        break
                else:
                    print(f"[WARN] Image ID {image_id}ë¥¼ ì‹œíŠ¸ ë°ì´í„°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
            except Exception as e:
                sheets_error = str(e)
                print(f"[WARN] Google Sheets ì €ì¥ ì‹¤íŒ¨: {e}")
                import traceback
                print(f"[WARN] ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
        elif not google_sheets_client:
            sheets_error = "Google Sheets í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            print("[WARN] Google Sheets í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif not worker_id:
            sheets_error = "ì‘ì—…ì IDê°€ ì—†ìŠµë‹ˆë‹¤"
            print("[WARN] ì‘ì—…ì IDê°€ ì—†ì–´ Google Sheetsì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. config.pyì— WORKER_IDë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ìš”ì²­ì— worker_idë¥¼ í¬í•¨í•˜ì„¸ìš”.")
        
        response_data = {
            'success': True, 
            'updated': found,
            'sheets_saved': sheets_success,
            'sheets_error': sheets_error if not sheets_success else None,
            'revision_updated': revision_updated
        }
        
        return jsonify(response_data)


def save_to_google_sheets(worker_id, annotation, image_info):
    """
    Google Sheetsì— ì–´ë…¸í…Œì´ì…˜ ì €ì¥
    
    Args:
        worker_id: ì‘ì—…ì ID (ì˜ˆ: "worker001")
        annotation: ì–´ë…¸í…Œì´ì…˜ ë”•ì…”ë„ˆë¦¬
        image_info: ì´ë¯¸ì§€ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    if not google_sheets_client:
        return False
    
    try:
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
        spreadsheet = google_sheets_client.open_by_key(GOOGLE_SHEETS_SPREADSHEET_ID)
        
        # ì‘ì—…ìë³„ ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        sheet_name = worker_id
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            # ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=20)
            # í—¤ë” ì¶”ê°€
            headers = [
                'ì €ì¥ì‹œê°„', 'Image ID', 'Image Path', 'Image Resolution', 
                'Question', 'Response', 'Rationale', 'View', 'Bbox'
            ]
            worksheet.append_row(headers)
            # í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì • (ì„ íƒì‚¬í•­)
            try:
                worksheet.format('A1:I1', {'textFormat': {'bold': True}})
            except:
                pass
        
        # Bboxë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        bbox_str = ''
        if annotation.get('bbox'):
            if isinstance(annotation['bbox'], list):
                if isinstance(annotation['bbox'][0], list):
                    # ì—¬ëŸ¬ bbox
                    bbox_str = '; '.join([str(b) for b in annotation['bbox']])
                else:
                    # ë‹¨ì¼ bbox (ë°°ì—´)
                    bbox_str = str(annotation['bbox'])
            else:
                bbox_str = str(annotation['bbox'])
        
        # í–‰ ë°ì´í„° ì¤€ë¹„
        row_data = [
            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # ì €ì¥ì‹œê°„
            annotation.get('image_id', ''),
            annotation.get('image_path', ''),
            annotation.get('image_resolution', ''),
            annotation.get('question', ''),
            annotation.get('response', ''),
            annotation.get('rationale', ''),
            annotation.get('view', ''),
            bbox_str
        ]
        
        # ê°™ì€ image_idê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (ì—…ë°ì´íŠ¸)
        existing_rows = worksheet.get_all_values()
        row_to_update = None
        for idx, row in enumerate(existing_rows[1:], start=2):  # í—¤ë” ì œì™¸
            if len(row) > 1 and str(row[1]) == str(annotation.get('image_id', '')):
                row_to_update = idx
                break
        
        if row_to_update:
            # ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸
            worksheet.update(f'A{row_to_update}:I{row_to_update}', [row_data])
        else:
            # ìƒˆ í–‰ ì¶”ê°€
            worksheet.append_row(row_data)
        
        return True
        
    except Exception as e:
        error_msg = str(e)
        print(f"[ERROR] Google Sheets ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"[ERROR] ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        # ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œì„œ ìƒìœ„ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨
        raise


def read_from_google_sheets(worker_id):
    """
    Google Sheetsì—ì„œ ì‘ì—…ìì˜ ì–´ë…¸í…Œì´ì…˜ ë°ì´í„° ì½ê¸°
    
    Args:
        worker_id: ì‘ì—…ì ID (ì˜ˆ: "test")
        
    Returns:
        ë¦¬ìŠ¤íŠ¸: ê° í–‰ì˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        ê° ë”•ì…”ë„ˆë¦¬ëŠ” {'image_id': ..., 'ê²€ìˆ˜': ..., 'ë¹„ê³ ': ..., 'ìˆ˜ì •ì—¬ë¶€': ..., ...} í˜•íƒœ
    """
    if not google_sheets_client:
        return []
    
    try:
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
        spreadsheet = google_sheets_client.open_by_key(GOOGLE_SHEETS_SPREADSHEET_ID)
        
        # ì‘ì—…ìë³„ ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸°
        sheet_name = worker_id
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            print(f"[WARN] ì‹œíŠ¸ '{sheet_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_values = worksheet.get_all_values()
        if len(all_values) < 2:  # í—¤ë”ë§Œ ìˆê±°ë‚˜ ë¹„ì–´ìˆìŒ
            return []
        
        # í—¤ë” ì¶”ì¶œ
        headers = all_values[0]
        
        # í—¤ë” ì¸ë±ìŠ¤ ì°¾ê¸°
        header_indices = {}
        for idx, header in enumerate(headers):
            header_indices[header] = idx
        
        # ë°ì´í„° í–‰ ì²˜ë¦¬
        result = []
        for row in all_values[1:]:  # í—¤ë” ì œì™¸
            if len(row) == 0 or not row[1]:  # Image IDê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                continue
            
            row_data = {}
            for header, idx in header_indices.items():
                if idx < len(row):
                    row_data[header] = row[idx]
                else:
                    row_data[header] = ''
            
            result.append(row_data)
        
        return result
        
    except Exception as e:
        print(f"[ERROR] Google Sheets ì½ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"[ERROR] ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        return []


def update_revision_status(worker_id, image_id, status='ìˆ˜ì •ì™„ë£Œ'):
    """
    Google Sheetsì˜ ìˆ˜ì •ì—¬ë¶€ ì—´ ì—…ë°ì´íŠ¸
    
    Args:
        worker_id: ì‘ì—…ì ID
        image_id: ì´ë¯¸ì§€ ID
        status: ì—…ë°ì´íŠ¸í•  ìƒíƒœ (ê¸°ë³¸ê°’: 'ìˆ˜ì • ì™„ë£Œ')
        
    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    if not google_sheets_client:
        return False
    
    try:
        spreadsheet = google_sheets_client.open_by_key(GOOGLE_SHEETS_SPREADSHEET_ID)
        worksheet = spreadsheet.worksheet(worker_id)
        
        # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_values = worksheet.get_all_values()
        if len(all_values) < 2:
            return False
        
        # í—¤ë”ì—ì„œ ì—´ ì¸ë±ìŠ¤ ì°¾ê¸°
        headers = all_values[0]
        print(f"[DEBUG] í—¤ë” ëª©ë¡: {headers}")
        image_id_col = None
        revision_status_col = None
        
        for idx, header in enumerate(headers):
            header_clean = header.strip()
            if header_clean == 'Image ID' or header_clean == 'image_id':
                image_id_col = idx
                print(f"[DEBUG] Image ID ì—´ ë°œê²¬: ì¸ë±ìŠ¤ {idx}")
            if header_clean == 'ìˆ˜ì •ì—¬ë¶€' or header_clean == 'ìˆ˜ì • ì—¬ë¶€':
                revision_status_col = idx
                print(f"[DEBUG] ìˆ˜ì •ì—¬ë¶€ ì—´ ë°œê²¬: ì¸ë±ìŠ¤ {idx}")
        
        if image_id_col is None:
            print("[WARN] Image ID ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"[WARN] ì‚¬ìš© ê°€ëŠ¥í•œ í—¤ë”: {headers}")
            return False
        
        if revision_status_col is None:
            print("[WARN] ìˆ˜ì •ì—¬ë¶€ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"[WARN] ì‚¬ìš© ê°€ëŠ¥í•œ í—¤ë”: {headers}")
            return False
        
        # í•´ë‹¹ image_id ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
        for row_idx, row in enumerate(all_values[1:], start=2):  # í—¤ë” ì œì™¸, 1-based index
            if len(row) > image_id_col and str(row[image_id_col]) == str(image_id):
                # ìˆ˜ì •ì—¬ë¶€ ì—´ ì—…ë°ì´íŠ¸ (update_cell ì‚¬ìš©: row, colì€ 1-based)
                # revision_status_colì€ 0-basedì´ë¯€ë¡œ +1 í•´ì„œ 1-basedë¡œ ë³€í™˜
                worksheet.update_cell(row_idx, revision_status_col + 1, status)
                print(f"[INFO] Image ID {image_id}ì˜ ìˆ˜ì •ì—¬ë¶€ë¥¼ '{status}'ë¡œ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤. (ì…€: í–‰{row_idx}, ì—´{revision_status_col + 1})")
                return True
        
        print(f"[WARN] Image ID {image_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
        
    except Exception as e:
        print(f"[ERROR] ìˆ˜ì •ì—¬ë¶€ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"[ERROR] ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        return False


def remove_duplicate_annotations(json_path):
    """
    JSON íŒŒì¼ì—ì„œ ì¤‘ë³µëœ ì–´ë…¸í…Œì´ì…˜ ì œê±° (ê°™ì€ image_idê°€ ì—¬ëŸ¬ ê°œ ìˆëŠ” ê²½ìš°)
    ê°€ì¥ ìµœê·¼ ê²ƒë§Œ ìœ ì§€ (ë˜ëŠ” ì²« ë²ˆì§¸ ê²ƒë§Œ ìœ ì§€)
    
    Args:
        json_path: JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì œê±°ëœ ì¤‘ë³µ ê°œìˆ˜
    """
    if not os.path.exists(json_path):
        return 0
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            annotations = json.load(f)
        
        # image_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ì¤‘ë³µ ì‹œ ë§ˆì§€ë§‰ ê²ƒë§Œ ìœ ì§€)
        seen = {}
        duplicates_removed = 0
        
        for ann in annotations:
            image_id = ann.get('image_id')
            if image_id is not None:
                if image_id in seen:
                    duplicates_removed += 1
                seen[image_id] = ann
        
        # ì¤‘ë³µì´ ìˆìœ¼ë©´ íŒŒì¼ ì €ì¥
        if duplicates_removed > 0:
            # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            unique_annotations = list(seen.values())
            
            # ì›ìì  ì“°ê¸°ë¡œ ì €ì¥
            output_dir = os.path.dirname(json_path)
            json_str = json.dumps(unique_annotations, indent=2, ensure_ascii=False)
            # bbox ë°°ì—´ì„ í•œ ì¤„ë¡œ ë³€ê²½
            json_str = re.sub(
                r'"bbox":\s*\[\s*\n\s*([^\]]+?)\s*\n\s*\]',
                lambda m: f'"bbox": [{re.sub(r"\\s+", " ", m.group(1).strip())}]',
                json_str,
                flags=re.MULTILINE
            )
            
            temp_fd, temp_path = tempfile.mkstemp(dir=output_dir, suffix='.json.tmp', text=True)
            try:
                with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
                    f.write(json_str)
                shutil.move(temp_path, json_path)
            except Exception:
                try:
                    os.unlink(temp_path)
                except:
                    pass
                raise
            
            print(f"[INFO] {json_path}: {duplicates_removed}ê°œ ì¤‘ë³µ ì–´ë…¸í…Œì´ì…˜ ì œê±°ë¨")
        
        return duplicates_removed
    except Exception as e:
        print(f"[ERROR] {json_path} ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {e}")
        return 0


@app.route('/api/sync_from_sheets', methods=['GET'])
def sync_from_sheets():
    """
    Google Sheetsì—ì„œ í˜„ì¬ ì‘ì—…ìì˜ ë°ì´í„° ë™ê¸°í™”
    """
    try:
        worker_id = WORKER_ID
        if not worker_id:
            return jsonify({'error': 'ì‘ì—…ì IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
        
        # êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì½ê¸°
        sheet_data = read_from_google_sheets(worker_id)
        
        # ê²€ìˆ˜ ìƒíƒœë³„ë¡œ ë¶„ë¥˜
        passed_images = []  # í†µê³¼
        failed_images = []  # ë¶ˆí†µ
        completed_images = []  # ë‚©í’ˆ ì™„ë£Œ
        
        for row in sheet_data:
            image_id = row.get('Image ID', '') or row.get('image_id', '')
            review_status = row.get('ê²€ìˆ˜', '') or row.get('ê²€ìˆ˜ ìƒíƒœ', '')
            note = row.get('ë¹„ê³ ', '') or row.get('ê²€ìˆ˜ ì˜ê²¬', '')
            revision_status = row.get('ìˆ˜ì •ì—¬ë¶€', '') or row.get('ìˆ˜ì • ì—¬ë¶€', '')
            
            if not image_id:
                continue
            
            image_info = {
                'image_id': int(image_id) if image_id.isdigit() else image_id,
                'review_status': review_status,
                'note': note,
                'revision_status': revision_status,
                'row_data': row
            }
            
            if review_status == 'í†µê³¼':
                passed_images.append(image_info)
            elif review_status == 'ë¶ˆí†µ':
                failed_images.append(image_info)
            elif review_status == 'ë‚©í’ˆ ì™„ë£Œ':
                completed_images.append(image_info)
        
        return jsonify({
            'success': True,
            'worker_id': worker_id,
            'passed': passed_images,
            'failed': failed_images,
            'completed': completed_images,
            'total': len(sheet_data)
        })
        
    except Exception as e:
        print(f"[ERROR] êµ¬ê¸€ ì‹œíŠ¸ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"[ERROR] ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        return jsonify({'error': f'ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}'}), 500


@app.route('/api/get_review_status/<int:image_id>', methods=['GET'])
def get_review_status(image_id):
    """
    íŠ¹ì • ì´ë¯¸ì§€ì˜ ê²€ìˆ˜ ìƒíƒœë§Œ ê°€ì ¸ì˜¤ê¸°
    """
    try:
        worker_id = request.args.get('worker_id') or WORKER_ID
        if not worker_id:
            return jsonify({'error': 'ì‘ì—…ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        # êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì½ê¸°
        sheet_data = read_from_google_sheets(worker_id)
        
        # í•´ë‹¹ image_id ì°¾ê¸°
        for row in sheet_data:
            row_image_id = row.get('Image ID', '') or row.get('image_id', '')
            if str(row_image_id) == str(image_id):
                review_status = row.get('ê²€ìˆ˜', '') or row.get('ê²€ìˆ˜ ìƒíƒœ', '')
                note = row.get('ë¹„ê³ ', '') or row.get('ê²€ìˆ˜ ì˜ê²¬', '')
                revision_status = row.get('ìˆ˜ì •ì—¬ë¶€', '') or row.get('ìˆ˜ì • ì—¬ë¶€', '')
                
                return jsonify({
                    'success': True,
                    'image_id': image_id,
                    'review_status': review_status,
                    'note': note,
                    'revision_status': revision_status
                })
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš°
        return jsonify({
            'success': False,
            'message': 'Image ID not found in sheet.'
        })
        
    except Exception as e:
        print(f"[ERROR] ê²€ìˆ˜ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"[ERROR] ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        return jsonify({'error': f'ê²€ìˆ˜ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'}), 500


@app.route('/api/remove_duplicates', methods=['POST'])
def remove_duplicates():
    """ì¤‘ë³µ ì–´ë…¸í…Œì´ì…˜ ì œê±° API"""
    try:
        exo_count = remove_duplicate_annotations(annotator.output_json_path_exo)
        ego_count = remove_duplicate_annotations(annotator.output_json_path_ego)
        
        # ì „ì²´ annotationsë„ ì—…ë°ì´íŠ¸
        annotator._reload_annotations()
        
        return jsonify({
            'success': True,
            'exo_removed': exo_count,
            'ego_removed': ego_count,
            'total_removed': exo_count + ego_count
        })
    except Exception as e:
        return jsonify({'error': f'Failed to remove duplicates: {e}'}), 500


def create_template():
    """Create HTML template for the annotation interface."""
    template_dir = 'templates'
    if not os.path.exists(template_dir):
        os.makedirs(template_dir)

    # index.html ë®ì–´ì“°ê¸° ë°©ì§€ ì¶”ê°€
    target = os.path.join(template_dir, 'index.html')
    if os.path.exists(target):
        return
    
    html_content = '''<!DOCTYPE html>
<html>
<head>
    <title>COCO Annotation Tool</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .container { display: flex; gap: 20px; }
        .image-panel { flex: 2; }
        .control-panel { flex: 1; min-width: 350px; }
        .image-container { 
            border: 2px solid #ccc; 
            position: relative; 
            display: inline-block;
        }
        #image { max-width: 100%; display: block; }
        .bbox { 
            position: absolute; 
            border: 2px solid rgba(255, 0, 0, 0.7); 
            background-color: rgba(255, 0, 0, 0.1);
            cursor: pointer;
            transition: all 0.2s ease;
            z-index: 10;
        }
        .bbox:hover { 
            border-color: rgba(255, 255, 0, 0.9);
            background-color: rgba(255, 255, 0, 0.2);
            transform: scale(1.05);
            box-shadow: 0 0 10px rgba(255, 255, 0, 0.5);
            z-index: 20;
        }
        .bbox.selected { 
            border-color: rgba(0, 0, 255, 0.9);
            background-color: rgba(0, 0, 255, 0.2);
            border-width: 3px;
        }
        .bbox.selected:hover { 
            border-color: rgba(0, 255, 255, 0.9);
            background-color: rgba(0, 255, 255, 0.3);
        }
        .bbox-label {
            position: absolute;
            top: -20px;
            left: 0;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 2px 5px;
            font-size: 11px;
            white-space: nowrap;
            display: none;
            pointer-events: none;
        }
        .bbox:hover .bbox-label {
            display: block;
        }
        .form-group { margin-bottom: 15px; }
        label { display: block; font-weight: bold; margin-bottom: 5px; }
        textarea, input { width: 100%; padding: 8px; border: 1px solid #ccc; }
        button { 
            padding: 10px 15px; 
            margin: 5px; 
            border: none; 
            cursor: pointer;
        }
        .btn-save { background-color: lightgreen; }
        .btn-nav { background-color: lightblue; }
        .status { 
            position: fixed; 
            bottom: 0; 
            left: 0; 
            right: 0; 
            background: #f0f0f0; 
            padding: 10px; 
            border-top: 1px solid #ccc;
        }
    </style>
</head>
<body>
    <h1>MS-COCO Annotation Tool (Web Version)</h1>
    
    <div class="container">
        <div class="image-panel">
            <div class="image-container" id="imageContainer">
                <img id="image" src="" alt="COCO Image">
            </div>
        </div>
        
        <div class="control-panel">
            <div class="form-group">
                <label>Image Info:</label>
                <div id="imageInfo">Loading...</div>
            </div>
            
            <div class="form-group">
                <label for="question">Question: 
                    <span style="color: red;">*</span></label>
                <textarea id="question" rows="4"></textarea>
            </div>
            
            <div class="form-group">
                <label for="response">Response: 
                    <span style="color: red;">*</span></label>
                <textarea id="response" rows="4"></textarea>
            </div>
            
            <div class="form-group">
                <label for="rationale">Rationale:</label>
                <textarea id="rationale" rows="3"></textarea>
            </div>
            
            <div class="form-group">
                <label>View: <span style="color: red;">*</span></label>
                <div>
                    <input type="radio" id="viewExo" name="view" value="exo">
                    <label for="viewExo">Exo</label>
                </div>
                <div>
                    <input type="radio" id="viewEgo" name="view" value="ego">
                    <label for="viewEgo">Ego</label>
                </div>
            </div>
            
            <div class="form-group">
                <label for="selectedBboxes">Selected Bounding Boxes: 
                    <span style="color: red;">*</span></label>
                <textarea id="selectedBboxes" rows="3" readonly></textarea>
                <button onclick="clearBboxes()">Clear Bboxes</button>
            </div>
            
            <div class="form-group">
                <button class="btn-nav" onclick="previousImage()">Previous</button>
                <button class="btn-nav" onclick="nextImage()">Next</button>
                <button class="btn-save" onclick="saveAnnotation()">Save</button>
            </div>
        </div>
    </div>
    
    <div class="status" id="status">Ready</div>

    <script>
        let currentIndex = 0;
        let currentImageData = null;
        let selectedBboxes = [];
        let bboxElements = [];

        function loadImage(index) {
            fetch(`/api/image/${index}`)
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert(data.error);
                        return;
                    }
                    
                    currentImageData = data;
                    currentIndex = index;
                    
                    // Update image
                    const img = document.getElementById('image');
                    img.src = data.image_data;
                    
                    // Wait for image to load before drawing bboxes
                    img.onload = () => {
                        drawBboxes();
                    };
                    
                    // Update info
                    document.getElementById('imageInfo').innerHTML = 
                        `Image ${index + 1}/${data.total_images}<br>` +
                        `ID: ${data.image_id}<br>` +
                        `Original Size: ${data.width}x` +
                        `${data.height}<br>` +
                        `Display Size: ${data.display_width}x` +
                        `${data.display_height}<br>` +
                        `File: ${data.file_name}`;
                    
                    // Load existing annotation
                    if (data.existing_annotation) {
                        document.getElementById('question').value = 
                            data.existing_annotation.question || '';
                        document.getElementById('response').value = 
                            data.existing_annotation.response || '';
                        document.getElementById('rationale').value = 
                            data.existing_annotation.rationale || '';
                        selectedBboxes = data.existing_annotation.bbox || [];
                        
                        // Set view radio button
                        const view = data.existing_annotation.view || '';
                        if (view === 'exo') {
                            document.getElementById('viewExo').checked = true;
                        } else if (view === 'ego') {
                            document.getElementById('viewEgo').checked = true;
                        }
                    } else {
                        document.getElementById('question').value = '';
                        document.getElementById('response').value = '';
                        document.getElementById('rationale').value = '';
                        selectedBboxes = [];
                        // Clear view radio buttons
                        document.getElementById('viewExo').checked = false;
                        document.getElementById('viewEgo').checked = false;
                    }
                    
                    updateBboxDisplay();
                    updateStatus();
                })
                .catch(error => {
                    console.error('Error:', error);
                    alert('Failed to load image');
                });
        }

        function drawBboxes() {
            // Clear existing bboxes
            bboxElements.forEach(el => el.remove());
            bboxElements = [];
            
            if (!currentImageData) return;
            
            const container = document.getElementById('imageContainer');
            const img = document.getElementById('image');
            const scale = currentImageData.scale || 1.0;
            
            currentImageData.bboxes.forEach((bbox, index) => {
                const [x, y, w, h] = bbox;
                
                // Scale bbox coordinates to match displayed image size
                const scaledX = x * scale;
                const scaledY = y * scale;
                const scaledW = w * scale;
                const scaledH = h * scale;
                
                const div = document.createElement('div');
                div.className = 'bbox';
                div.style.left = `${scaledX}px`;
                div.style.top = `${scaledY}px`;
                div.style.width = `${scaledW}px`;
                div.style.height = `${scaledH}px`;
                
                // Add label
                const label = document.createElement('div');
                label.className = 'bbox-label';
                label.textContent = `Box ${index + 1}: [${x},${y},${w},${h}]`;
                div.appendChild(label);
                
                // Check if selected
                if (selectedBboxes.some(sb => 
                    JSON.stringify(sb) === JSON.stringify(bbox))) {
                    div.classList.add('selected');
                }
                
                // Add click event
                div.addEventListener('click', (e) => {
                    e.stopPropagation();
                    selectBbox(bbox, div);
                });
                
                container.appendChild(div);
                bboxElements.push(div);
            });
        }

        function selectBbox(bbox, element) {
            const bboxStr = JSON.stringify(bbox);
            const existingIndex = selectedBboxes.findIndex(sb => 
                JSON.stringify(sb) === bboxStr);
            
            if (existingIndex === -1) {
                selectedBboxes.push(bbox);
                element.classList.add('selected');
            } else {
                selectedBboxes.splice(existingIndex, 1);
                element.classList.remove('selected');
            }
            
            updateBboxDisplay();
            updateStatus();
        }

        function updateBboxDisplay() {
            const display = selectedBboxes.map(bbox => 
                `[${bbox.join(',')}]`).join(', ');
            document.getElementById('selectedBboxes').value = display;
        }

        function clearBboxes() {
            selectedBboxes = [];
            updateBboxDisplay();
            drawBboxes();
        }

        function previousImage() {
            if (currentIndex > 0) {
                loadImage(currentIndex - 1);
            }
        }

        function nextImage() {
            loadImage(currentIndex + 1);
        }

        function saveAnnotation() {
            const question = document.getElementById('question').value.trim();
            const response = document.getElementById('response').value.trim();
            const rationale = document.getElementById('rationale').value.trim();
            
            // Get selected view
            const viewRadios = document.getElementsByName('view');
            let selectedView = '';
            for (let radio of viewRadios) {
                if (radio.checked) {
                    selectedView = radio.value;
                    break;
                }
            }
            
            // Client-side validation
            const missingFields = [];
            if (!question) missingFields.push('question');
            if (!response) missingFields.push('response');
            if (!selectedView) missingFields.push('view');
            if (selectedBboxes.length === 0) missingFields.push('bbox');
            
            if (missingFields.length > 0) {
                alert(`Please fill in the following required fields: ` +
                      `${missingFields.join(', ')}`);
                return;
            }
            
            const data = {
                image_id: currentImageData.image_id,
                question: question,
                response: response,
                rationale: rationale,
                view: selectedView,
                selected_bboxes: selectedBboxes
            };
            
            fetch('/api/save', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify(data)
            })
            .then(response => response.json())
            .then(result => {
                if (result.success) {
                    alert('Annotation saved successfully!');
                    nextImage();
                } else {
                    if (result.missing_fields) {
                        alert(`Server validation failed: ${result.message}`);
                    } else {
                        alert('Failed to save: ' + result.error);
                    }
                }
            })
            .catch(error => {
                console.error('Error:', error);
                alert('Failed to save annotation');
            });
        }

        function updateStatus() {
            document.getElementById('status').textContent = 
                `Current: ${currentIndex + 1} | Selected bboxes: ` +
                `${selectedBboxes.length}`;
        }

        // Auto-save function
        function autoSave() {
            const question = document.getElementById('question').value.trim();
            const response = document.getElementById('response').value.trim();
            const rationale = document.getElementById('rationale').value.trim();
            
            // Get selected view
            const viewRadios = document.getElementsByName('view');
            let selectedView = '';
            for (let radio of viewRadios) {
                if (radio.checked) {
                    selectedView = radio.value;
                    break;
                }
            }
            
            // Only auto-save if all required fields are filled
            if (currentImageData && question && response && 
                selectedView && selectedBboxes.length > 0) {
                const data = {
                    image_id: currentImageData.image_id,
                    question: question,
                    response: response,
                    rationale: rationale,
                    view: selectedView,
                    selected_bboxes: selectedBboxes
                };
                
                fetch('/api/save', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(data)
                })
                .then(response => response.json())
                .then(result => {
                    if (result.success) {
                        console.log('Auto-saved');
                    }
                })
                .catch(error => {
                    console.error('Auto-save error:', error);
                });
            }
        }

        // Save on unload
        window.addEventListener('beforeunload', (e) => {
            autoSave();
        });

        // Auto-save every 30 seconds
        setInterval(autoSave, 30000);

        // Handle keyboard shortcuts
        document.addEventListener('keydown', (e) => {
            if (e.ctrlKey || e.metaKey) {
                if (e.key === 's') {
                    e.preventDefault();
                    saveAnnotation();
                } else if (e.key === 'ArrowLeft') {
                    e.preventDefault();
                    previousImage();
                } else if (e.key === 'ArrowRight') {
                    e.preventDefault();
                    nextImage();
                }
            }
        });

        // Load first image on start
        loadImage(0);
    </script>
</body>
</html>'''
    
    with open(os.path.join(template_dir, 'index.html'), 'w', encoding='utf-8') as f:
        f.write(html_content)


def main():
    """Main function to start the web server."""
    
    parser = argparse.ArgumentParser(
        description='Web-based COCO Annotation Tool')
    parser.add_argument('--mscoco_folder', 
                        default='./mscoco',
                        help='Path to mscoco folder (contains exo_images and ego_images)')
    parser.add_argument('--coco_json', 
                        default='/Data/MSCOCO/annotations/instances_train2017.json',
                        help='Path to COCO annotations JSON file')
    parser.add_argument('--output_json', required=True,
                        help='Path to output JSON file for annotations')
    parser.add_argument('--host', default='0.0.0.0', 
                        help='Host to run server on')
    parser.add_argument('--port', default=5000, type=int, 
                        help='Port to run server on')
    parser.add_argument('--categories_json', default=None,
                        help='Path to custom categories JSON (list of {id,name})')
    parser.add_argument('--test_folder', default=None,
                        help='Test folder name (e.g., exo_test_image) to use instead of exo_images')

    
    args = parser.parse_args()
    
    # Validate paths
    if not os.path.exists(args.mscoco_folder):
        print(f"Error: mscoco folder not found: {args.mscoco_folder}")
        return
    
    # í…ŒìŠ¤íŠ¸ í´ë”ê°€ ì§€ì •ë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ë³¸ í´ë” í™•ì¸
    if args.test_folder:
        exo_images_path = os.path.join(args.mscoco_folder, args.test_folder)
        print(f"[INFO] Using test folder: {exo_images_path}")
        # test_folder ëª¨ë“œì—ì„œëŠ” ego_images_pathë¥¼ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        ego_images_path = None
    else:
        exo_images_path = os.path.join(args.mscoco_folder, 'exo_images')
        ego_images_path = os.path.join(args.mscoco_folder, 'ego_images')
    
    if not os.path.exists(exo_images_path):
        print(f"Warning: exo images folder not found: {exo_images_path}")
    if ego_images_path and not os.path.exists(ego_images_path):
        print(f"Warning: ego_images folder not found: {ego_images_path}")
    
    if not os.path.exists(args.coco_json):
        print(f"Error: COCO JSON file not found: {args.coco_json}")
        return
    
    # Create output directory
    output_dir = os.path.dirname(args.output_json) if os.path.dirname(args.output_json) else '.'
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    # Initialize global annotator
    global annotator
    annotator = COCOWebAnnotator(args.mscoco_folder, args.coco_json, 
                                 args.output_json, args.categories_json, 
                                 test_folder=args.test_folder)
    
    # Create template
    create_template()
    
    
    print(f"Starting web server at http://{args.host}:{args.port}")
    print("Access the annotation tool in your web browser")
    print(f"Exo annotations will be saved to: {annotator.output_json_path_exo}")
    print(f"Ego annotations will be saved to: {annotator.output_json_path_ego}")
    
    # ë©€í‹°ìŠ¤ë ˆë“œ ëª¨ë“œë¡œ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ë°©ì§€)
    # Google Sheets ì—°ë™ ìƒíƒœ í™•ì¸
    if GOOGLE_SHEETS_AVAILABLE:
        print(f"[INFO] Google Sheets ì—°ë™: ì‚¬ìš© ê°€ëŠ¥")
        if google_sheets_client:
            print(f"[INFO] Google Sheets í´ë¼ì´ì–¸íŠ¸: ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            print(f"[WARN] Google Sheets í´ë¼ì´ì–¸íŠ¸: ì´ˆê¸°í™” ì‹¤íŒ¨ (ì„¤ì • í™•ì¸ í•„ìš”)")
    else:
        print(f"[WARN] Google Sheets ì—°ë™: ì‚¬ìš© ë¶ˆê°€")
    
    app.run(host=args.host, port=args.port, debug=True, threaded=True, use_reloader=False)


if __name__ == "__main__":
    main()
