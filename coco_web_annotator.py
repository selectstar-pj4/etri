#!/usr/bin/env python3
"""
Web-based COCO Annotation Interface (Flask)
Web-based annotation tool that can be used on remote servers
"""

import argparse
import base64
import json
import os
from io import BytesIO

from flask import Flask, render_template, request, jsonify, make_response
from PIL import Image
from pycocotools.coco import COCO
try:
    from openai import OpenAI
    from openai import RateLimitError
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Gemini support removed - using OpenAI only
GEMINI_AVAILABLE = False

import re

app = Flask(__name__)
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0

# API Keys (config.pyì—ì„œ ë¡œë“œ, ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
try:
    from config import OPENAI_API_KEY, DEFAULT_MODEL
except ImportError:
    import os
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
    DEFAULT_MODEL = os.getenv('DEFAULT_MODEL', 'openai')
    if not OPENAI_API_KEY:
        print("[WARN] OpenAI API key not found. Please create config.py or set OPENAI_API_KEY environment variable.")

class COCOWebAnnotator:
    """Web-based COCO annotation tool for creating question-response pairs."""
    
    def __init__(self, mscoco_folder, coco_json_path, output_json_path, categories_json_path=None, test_folder=None):
        # mscoco í´ë” ê²½ë¡œ (exo_imagesì™€ ego_imagesê°€ ìˆëŠ” í´ë”)
        self.mscoco_folder = mscoco_folder
        # í…ŒìŠ¤íŠ¸ í´ë”ê°€ ì§€ì •ë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ë³¸ í´ë” ì‚¬ìš©
        if test_folder:
            self.exo_images_folder = os.path.join(mscoco_folder, test_folder)
            self.ego_images_folder = os.path.join(mscoco_folder, 'ego_images')  # í…ŒìŠ¤íŠ¸ ì‹œì—ë„ egoëŠ” ê¸°ë³¸ í´ë”
        else:
            self.exo_images_folder = os.path.join(mscoco_folder, 'exo_images')
            self.ego_images_folder = os.path.join(mscoco_folder, 'ego_images')
        self.coco_json_path = coco_json_path
        # output_json_pathë¥¼ exo/egoë¡œ ë¶„ë¦¬
        output_dir = os.path.dirname(output_json_path) if os.path.dirname(output_json_path) else '.'
        output_basename = os.path.basename(output_json_path) if os.path.basename(output_json_path) else 'annotations.json'
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ê³  exo/ego ì ‘ë¯¸ì‚¬ ì¶”ê°€
        if output_basename.endswith('.json'):
            base_name = output_basename[:-5]
        else:
            base_name = output_basename
        
        self.output_json_path_exo = os.path.join(output_dir, f'{base_name}_exo.json')
        self.output_json_path_ego = os.path.join(output_dir, f'{base_name}_ego.json')
        
        # Initialize COCO API
        self.coco = COCO(coco_json_path)
        all_image_ids = list(self.coco.imgs.keys())
        
        # ì´ë¯¸ì§€ ìˆœì„œ ì •ë ¬: exo_images ë¨¼ì €, ê·¸ ë‹¤ìŒ ego_images
        exo_image_ids = []
        ego_image_ids = []
        unknown_image_ids = []
        
        # test_folderê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ í´ë”ì— ìˆëŠ” ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬
        if test_folder:
            # test_folderì— ìˆëŠ” ì‹¤ì œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            test_folder_files = set()
            if os.path.exists(self.exo_images_folder):
                test_folder_files = set(os.listdir(self.exo_images_folder))
            
            for image_id in all_image_ids:
                image_info = self.coco.imgs[image_id]
                file_name = image_info.get('file_name', '')
                
                # test_folderì— ìˆëŠ” íŒŒì¼ë§Œ í¬í•¨
                if file_name in test_folder_files:
                    exo_path = os.path.join(self.exo_images_folder, file_name)
                    if os.path.exists(exo_path):
                        exo_image_ids.append(image_id)
        else:
            # test_folderê°€ ì—†ìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ ìˆœíšŒ
            for image_id in all_image_ids:
                image_info = self.coco.imgs[image_id]
                file_name = image_info.get('file_name', '')
                
                # exo_images í´ë”ì— ìˆëŠ”ì§€ í™•ì¸
                exo_path = os.path.join(self.exo_images_folder, file_name)
                ego_path = os.path.join(self.ego_images_folder, file_name)
                
                if os.path.exists(exo_path):
                    exo_image_ids.append(image_id)
                elif os.path.exists(ego_path):
                    ego_image_ids.append(image_id)
                else:
                    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ exoì— ì¶”ê°€ (ë˜ëŠ” unknownì— ì¶”ê°€)
                    unknown_image_ids.append(image_id)
        
        # ì´ë¯¸ì§€ IDë¥¼ íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” í•¨ìˆ˜
        def sort_by_filename(image_id_list):
            """ì´ë¯¸ì§€ ID ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬"""
            def get_filename(image_id):
                image_info = self.coco.imgs.get(image_id, {})
                return image_info.get('file_name', '')
            
            return sorted(image_id_list, key=get_filename)
        
        # test_folderê°€ ì§€ì •ë˜ë©´ exoë§Œ, ì•„ë‹ˆë©´ exo + ego + unknown
        if test_folder:
            self.image_ids = sort_by_filename(exo_image_ids)
            print(f"[INFO] Test folder mode: {len(exo_image_ids)} images from {test_folder} (sorted by filename)")
        else:
            # exo ë¨¼ì €, ê·¸ ë‹¤ìŒ ego, ë§ˆì§€ë§‰ì— unknown (ê°ê° íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬)
            sorted_exo = sort_by_filename(exo_image_ids)
            sorted_ego = sort_by_filename(ego_image_ids)
            sorted_unknown = sort_by_filename(unknown_image_ids)
            self.image_ids = sorted_exo + sorted_ego + sorted_unknown
            print(f"[INFO] Image order: {len(exo_image_ids)} exo images, {len(ego_image_ids)} ego images, {len(unknown_image_ids)} unknown images (all sorted by filename)")

        # --- ì¶”ê°€: category id -> name ë§¤í•‘ ë¡œë“œ ---
        self.category_id_to_name = {}
        if categories_json_path and os.path.exists(categories_json_path):
            try:
                with open(categories_json_path, 'r', encoding='utf-8') as f:
                    cats = json.load(f)
                    # catsê°€ [{"id": 74, "name": "mouse", ...}, ...] í˜•íƒœë¼ê³  ê°€ì •
                    for c in cats:
                        cid = c.get('id')
                        name = c.get('name')
                        if cid is not None and name:
                            self.category_id_to_name[int(cid)] = str(name)
            except Exception as e:
                print(f"[WARN] Failed to load categories_json: {e}")
        # pycocotools fallback
        if not self.category_id_to_name:
            # COCOì˜ ì¹´í…Œê³ ë¦¬ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©
            for cid, info in self.coco.cats.items():
                self.category_id_to_name[int(cid)] = info.get('name', 'unknown')
        # -----------------------------------------
        
        # Load existing annotations (exoì™€ ego ëª¨ë‘ ë¡œë“œ)
        self.annotations = []
        self._reload_annotations()
    
    def _reload_annotations(self):
        """Reload exo and ego annotations (called when needed)"""
        self.annotations = []
        # exo annotations ë¡œë“œ
        if os.path.exists(self.output_json_path_exo):
            try:
                with open(self.output_json_path_exo, 'r', encoding='utf-8') as f:
                    exo_anns = json.load(f)
                    self.annotations.extend(exo_anns)
            except (FileNotFoundError, json.JSONDecodeError) as e:
                print(f"[WARN] Failed to load exo annotations: {e}")
        # ego annotations ë¡œë“œ
        if os.path.exists(self.output_json_path_ego):
            try:
                with open(self.output_json_path_ego, 'r', encoding='utf-8') as f:
                    ego_anns = json.load(f)
                    self.annotations.extend(ego_anns)
            except (FileNotFoundError, json.JSONDecodeError) as e:
                print(f"[WARN] Failed to load ego annotations: {e}")
    

def get_vqa_json_by_filename(image_filename, coco_json_path, mscoco_folder=None, question=None, response=None, rationale=None, bbox=None, view=None):
    """
    ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ë©´, COCO jsonì—ì„œ í•´ë‹¹ ì´ë¯¸ì§€ì˜ image_id/annotation/bbox/categoryë¥¼ ì°¾ì•„
    VQA Output ì˜ˆì‹œì— ë§ëŠ” json(dict)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    question, response, rationale, bbox, viewëŠ” ì¸ìë¡œ ë°›ì•„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ê²°ê³¼ëŠ” íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•Šê³  dictë¡œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    import os
    from pycocotools.coco import COCO

    coco = COCO(coco_json_path)
    # íŒŒì¼ëª… -> image_id, image_path ì°¾ê¸°
    image_id = None
    for img in coco.dataset["images"]:
        if img["file_name"] == image_filename:
            image_id = img["id"]
            break
    if image_id is None:
        raise ValueError(f"Image filename '{image_filename}' not found in COCO json.")

    # ìƒëŒ€ ê²½ë¡œë¡œ image_path ìƒì„± (viewê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
    view_type = view if view else 'exo'
    # mscoco í´ë”ëª… ì¶”ì¶œ
    if mscoco_folder:
        mscoco_folder_name = os.path.basename(os.path.normpath(mscoco_folder))
    else:
        mscoco_folder_name = 'mscoco'
    
    if view_type == 'ego':
        image_path = f"{mscoco_folder_name}/ego_images/{image_filename}"
    else:
        image_path = f"{mscoco_folder_name}/exo_images/{image_filename}"

    # bbox ìë™/ìˆ˜ë™ ì…ë ¥: ì…ë ¥ê°’ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ, ì—†ìœ¼ë©´ ì „ì²´ bbox ëª¨ë‘
    anns = coco.loadAnns(coco.getAnnIds(imgIds=image_id))
    all_bboxes = [a.get("bbox", []) for a in anns]
    bbox_out = bbox if bbox is not None else all_bboxes

    vqa_json = {
        "image_id": image_id,
        "image_path": image_path,  # ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½
        "question": question if question is not None else "",
        "response": response if response is not None else "",
        "rationale": rationale if rationale is not None else "",
        "bbox": bbox_out,
        "view": view_type
    }
    return vqa_json

# Global annotator instance
annotator = None

# ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìºì‹œ (image_idë¥¼ í‚¤ë¡œ ì‚¬ìš©)
image_analysis_cache = {}

# idx ê²€ìƒ‰ ë¼ìš°íŠ¸ ì¶”ê°€ #
@app.route('/api/find/<int:image_id>')
def find_by_image_id(image_id):
    """Return dataset index for the given COCO image_id."""
    if annotator is None or not annotator.image_ids:
        return jsonify({'error': 'Annotator not initialized'}), 500
    try:
        idx = annotator.image_ids.index(image_id)
        return jsonify({'index': idx, 'total': len(annotator.image_ids)})
    except ValueError:
        return jsonify({'error': f'Image ID {image_id} not found'}), 404

@app.route('/')
def index():
    """Render the main annotation interface."""
    response = make_response(render_template('index.html'))
    # ë¸Œë¼ìš°ì € ìºì‹œ ë°©ì§€
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/exo_image_indices', methods=['GET'])
def get_exo_image_indices():
    """Get list of all exo image indices (for batch processing) - ë¹ ë¥¸ ë²„ì „"""
    try:
        exo_indices = []
        for idx, image_id in enumerate(annotator.image_ids):
            image_info = annotator.coco.imgs[image_id]
            file_name = image_info.get('file_name', '')
            exo_path = os.path.join(annotator.exo_images_folder, file_name)
            if os.path.exists(exo_path):
                exo_indices.append(idx)
        
        return jsonify({
            'success': True,
            'exo_indices': exo_indices,
            'total': len(exo_indices)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/image/<int:index>')
def get_image(index):
    """Get image information for a specific index."""
    if index >= len(annotator.image_ids):
        return jsonify({'error': 'Invalid index'}), 400
        
    image_id = annotator.image_ids[index]
    image_info = annotator.coco.imgs[image_id]
    
    # Get annotations for this image
    ann_ids = annotator.coco.getAnnIds(imgIds=image_id)
    annotations = annotator.coco.loadAnns(ann_ids)

    # === ìƒˆë¡œ ì¶”ê°€: bbox/ì¹´í…Œê³ ë¦¬ ë¬¶ìŒ ë°°ì—´ ===
    anns_payload = []
    for ann in annotations:
        bbox = ann.get('bbox', [])
        cid = ann.get('category_id', None)
        name = annotator.category_id_to_name.get(int(cid), 'unknown') if cid is not None else 'unknown'
        anns_payload.append({
            'bbox': bbox,
            'category_id': cid,
            'category_name': name
        })

    # === ì¶”ê°€: category_names ì±„ìš°ê¸° ===
    category_names = []
    for ann in annotations:
        cid = ann.get('category_id', None)
        name = annotator.category_id_to_name.get(int(cid)) if cid is not None else None
        category_names.append(name if name else 'unknown')

    # Check existing annotations (exoì™€ ego ëª¨ë‘ í™•ì¸)
    existing_annotation = None
    for ann in annotator.annotations:
        if ann['image_id'] == image_id:
            existing_annotation = ann
            break

    # Convert image to base64 for web display
    # ê¸°ì¡´ annotationì˜ view íƒ€ì… í™•ì¸í•˜ì—¬ í•´ë‹¹ í´ë”ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    view_type = 'exo'  # ê¸°ë³¸ê°’
    if existing_annotation:
        view_type = existing_annotation.get('view', 'exo')
    else:
        # annotationsì—ì„œ ì°¾ê¸°
        for ann in annotator.annotations:
            if ann.get('image_id') == image_id:
                view_type = ann.get('view', 'exo')
                break
    
    # view íƒ€ì…ì— ë”°ë¼ ì˜¬ë°”ë¥¸ í´ë”ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    if view_type == 'ego':
        image_path = os.path.join(annotator.ego_images_folder, image_info['file_name'])
    else:
        image_path = os.path.join(annotator.exo_images_folder, image_info['file_name'])
    
    # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í´ë”ì—ì„œ ì‹œë„
    if not os.path.exists(image_path):
        print(f"[WARN] Image not found at {image_path}, trying alternative paths...")
        # exoì—ì„œ ì°¾ê¸°
        alt_path_exo = os.path.join(annotator.exo_images_folder, image_info['file_name'])
        alt_path_ego = os.path.join(annotator.ego_images_folder, image_info['file_name'])
        
        if os.path.exists(alt_path_exo):
            image_path = alt_path_exo
            view_type = 'exo'
            print(f"[INFO] Found image in exo_images: {image_path}")
        elif os.path.exists(alt_path_ego):
            image_path = alt_path_ego
            view_type = 'ego'
            print(f"[INFO] Found image in ego_images: {image_path}")
        else:
            # ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
            error_msg = f"Image not found: {image_info['file_name']}\n"
            error_msg += f"Tried paths:\n"
            error_msg += f"  - {alt_path_exo} (exists: {os.path.exists(alt_path_exo)})\n"
            error_msg += f"  - {alt_path_ego} (exists: {os.path.exists(alt_path_ego)})"
            print(f"[ERROR] {error_msg}")
            return jsonify({'error': error_msg}), 500
    
    try:
        with Image.open(image_path) as img:
            original_width, original_height = img.size
            # Resize if too large but keep track of scale
            max_width, max_height = 800, 600
            scale = min(max_width/original_width, 
                       max_height/original_height, 1.0)
            if scale < 1.0:
                new_width = int(original_width * scale)
                new_height = int(original_height * scale)
                img = img.resize((new_width, new_height), 
                                Image.Resampling.LANCZOS)
            else:
                new_width, new_height = original_width, original_height
            
            buffer = BytesIO()
            img.save(buffer, format='JPEG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
    except (IOError, OSError, ValueError) as e:
        return jsonify({'error': f'Failed to load image: {e}'}), 500
    return jsonify({
        'image_id': image_id,
        'image_data': f'data:image/jpeg;base64,{img_base64}',
        'width': image_info['width'],
        'height': image_info['height'],
        'display_width': new_width,
        'display_height': new_height,
        'scale': scale,
        'file_name': image_info['file_name'],
        'bboxes': [ann['bbox'] for ann in annotations],
        'categories': [ann.get('category_id', 0) for ann in annotations],
        'category_names': category_names,  # <<< ì¶”ê°€
        'anns': anns_payload, # <<< ì¶”ê°€
        'existing_annotation': existing_annotation,
        'view_type': view_type,  # ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë”ì— ë”°ë¼ ê²°ì •ëœ view íƒ€ì…
        'current_index': index,
        'total_images': len(annotator.image_ids)
    })

@app.route('/api/translate/question', methods=['POST'])
def translate_question():
    """Translate Korean question to English using GPT-5."""
    data = request.json
    question_ko = data.get('question_ko', '').strip()
    
    if not question_ko:
        return jsonify({'success': False, 'error': 'Question (Korean) is required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        # OpenAI API í˜¸ì¶œ (ì½”ë“œì—ì„œ ì§ì ‘ API í‚¤ ì‚¬ìš©)
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # exo_data_sample.json í˜•ì‹ ì°¸ê³ í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì‘ì„±
        prompt = f"""Translate the following Korean question to English. You MUST follow this EXACT format:

CORRECT FORMAT:
[Question with <ATT>, <POS>, <REL> tags embedded naturally in the sentence] <choice>(a) option1, (b) option2, (c) option3, (d) option4</choice> And provide the bounding box coordinate of the region related to your answer.

CRITICAL TAG USAGE RULES:

1. <REL> tag - Use ONLY for RELATIONSHIP terms (distance, order, placement):
   - Examples: "farthest", "closest", "second-closest", "placed on the floor"
   - DO NOT use for objects or locations

2. <POS> tag - Use ONLY for POSITION/LOCATION information:
   - Examples: "in the center", "on the left side of", "in front of", "to the left side", "on the right side"
   - DO NOT use for object attributes or relationships
   - DO NOT use generic phrases like "in the image"

3. <ATT> tag - Use ONLY for ATTRIBUTES or TARGET GROUPS:
   - Examples: "red object", "square-shaped item", "among the items", "among the visible people", "edible food item"
   - Use for describing WHAT object/group is being asked about

Reference examples:
- "Which <ATT>red object</ATT> is <REL>farthest</REL> from the flag <POS>in the center of the table</POS>?"
- "Which <ATT>square-shaped item</ATT> is <REL>placed on the floor</REL> <POS>in front of</POS> the man?"
- "Which <ATT>edible food item</ATT> is the <REL>farthest</REL> from the fork <POS>on the left side of</POS> the table?"

Korean question: {question_ko}

Translate to English following the EXACT format above. Make sure:
- <REL> is used ONLY for relationship terms (farthest, closest, etc.)
- <POS> is used ONLY for position/location information (in the center, on the left side, etc.)
- <ATT> is used ONLY for attributes or target groups (red object, among the items, etc.)
- All tags have meaningful content inside them
- <choice> tag comes before "And provide..." phrase
- DO NOT use generic phrases like "in the image" for <POS> tag"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a professional translator specializing in VQA (Visual Question Answering) questions. CRITICAL RULES: 1) <REL> tag ONLY for relationship terms (farthest, closest, etc.), 2) <POS> tag ONLY for position/location (in the center, on the left side, etc.), 3) <ATT> tag ONLY for attributes/target groups (red object, among the items, etc.), 4) Tags MUST contain actual meaningful content, 5) Format: [Question with tags] <choice>...</choice> And provide..., 6) DO NOT use generic phrases like 'in the image' for <POS> tag."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        translated_question = response.choices[0].message.content.strip()
        
        # íƒœê·¸ ê²€ì¦
        if '<ATT>' not in translated_question and '<POS>' not in translated_question and '<REL>' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must include at least one of <ATT>, <POS>, or <REL> tags'}), 400
        
        if '<choice>' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must include <choice> tag'}), 400
        
        if 'And provide the bounding box coordinate of the region related to your answer.' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must end with the required phrase'}), 400
        
        return jsonify({
            'success': True,
            'translated_question': translated_question
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/translate/choices', methods=['POST'])
def translate_choices():
    """Translate Korean choices to English and format as <choice> tag."""
    data = request.json
    choice_a = data.get('choice_a', '').strip()
    choice_b = data.get('choice_b', '').strip()
    choice_c = data.get('choice_c', '').strip()
    choice_d = data.get('choice_d', '').strip()
    
    if not all([choice_a, choice_b, choice_c, choice_d]):
        return jsonify({'success': False, 'error': 'All choices are required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY environment variable not set'}), 500
        
        client = OpenAI(api_key=api_key)
        
        prompt = f"""Translate the following Korean multiple choice options to English. Use concise, intuitive adjective+noun or noun+noun format (NOT full sentences).

CRITICAL FORMATTING RULES:
- Use concise, intuitive format: adjective + noun or noun + noun
- Examples:
  * "a person in a black shirt" â†’ "black shirt person"
  * "a person wearing glasses" â†’ "glasses person"
  * "a cup on the table" â†’ "table cup" or "cup"
  * "a red chair" â†’ "red chair"
  * "a man with a blue t-shirt" â†’ "blue t-shirt man"
- DO NOT use full sentences like "a person who is wearing a black shirt"
- DO NOT use articles "a" or "the" unless necessary
- Keep it short and intuitive

Korean choices:
(a) {choice_a}
(b) {choice_b}
(c) {choice_c}
(d) {choice_d}

Translate each option to English and format as: <choice>(a) translated_a, (b) translated_b, (c) translated_c, (d) translated_d</choice>

Return only the formatted <choice> tag with translations."""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a translator specializing in concise, intuitive translations for multiple choice options. CRITICAL: Use adjective+noun or noun+noun format (e.g., 'black shirt person', 'glasses person'), NOT full sentences. Keep translations short and intuitive."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        translated_choices = response.choices[0].message.content.strip()
        
        # <choice> íƒœê·¸ ì¶”ì¶œ
        choice_match = re.search(r'<choice>(.*?)</choice>', translated_choices, re.IGNORECASE)
        if not choice_match:
            return jsonify({'success': False, 'error': 'Translation must include <choice> tag'}), 400
        
        choice_content = choice_match.group(1)
        # ê° ì„ íƒì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        choice_texts = {}
        for letter in ['a', 'b', 'c', 'd']:
            pattern = rf'\({letter}\)\s*([^,)]+)'
            match = re.search(pattern, choice_content, re.IGNORECASE)
            if match:
                choice_texts[letter] = match.group(1).strip()
        
        return jsonify({
            'success': True,
            'translated_choices': translated_choices,
            'choice_texts': choice_texts
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


# Gemini functions removed - using OpenAI only

def analyze_image_with_model(image_base64, model='openai', image_path=None):
    """ì´ë¯¸ì§€ ë¶„ì„ì„ ëª¨ë¸ë³„ë¡œ ìˆ˜í–‰í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    analysis_prompt = """Analyze this image in detail and extract specific visual features. Focus on:

1. **Objects with detailed attributes**: 
   - Color (e.g., "yellow cup", "red chair", "blue bag")
   - Size/shape (e.g., "large square table", "small round plate")
   - Material/texture (e.g., "wooden shelf", "glass window", "metal door")

2. **Spatial relationships and positions**:
   - Location (e.g., "book on the shelf", "cup on the table", "person in the corner")
   - Relative positions (e.g., "left side of the image", "center of the room", "right edge")
   - Orientation (e.g., "person facing right", "door opening left", "chair tilted")

3. **Detailed object descriptions**:
   - Specific features (e.g., "person wearing glasses", "book with red cover", "chair with armrests")
   - States/conditions (e.g., "open door", "closed window", "empty cup")
   - Interactions (e.g., "person holding cup", "book placed on shelf")

4. **Spatial context**:
   - Room/space type (e.g., "kitchen", "living room", "office")
   - Layout information (e.g., "countertop in center", "refrigerator on left side")
   - Distance relationships (e.g., "closest to camera", "farthest from door")

Provide a comprehensive but concise description that captures these detailed visual features. Format the output as structured text that can be used to understand spatial relationships and object attributes for VQA (Visual Question Answering) tasks."""
    
    if model == 'openai' or model == 'gpt':
        if not OPENAI_AVAILABLE:
            raise Exception('OpenAI library not installed. Install with: pip install openai')
        if not OPENAI_API_KEY:
            raise Exception('OPENAI_API_KEY is not set')
        
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": [{
                    "type": "text",
                    "text": analysis_prompt
                }, {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }]
            }],
            temperature=0.3,
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()
    
    else:
        raise Exception(f'Unknown model: {model}. Supported models: "openai", "gpt"')

@app.route('/api/analyze_image/<int:index>', methods=['GET'])
def analyze_image(index):
    """Analyze image using GPT-4o to extract detailed features."""
    if index >= len(annotator.image_ids):
        return jsonify({'error': 'Invalid index'}), 400
    
    image_id = annotator.image_ids[index]
    model = request.args.get('model', DEFAULT_MODEL).lower()
    
    # ìºì‹œ í™•ì¸ (ëª¨ë¸ë³„ ìºì‹œ í‚¤)
    cache_key = f"{image_id}_{model}"
    if cache_key in image_analysis_cache:
        return jsonify({
            'success': True,
            'image_id': image_id,
            'analysis': image_analysis_cache[cache_key],
            'cached': True,
            'model': model
        })
    
    try:
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° base64 ë³€í™˜
        image_info = annotator.coco.imgs[image_id]
        
        # Check existing annotations to determine view type
        existing_annotation = None
        for ann in annotator.annotations:
            if ann['image_id'] == image_id:
                existing_annotation = ann
                break
        
        view_type = 'exo'
        if existing_annotation:
            view_type = existing_annotation.get('view', 'exo')
        
        if view_type == 'ego':
            image_path = os.path.join(annotator.ego_images_folder, image_info['file_name'])
        else:
            image_path = os.path.join(annotator.exo_images_folder, image_info['file_name'])
        
        if not os.path.exists(image_path):
            alt_path_exo = os.path.join(annotator.exo_images_folder, image_info['file_name'])
            alt_path_ego = os.path.join(annotator.ego_images_folder, image_info['file_name'])
            if os.path.exists(alt_path_exo):
                image_path = alt_path_exo
            elif os.path.exists(alt_path_ego):
                image_path = alt_path_ego
            else:
                return jsonify({'success': False, 'error': f'Image not found: {image_info["file_name"]}'}), 404
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜ (ë¶„ì„ìš©ìœ¼ë¡œëŠ” ì›ë³¸ í¬ê¸° ì‚¬ìš©, ìµœëŒ€ 1024x1024ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)
        with Image.open(image_path) as img:
            original_width, original_height = img.size
            # Vision APIëŠ” ìµœëŒ€ 20MPê¹Œì§€ ì§€ì›í•˜ì§€ë§Œ, í† í° ì ˆì•½ì„ ìœ„í•´ ë¦¬ì‚¬ì´ì¦ˆ
            max_size = 1024
            if original_width > max_size or original_height > max_size:
                scale = min(max_size/original_width, max_size/original_height)
                new_width = int(original_width * scale)
                new_height = int(original_height * scale)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            buffer = BytesIO()
            img.save(buffer, format='JPEG', quality=85)
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        # ëª¨ë¸ë³„ ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰ (CLIP-2 í†µí•© ì§€ì›)
        analysis_result = analyze_image_with_model(img_base64, model, image_path)
        
        # ìºì‹œì— ì €ì¥ (ëª¨ë¸ë³„ í‚¤ ì‚¬ìš©)
        image_analysis_cache[cache_key] = analysis_result
        
        return jsonify({
            'success': True,
            'image_id': image_id,
            'analysis': analysis_result,
            'cached': False,
            'model': model
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/generate_question_and_choices', methods=['POST'])
def generate_question_and_choices():
    """Generate Korean question and choices using GPT-4o, after image analysis with GPT-4o."""
    data = request.json
    image_id = data.get('image_id', None)
    index = data.get('index', None)
    # ê¸°ë³¸ê°’ì€ DEFAULT_MODEL ì‚¬ìš©
    model = data.get('model', DEFAULT_MODEL).lower()
    
    if image_id is None and index is None:
        return jsonify({'success': False, 'error': 'image_id or index is required'}), 400
    
    try:
        # image_idê°€ ì—†ìœ¼ë©´ indexë¡œ ì°¾ê¸°
        if image_id is None:
            if index >= len(annotator.image_ids):
                return jsonify({'error': 'Invalid index'}), 400
            image_id = annotator.image_ids[index]
        
        # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ (ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©) - ìºì‹œ í™•ì¸ ë˜ëŠ” ì‹¤í–‰
        image_analysis = ""
        image_path = None  # image_path ì´ˆê¸°í™”
        cache_key = f"{image_id}_{model}"
        if cache_key in image_analysis_cache:
            image_analysis = image_analysis_cache[cache_key]
        else:
            # ì´ë¯¸ì§€ ë¶„ì„ API í˜¸ì¶œ (ìºì‹œì— ì—†ìœ¼ë©´ ì‹¤í–‰)
            # index ì°¾ê¸°
            if index is None:
                for idx, img_id in enumerate(annotator.image_ids):
                    if img_id == image_id:
                        index = idx
                        break
                if index is None:
                    return jsonify({'success': False, 'error': 'Image not found'}), 404
            
            # analyze_image í•¨ìˆ˜ ë¡œì§ ì¬ì‚¬ìš©
            image_info = annotator.coco.imgs[image_id]
            existing_annotation = None
            for ann in annotator.annotations:
                if ann['image_id'] == image_id:
                    existing_annotation = ann
                    break
            
            view_type = 'exo'
            if existing_annotation:
                view_type = existing_annotation.get('view', 'exo')
            
            if view_type == 'ego':
                image_path = os.path.join(annotator.ego_images_folder, image_info['file_name'])
            else:
                image_path = os.path.join(annotator.exo_images_folder, image_info['file_name'])
            
            if not os.path.exists(image_path):
                alt_path_exo = os.path.join(annotator.exo_images_folder, image_info['file_name'])
                alt_path_ego = os.path.join(annotator.ego_images_folder, image_info['file_name'])
                if os.path.exists(alt_path_exo):
                    image_path = alt_path_exo
                elif os.path.exists(alt_path_ego):
                    image_path = alt_path_ego
                else:
                    return jsonify({'success': False, 'error': f'Image not found: {image_info["file_name"]}'}), 404
            
            # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰ (GPT-4o-mini)
            with Image.open(image_path) as img:
                original_width, original_height = img.size
                max_size = 1024
                if original_width > max_size or original_height > max_size:
                    scale = min(max_size/original_width, max_size/original_height)
                    new_width = int(original_width * scale)
                    new_height = int(original_height * scale)
                    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                buffer = BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            # ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰
            image_analysis = analyze_image_with_model(img_base64, model, image_path)
            image_analysis_cache[cache_key] = image_analysis
        
        # 2ë‹¨ê³„: COCO ì–´ë…¸í…Œì´ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        ann_ids = annotator.coco.getAnnIds(imgIds=image_id)
        annotations = annotator.coco.loadAnns(ann_ids)
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´ êµ¬ì„±
        category_info = []
        for ann in annotations:
            cid = ann.get('category_id', None)
            name = annotator.category_id_to_name.get(int(cid), 'unknown') if cid is not None else 'unknown'
            bbox = ann.get('bbox', [])
            category_info.append({
                'category_name': name,
                'bbox': bbox
            })
        
        # ì£¼ìš” ê°ì²´ ëª©ë¡ ìƒì„±
        main_objects = list(set([cat['category_name'] for cat in category_info if cat['category_name'] != 'unknown']))[:10]
        
        # 3ë‹¨ê³„: ì§ˆë¬¸ ìƒì„± (OpenAIë§Œ ì‚¬ìš©)
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in config.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # 3-hop ì§ˆë¬¸ ìƒì„±: ATT, POS, RELì´ ëª¨ë‘ í¬í•¨ëœ ë³µì¡í•œ ì§ˆë¬¸
        question_generation_prompt = f"""ì´ë¯¸ì§€ì™€ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ VQA (Visual Question Answering) 3-hop ì§ˆë¬¸ì„ í•œê¸€ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ğŸš¨ **ì ˆëŒ€ í•„ìˆ˜ ê·œì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•¨**:

**STEP 1: ì´ë¯¸ì§€ ë‚´ìš© ì§ì ‘ í™•ì¸ ë° ATT ì†ì„± ê²€ì¦ (ì ˆëŒ€ í•„ìˆ˜)**

ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì§ì ‘ í™•ì¸í•˜ê³ , ì§ˆë¬¸ì— ì‚¬ìš©í•  ATT ì†ì„±ì´ ì‹¤ì œ ì´ë¯¸ì§€ì˜ ê°ì²´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.

ğŸš¨ **CRITICAL - ATT ì†ì„± ì •í™•ì„± ê²€ì¦ (ì ˆëŒ€ í•„ìˆ˜)**:
1. ì§ˆë¬¸ì—ì„œ ì‚¬ìš©í•  ATT ì†ì„±(ì˜ˆ: "ë¹¨ê°„ìƒ‰ ê°ì²´", "ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´", "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´")ì„ ë¨¼ì € ê²°ì •í•˜ì„¸ìš”.
2. ì´ë¯¸ì§€ë¥¼ ì§ì ‘ í™•ì¸í•˜ì—¬ í•´ë‹¹ ATT ì†ì„±ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ë“¤ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
3. ì˜ˆë¥¼ ë“¤ì–´, "í°ìƒ‰ ê°ì²´"ë¼ê³  ì§ˆë¬¸í•˜ë ¤ë©´ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ í°ìƒ‰ ê°ì²´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
4. ì˜ˆë¥¼ ë“¤ì–´, "ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜• ê°ì²´"ë¼ê³  ì§ˆë¬¸í•˜ë ¤ë©´ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜• ê°ì²´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
5. ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì†ì„±ì„ ATTë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤.

**ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ì§ˆë¬¸ì—ì„œ ì‚¬ìš©í•  ATT ì†ì„±ì´ ì‹¤ì œ ì´ë¯¸ì§€ì˜ ê°ì²´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ê°€?
- [ ] ATT ì†ì„±ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì†ì„±ì„ ATTë¡œ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ëŠ”ê°€?

**STEP 2: ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ 3-hop ì§ˆë¬¸ êµ¬ì¡° ìƒì„±**

ğŸš¨ **CRITICAL - ì§ˆë¬¸ ë³µì¡ë„ ë° ê³ ê¸‰ ì¶”ë¡  ìš”êµ¬ì‚¬í•­ (ì ˆëŒ€ í•„ìˆ˜)**:

ê° ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ATT(ì†ì„±), POS(ìœ„ì¹˜), REL(ê´€ê³„) ì„¸ ê°€ì§€ ìš”ì†Œë¥¼ ëª¨ë‘ í¬í•¨í•´ì•¼ í•˜ë©°, **ë‹¨ìˆœí•œ ì§ˆë¬¸ì€ ì ˆëŒ€ ê¸ˆì§€**ì…ë‹ˆë‹¤.

**âŒ ì ˆëŒ€ ê¸ˆì§€ - ë„ˆë¬´ ë‹¨ìˆœí•œ ì§ˆë¬¸ íŒ¨í„´**:
- "X ì˜¤ë¥¸ìª½ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„± ì¡°í•©)
- "X ìœ„ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„± ì¡°í•©)
- "X ì™¼ìª½ì— ìˆëŠ” ê°€ì¥ ë¨¼ Y ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„± ì¡°í•©)

**âœ… ë°˜ë“œì‹œ ì‚¬ìš© - ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸ íŒ¨í„´**:

1. **ì¤‘ì²©ëœ ì¡°ê±´ ì¡°í•©**:
   - "X <POS>ìœ„ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Zë¡œë¶€í„° <REL>ê°€ì¥ ë¨¼</REL> ê°ì²´"
   - "X <POS>ì™¼ìª½ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ì•ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ê°€ê¹Œìš´</REL> ê°ì²´"
   - "<ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ X <POS>ìœ„ì— ìˆëŠ”</POS> Zë¡œë¶€í„° <REL>ê°€ì¥ ë¨¼</REL> ê°ì²´"

2. **ë³µì¡í•œ ê¸°ì¤€ì ê³¼ ëŒ€ìƒì˜ ì¡°í•©**:
   - "X <POS>ìœ„ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT>ë¡œë¶€í„° <REL>ê°€ì¥ ë¨¼</REL> <ATT>Z ê°ì²´</ATT>"
   - "X <POS>ì•ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ì˜†ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ê°€ê¹Œìš´</REL> ê°ì²´"

3. **ì—¬ëŸ¬ ì¡°ê±´ì´ ë™ì‹œì— ì ìš©ë˜ëŠ” ì§ˆë¬¸**:
   - "<ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ X <POS>ìœ„ì—</POS> <REL>ë†“ì—¬ ìˆëŠ”</REL> Z <POS>ì•ì— ìˆëŠ”</POS> ê°ì²´"
   - "<ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ X <POS>ì˜†ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ë†’ì€</REL> ê°ì²´"

4. **ë³µì¡í•œ ê³µê°„ ê´€ê³„**:
   - "X <POS>ì•ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ë°˜ëŒ€í¸ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ë¨¼</REL> ê°ì²´"
   - "X <POS>ì¤‘ì•™ì— ìˆëŠ”</POS> <ATT>Y ê°ì²´</ATT> ì¤‘ì—ì„œ Z <POS>ì˜†ì— ìˆëŠ”</POS> <REL>ê°€ì¥ ê°€ê¹Œìš´</REL> ê°ì²´"

**ATT (ì†ì„±/ëŒ€ìƒ) ê·œì¹™ - CRITICAL: ì†ì„± ê¸°ë°˜ í‘œí˜„ë§Œ ì‚¬ìš©, êµ¬ì²´ì  ëª…ì‚¬ ê¸ˆì§€**:
- âŒ **ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ - êµ¬ì²´ì  ëª…ì‚¬**: "ì»µ", "ì ‘ì‹œ", "ì˜ì", "í…Œì´ë¸”" ë“±
- âœ… **ë°˜ë“œì‹œ ì‚¬ìš© - ì†ì„± ê¸°ë°˜ í‘œí˜„**:
  * "ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´" (ì»µ, ë³‘ ë“±)
  * "ë°ì€ ìƒ‰ìƒì˜ ê°ì²´" (ë°ì€ ìƒ‰ì˜ ë¬¼ì²´ë“¤)
  * "íŒŒí‹°ìš©í’ˆ ê°ì²´" (íŒŒí‹° ê´€ë ¨ ë¬¼ì²´ë“¤)
  * "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´" (ë¨¹ì„ ìˆ˜ ìˆëŠ” ê²ƒë“¤)
  * "ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜• ê°ì²´" (ì‚¬ê°í˜• ëª¨ì–‘)
  * "ë¹¨ê°„ìƒ‰ ê°ì²´", "í°ìƒ‰ ìƒ‰ìƒì˜ ê°ì²´" (ìƒ‰ìƒ ê¸°ë°˜)
  * "ë‚˜ë¬´ ì¬ì§ˆì˜ ê°ì²´" (ì¬ì§ˆ ê¸°ë°˜)

**POS (ìœ„ì¹˜) ê·œì¹™**:
- âŒ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€: "ì´ë¯¸ì§€ ì¤‘ì•™ì—", "ì´ë¯¸ì§€ ì™¼ìª½ì—" (ëª¨í˜¸í•¨)
- âœ… ë°˜ë“œì‹œ ì‚¬ìš©: "í…Œì´ë¸” ì¤‘ì•™ì—", "ì†ŒíŒŒ ì™¼ìª½ì—", "ì‹±í¬ëŒ€ ì˜¤ë¥¸ìª½ì—" (êµ¬ì²´ì  ê°ì²´ ê¸°ì¤€)
- **ìœ„ì¹˜ ë°˜ì „ ê·œì¹™**: ì‹¤ì œë¡œ "ì™¼ìª½"ì— ìˆìœ¼ë©´ ì§ˆë¬¸ì—ì„œëŠ” "ì˜¤ë¥¸ìª½"ìœ¼ë¡œ í‘œí˜„

**REL (ê´€ê³„) ê·œì¹™**:
- "ê°€ì¥ ê°€ê¹Œìš´", "ê°€ì¥ ë¨¼", "ë‘ ë²ˆì§¸ë¡œ ê°€ê¹Œìš´" ë“±

**ğŸš¨ CRITICAL - ì§ˆë¬¸ ë í‘œí˜„ ê·œì¹™ (ì ˆëŒ€ í•„ìˆ˜)**:
ì§ˆë¬¸ì€ ë°˜ë“œì‹œ "~ê°ì²´"ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤. "ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ê°™ì€ ì˜ë¬¸ì‚¬ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

- âŒ **ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€**:
  * "~ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?" (ì‚¬ëŒì„ ë¬»ëŠ” í˜•ì‹ ê¸ˆì§€)
  * "ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" (ëª¨í˜¸í•œ í‘œí˜„ ê¸ˆì§€)
  * "ê°€ì¥ ê°€ê¹Œìš´ ê²ƒì€?" (ATT ì†ì„± ë¯¸ëª…ì‹œ)
  * "ê°€ì¥ ë¨¼ ê²ƒì€?" (ATT ì†ì„± ë¯¸ëª…ì‹œ)
  * "~ê°ì²´ëŠ”?" ("ëŠ”?" ì‚¬ìš© ê¸ˆì§€)
  * "~ê°ì²´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ("ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš© ê¸ˆì§€)
  * "ë¬´ì—‡ì¸ê°€ìš”?" (ATT ì†ì„±ì´ ëª…ì‹œë˜ì§€ ì•Šì€ í˜•ì‹ ê¸ˆì§€)

- âœ… **ë°˜ë“œì‹œ ì‚¬ìš© - "~ê°ì²´"ë¡œ ëë‚˜ëŠ” í˜•ì‹**:
  * "ì •ì‚¬ê°í˜• ë˜ëŠ” ì§ì‚¬ê°í˜•ì˜ ê°ì²´"
  * "ì›í†µí˜• ë˜ëŠ” ì›í˜•ì˜ ê°ì²´"
  * "ë°ì€ ìƒ‰ìƒì˜ ê°ì²´"
  * "ë¬´ì±„ìƒ‰ ê°ì²´"
  * "ê¸ˆì† ì¬ì§ˆì˜ ê°ì²´"
  * "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´"
  * "ë¹¨ê°„ìƒ‰ ê°ì²´"
  * "ë‚˜ë¬´ ì¬ì§ˆì˜ ê°ì²´"

**ì§ˆë¬¸ í˜•ì‹ ì˜ˆì‹œ**:
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ ì›í˜• ë˜ëŠ” ì›í†µí˜•ì˜ ê°ì²´"
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "ì†ŒíŒŒ ì™¼ìª½ì— ìœ„ì¹˜í•œ ë°ì€ ìƒ‰ìƒì˜ ê°ì²´"
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "ì‹±í¬ëŒ€ ì˜¤ë¥¸ìª½ì— ìˆëŠ” ë¬´ì±„ìƒ‰ ê°ì²´"
- âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í¬í¬ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´"
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ì†ŒíŒŒ ì™¼ìª½ì— ìˆëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?" (ì‚¬ëŒì„ ë¬»ëŠ” í˜•ì‹, "ëŠ”?" ì‚¬ìš©)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" (ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš©)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ê°€ì¥ ê°€ê¹Œìš´ ê²ƒì€?" (ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ”?" ì‚¬ìš©)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ëŠ”?" ("ëŠ”?" ì‚¬ìš© ê¸ˆì§€)
- âŒ ì˜ëª»ëœ ì˜ˆì‹œ: "ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ("ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš© ê¸ˆì§€)

**ì¤‘ìš”**: ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ATT ì†ì„±ì„ í¬í•¨í•œ "~ê°ì²´"ë¡œ ëë‚˜ì•¼ í•˜ë©°, "ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ê°™ì€ ì˜ë¬¸ì‚¬ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì§ˆë¬¸ì€ "~ê°ì²´"ë¡œ ëë‚˜ëŠ” ëª…ì‚¬êµ¬ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.

**STEP 3: ì†Œê±°ë²•ì„ ìœ„í•œ ì„ íƒì§€ ì„¤ê³„ ë° ê²€ì¦ (ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬)**

ğŸš¨ **CRITICAL - ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬ë¥¼ ìœ„í•œ ì„ íƒì§€ êµ¬ì„± (ì ˆëŒ€ í•„ìˆ˜)**:
- ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— **ìµœì†Œ 2ê°œ ì´ìƒ** ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
- ì´ë ‡ê²Œ í•´ì•¼ ë‹¤ë¥¸ AIê°€ ë¬¸ì œë¥¼ í’€ ë•Œ ë‹¨ìˆœíˆ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì •ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ê³ , ì¶”ê°€ì ì¸ ì¶”ë¡ (ìœ„ì¹˜, ê±°ë¦¬ ë“±)ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ 1 - ì˜¬ë°”ë¥¸ êµ¬ì„± (ê³ ê¸‰ ì¶”ë¡  ìš”êµ¬)**:
ì§ˆë¬¸: "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´ ì¤‘ì—ì„œ..."
ì„ íƒì§€:
- a: ì¼€ì´í¬ ì¡°ê° (ATT ì¡°ê±´ ë§Œì¡±, í•˜ì§€ë§Œ ë‹¤ë¥¸ ì¡°ê±´ ë¶ˆë§Œì¡±)
- b: ì¼€ì´í¬ ì¡°ê° (ATT ì¡°ê±´ ë§Œì¡±, í•˜ì§€ë§Œ ë‹¤ë¥¸ ì¡°ê±´ ë¶ˆë§Œì¡±) â† ë‹¤ë¥¸ ì¼€ì´í¬ ì¡°ê°
- c: í”¼ì (ATT ì¡°ê±´ ë§Œì¡±, í•˜ì§€ë§Œ ë‹¤ë¥¸ ì¡°ê±´ ë¶ˆë§Œì¡±)
- d: í–„ë²„ê±° (ì •ë‹µ: ATT ì¡°ê±´ ë§Œì¡± + ë‹¤ë¥¸ ëª¨ë“  ì¡°ê±´ ë§Œì¡±)

ì´ ê²½ìš° ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 4ê°œ(a, b, c, d ëª¨ë‘)ì´ë¯€ë¡œ ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ 2 - ì˜ëª»ëœ êµ¬ì„± (ë„ˆë¬´ ì‰¬ì›€)**:
ì§ˆë¬¸: "ì‹ìš© ê°€ëŠ¥í•œ ë¬¼ì²´ ì¤‘ì—ì„œ..."
ì„ íƒì§€:
- a: ì»µ (ATT ì¡°ê±´ ë¶ˆë§Œì¡± - ì‹ìš© ë¶ˆê°€)
- b: ì ‘ì‹œ (ATT ì¡°ê±´ ë¶ˆë§Œì¡± - ì‹ìš© ë¶ˆê°€)
- c: í¬í¬ (ATT ì¡°ê±´ ë¶ˆë§Œì¡± - ì‹ìš© ë¶ˆê°€)
- d: ì¼€ì´í¬ ì¡°ê° (ì •ë‹µ: ATT ì¡°ê±´ ë§Œì¡±)

ì´ ê²½ìš° ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 1ê°œ(dë§Œ)ì´ë¯€ë¡œ ë„ˆë¬´ ì‰½ìŠµë‹ˆë‹¤. âŒ

**ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— ìµœì†Œ 2ê°œ ì´ìƒ ìˆëŠ”ê°€? (ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬)
- [ ] ê° ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë  ìˆ˜ ìˆëŠ”ê°€?
- [ ] ì„ íƒì§€ì— ë™ì¼í•œ ë¬¼ì²´ê°€ ì¤‘ë³µë˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ì„ íƒì§€ì˜ ëª¨ë“  ê°ì²´ê°€ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?

**STEP 4: ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€**

ğŸš¨ **CRITICAL - ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€ (ì ˆëŒ€ í•„ìˆ˜)**:
- ê° ì„ íƒì§€ëŠ” ë°˜ë“œì‹œ **ì„œë¡œ ë‹¤ë¥¸ ê°ì²´ ì¸ìŠ¤í„´ìŠ¤**ë¥¼ ê°€ë¦¬ì¼œì•¼ í•©ë‹ˆë‹¤.
- ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ ê°ì²´ë¼ë„, ì´ë¯¸ì§€ ë‚´ì—ì„œ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤(ë‹¤ë¥¸ bbox)ë¥¼ ê°€ë¦¬ì¼œì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆ: ì´ë¯¸ì§€ì— "ì»µ"ì´ 3ê°œ ìˆì–´ë„, ì„ íƒì§€ì— "ì»µ"ì´ 2ë²ˆ ë‚˜ì˜¤ë©´ ì•ˆ ë©ë‹ˆë‹¤. ê°ê° "ì™¼ìª½ ì»µ", "ì˜¤ë¥¸ìª½ ì»µ", "ì¤‘ì•™ ì»µ" ë“±ìœ¼ë¡œ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤.

**ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼**:
{image_analysis}

**COCO ê°ì²´ ì •ë³´ (bboxë¡œ ì‹ë³„ ê°€ëŠ¥í•œ ê°ì²´ë“¤)**:
- ì£¼ìš” ê°ì²´: {', '.join(main_objects) if main_objects else 'ì—†ìŒ'}
- ì´ ê°ì²´ ìˆ˜: {len(category_info)}
- ê° ê°ì²´ëŠ” ì´ë¯¸ì§€ ë‚´ bboxë¡œ ì •í™•íˆ ì‹ë³„ ê°€ëŠ¥í•¨

**ì¤‘ìš”**: ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì—ì„œ ì–¸ê¸‰ëœ ê°ì²´ë“¤ ì¤‘ì—ì„œ, COCO ì–´ë…¸í…Œì´ì…˜ì— ì¡´ì¬í•˜ëŠ” ê°ì²´ë§Œ ì„ íƒì§€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. ê°™ì€ ì¢…ë¥˜ì˜ ê°ì²´ê°€ ì—¬ëŸ¬ ê°œ ìˆìœ¼ë©´ ìƒ‰ìƒ, ìœ„ì¹˜, ì†ì„± ë“±ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”.

**ğŸš¨ CRITICAL - ì°¸ê³  ì˜ˆì‹œ (exo_data_sample.json, web_annotations_exo.json ìŠ¤íƒ€ì¼)**:

ë‹¤ìŒ ì˜ˆì‹œë“¤ì„ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ **ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ** ì§ˆë¬¸ê³¼ ì„ íƒì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”:

**ì˜ˆì‹œ 1** (exo_data_sample.json - ë³µì¡í•œ ì¡°ê±´ ì¡°í•©):
- ì§ˆë¬¸: "Which <ATT>edible food item</ATT> is the <REL>farthest</REL> from the fork <POS>on the left side of</POS> the table?"
- ì„ íƒì§€: (a) glass, (b) potato fries, (c) hamburger, (d) cell phone
- ê·¼ê±°: cell phoneì€ ì‹ìš© ë¶ˆê°€ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), glassë„ ì‹ìš© ë¶ˆê°€ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), potato friesëŠ” hamburgerë³´ë‹¤ ê°€ê¹Œì›€ (REL ì¡°ê±´ ë¶ˆë§Œì¡±), ë”°ë¼ì„œ hamburgerê°€ ì •ë‹µ
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´ + POS ì¡°ê±´ + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 2ê°œ(b, c) ìˆì–´ì„œ ë‹¨ìˆœíˆ ATTë§Œ í™•ì¸í•´ì„œëŠ” ì•ˆ ë¨

**ì˜ˆì‹œ 2** (exo_data_sample.json - ì¤‘ì²©ëœ ê³µê°„ ê´€ê³„):
- ì§ˆë¬¸: "Which <ATT>round and cylindrical object</ATT> is <REL>farthest</REL> from the person sitting <POS>on the right side of</POS> the dining table?"
- ì„ íƒì§€: (a) plate, (b) white cake, (c) rightmost coke, (d) vase
- ê·¼ê±°: plate, white cake, rightmost cokeëŠ” ëª¨ë‘ ê°€ê¹Œìš´ í¸ì´ì§€ë§Œ, vaseëŠ” í…Œì´ë¸” ë°˜ëŒ€í¸ì— ìœ„ì¹˜í•˜ì—¬ ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìŒ
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´ + POS ì¡°ê±´(ì‚¬ëŒì˜ ìœ„ì¹˜) + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 4ê°œ(a, b, c, d ëª¨ë‘) ìˆì–´ì„œ ê±°ë¦¬ ê³„ì‚°ì´ í•„ìš”í•¨

**ì˜ˆì‹œ 3** (exo_data_sample.json - ì—¬ëŸ¬ ì¡°ê±´ ë™ì‹œ ì ìš©):
- ì§ˆë¬¸: "Which <ATT>square-shaped item</ATT> is <REL>placed on the floor</REL> <POS>in front of</POS> the brown-haired man sitting on the sofa?"
- ì„ íƒì§€: (a) handbag, (b) coke, (c) laptop, (d) cell phone
- ê·¼ê±°: laptopê³¼ cell phoneì€ ì†ŒíŒŒ ìœ„ì— ìˆìŒ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), cokeëŠ” ì›í†µí˜•ì´ë¯€ë¡œ ì œì™¸ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), handbagë§Œ ë°”ë‹¥ì— ìˆê³  ì‚¬ê°í˜• ëª¨ì–‘ (ëª¨ë“  ì¡°ê±´ ë§Œì¡±)
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´ + REL ì¡°ê±´(ìœ„ì¹˜ ìƒíƒœ) + POS ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ê° ì„ íƒì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë¨ (ìœ„ì¹˜, í˜•íƒœ ë“±)

**ì˜ˆì‹œ 4** (web_annotations_exo.json - ë³µì¡í•œ ê¸°ì¤€ì ):
- ì§ˆë¬¸: "Which object is <REL>farthest</REL> from the <ATT>white object</ATT> <POS>on the left side of</POS> the child wearing a striped shirt in the center?"
- ì„ íƒì§€: (a) keyboard, (b) piano, (c) sofa, (d) plant
- ê·¼ê±°: sofaëŠ” ì•„ì´ ì˜¤ë¥¸ìª½ì— ìˆìŒ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), keyboardì™€ pianoëŠ” ë” ê°€ê¹Œì›€ (REL ì¡°ê±´ ë¶ˆë§Œì¡±), plantê°€ ê°€ì¥ ë©€ë¦¬ ìˆìŒ
- âœ… **ë³µì¡ë„**: ê¸°ì¤€ì ì´ "í°ìƒ‰ ê°ì²´"ì´ê³ , ê·¸ ê°ì²´ì˜ ìœ„ì¹˜ê°€ "ì•„ì´ ì™¼ìª½"ì´ë¼ëŠ” ì¤‘ì²©ëœ ì¡°ê±´
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ê¸°ì¤€ì ì„ ë¨¼ì € ì°¾ê³ , ê·¸ ê¸°ì¤€ì ìœ¼ë¡œë¶€í„° ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì•¼ í•¨

**ì˜ˆì‹œ 5** (web_annotations_exo.json - ë³µì¡í•œ ì†ì„± ì¡°í•©):
- ì§ˆë¬¸: "Which <ATT>object that can hold water</ATT> is the <REL>closest</REL> to the pizza placed in front of the woman <POS>on the left</POS>?"
- ì„ íƒì§€: (a) fork, (b) empty glass, (c) blue vase, (d) water glass
- ê·¼ê±°: forkëŠ” ë¬¼ì„ ë‹´ì„ ìˆ˜ ì—†ìŒ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), blue vaseì™€ water glassëŠ” ì˜¤ë¥¸ìª½ ì—¬ìì—ê²Œ ë” ê°€ê¹Œì›€ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), empty glassê°€ ì™¼ìª½ ì—¬ì ì• í”¼ìì— ê°€ì¥ ê°€ê¹Œì›€
- âœ… **ë³µì¡ë„**: ATT ì¡°ê±´(ê¸°ëŠ¥ì  ì†ì„±) + POS ì¡°ê±´(ì—¬ìì˜ ìœ„ì¹˜) + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ 3ê°œ(b, c, d) ìˆì–´ì„œ ìœ„ì¹˜ì™€ ê±°ë¦¬ë¥¼ ëª¨ë‘ ê³ ë ¤í•´ì•¼ í•¨

**ì˜ˆì‹œ 6** (web_annotations_exo.json - ë³µì¡í•œ ê³µê°„ ê´€ê³„):
- ì§ˆë¬¸: "Which object <REL>farthest</REL> from the window <POS>on the table</POS> among the <ATT>square or rectangular objects</ATT>?"
- ì„ íƒì§€: (a) backpack, (b) laptop, (c) beige book, (d) blue bowl
- ê·¼ê±°: backpackì€ í…Œì´ë¸” ìœ„ì— ì—†ìŒ (POS ì¡°ê±´ ë¶ˆë§Œì¡±), blue bowlì€ ì‚¬ê°í˜•ì´ ì•„ë‹˜ (ATT ì¡°ê±´ ë¶ˆë§Œì¡±), laptopì€ beige bookë³´ë‹¤ ì°½ë¬¸ì— ê°€ê¹Œì›€ (REL ì¡°ê±´ ë¶ˆë§Œì¡±), beige bookì´ ê°€ì¥ ë©€ë¦¬ ìˆìŒ
- âœ… **ë³µì¡ë„**: POS ì¡°ê±´ + ATT ì¡°ê±´ + REL ì¡°ê±´ì´ ëª¨ë‘ ì ìš©ë¨
- âœ… **ê³ ê¸‰ ì¶”ë¡ **: ê° ì„ íƒì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë˜ê³ , ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ ì¤‘ì—ì„œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì•¼ í•¨

**ğŸš¨ CRITICAL - ì„ íƒì§€ êµ¬ì„± ì›ì¹™ (ì ˆëŒ€ í•„ìˆ˜)**:

1. **ë‹¤ì–‘í•œ ì œì™¸ ì´ìœ **: ê° ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:
   - ATT ì¡°ê±´ ë¶ˆë§Œì¡± (ì†ì„±, í˜•íƒœ, ìƒ‰ìƒ ë“±)
   - POS ì¡°ê±´ ë¶ˆë§Œì¡± (ìœ„ì¹˜, ê³µê°„ ê´€ê³„ ë“±)
   - REL ì¡°ê±´ ë¶ˆë§Œì¡± (ê±°ë¦¬, ìˆœì„œ ë“±)
   - ì—¬ëŸ¬ ì¡°ê±´ ë™ì‹œ ë¶ˆë§Œì¡±

2. **ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ**: ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— ìµœì†Œ 2ê°œ ì´ìƒ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•´ì•¼ ë‹¨ìˆœíˆ ATT ì¡°ê±´ë§Œ í™•ì¸í•´ì„œëŠ” ì •ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ê³ , ì¶”ê°€ì ì¸ ì¶”ë¡ (POS, REL)ì´ í•„ìš”í•©ë‹ˆë‹¤.

3. **ì„ íƒì§€ ë‹¤ì–‘ì„±**: ì„ íƒì§€ëŠ” ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì™€ ì†ì„±ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
   - âŒ ë‚˜ìœ ì˜ˆ: "ë°ì€ ìƒ‰ìƒì˜ ì˜ì", "ë°ì€ ìƒ‰ìƒì˜ ë²¤ì¹˜", "ë°ì€ ìƒ‰ìƒì˜ ì‹íƒ", "ë°ì€ ìƒ‰ìƒì˜ ì“°ë ˆê¸°í†µ" (ëª¨ë‘ ê°™ì€ ì†ì„±)
   - âœ… ì¢‹ì€ ì˜ˆ: "glass", "potato fries", "hamburger", "cell phone" (ë‹¤ì–‘í•œ ì†ì„±ê³¼ ì¹´í…Œê³ ë¦¬)

**ì¤‘ìš”**: ìœ„ ì˜ˆì‹œë“¤ì„ ì°¸ê³ í•˜ì—¬:
1. **ë³µì¡í•œ ì§ˆë¬¸ êµ¬ì¡°**: ë‹¨ìˆœí•œ "X ì˜¤ë¥¸ìª½ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" í˜•ì‹ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
2. **ì¤‘ì²©ëœ ì¡°ê±´**: ì—¬ëŸ¬ ì¡°ê±´ì´ ë™ì‹œì— ì ìš©ë˜ëŠ” ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”
3. **ë‹¤ì–‘í•œ ì œì™¸ ì´ìœ **: ê° ì„ íƒì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë˜ë„ë¡ êµ¬ì„±í•˜ì„¸ìš”
4. **ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ**: ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•˜ë„ë¡ ì„ íƒì§€ë¥¼ êµ¬ì„±í•˜ì„¸ìš”

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ, ì •í™•íˆ 3ê°œë§Œ ìƒì„±)**:

ğŸš¨ **CRITICAL**: ëª¨ë“  ì§ˆë¬¸ì€ ë°˜ë“œì‹œ "~ê°ì²´"ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤. "ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ê°™ì€ ì˜ë¬¸ì‚¬ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "questions": [
    {{
      "question": "ì²« ë²ˆì§¸ 3-hop í•œê¸€ ì§ˆë¬¸ (ATTëŠ” ì†ì„± ê¸°ë°˜ í‘œí˜„, POSëŠ” êµ¬ì²´ì  ê°ì²´ ê¸°ì¤€, REL í¬í•¨, ì†Œê±°ë²• ê°€ëŠ¥í•œ ì„ íƒì§€ êµ¬ì„±, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ, ë°˜ë“œì‹œ '~ê°ì²´'ë¡œ ëë‚¨, 'ëŠ”?' ë˜ëŠ” 'ëŠ” ë¬´ì—‡ì¸ê°€ìš”?' ì‚¬ìš© ê¸ˆì§€)",
      "choices": {{
        "a": "ì„ íƒì§€ a (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "b": "ì„ íƒì§€ b (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "c": "ì„ íƒì§€ c (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "d": "ì„ íƒì§€ d (í•œê¸€, ì •ë‹µ, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ì¤‘ í•˜ë‚˜)"
      }},
      "correct_answer": "a"
    }},
    {{
      "question": "ë‘ ë²ˆì§¸ 3-hop í•œê¸€ ì§ˆë¬¸ (ì²« ë²ˆì§¸ì™€ ë‹¤ë¥¸ êµ¬ì¡°/ì¡°í•©, ATTëŠ” ì†ì„± ê¸°ë°˜ í‘œí˜„, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ, ë°˜ë“œì‹œ '~ê°ì²´'ë¡œ ëë‚¨, 'ëŠ”?' ë˜ëŠ” 'ëŠ” ë¬´ì—‡ì¸ê°€ìš”?' ì‚¬ìš© ê¸ˆì§€)",
      "choices": {{
        "a": "ì„ íƒì§€ a (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "b": "ì„ íƒì§€ b (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "c": "ì„ íƒì§€ c (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "d": "ì„ íƒì§€ d (í•œê¸€, ì •ë‹µ, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ì¤‘ í•˜ë‚˜)"
      }},
      "correct_answer": "b"
    }},
    {{
      "question": "ì„¸ ë²ˆì§¸ 3-hop í•œê¸€ ì§ˆë¬¸ (ì•ì˜ ë‘ ì§ˆë¬¸ê³¼ ë‹¤ë¥¸ êµ¬ì¡°/ì¡°í•©, ATTëŠ” ì†ì„± ê¸°ë°˜ í‘œí˜„, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ìµœì†Œ 2ê°œ ì´ìƒ, ë°˜ë“œì‹œ '~ê°ì²´'ë¡œ ëë‚¨, 'ëŠ”?' ë˜ëŠ” 'ëŠ” ë¬´ì—‡ì¸ê°€ìš”?' ì‚¬ìš© ê¸ˆì§€)",
      "choices": {{
        "a": "ì„ íƒì§€ a (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "b": "ì„ íƒì§€ b (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "c": "ì„ íƒì§€ c (í•œê¸€, ì†Œê±° ê°€ëŠ¥í•œ ì´ìœ ê°€ ëª…í™•í•´ì•¼ í•¨, ë™ì¼ ë¬¼ì²´ ì¤‘ë³µ ê¸ˆì§€)",
        "d": "ì„ íƒì§€ d (í•œê¸€, ì •ë‹µ, ATT ì¡°ê±´ ë§Œì¡± ê°ì²´ ì¤‘ í•˜ë‚˜)"
      }},
      "correct_answer": "c"
    }}
  ]
}}

**ì§ˆë¬¸ í˜•ì‹ ì˜ˆì‹œ (ë°˜ë“œì‹œ ì°¸ê³ )**:

**âŒ ì ˆëŒ€ ê¸ˆì§€ - ë„ˆë¬´ ë‹¨ìˆœí•œ ì§ˆë¬¸**:
- "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ ì›í˜• ë˜ëŠ” ì›í†µí˜•ì˜ ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„±)
- "ì†ŒíŒŒ ì™¼ìª½ì— ìœ„ì¹˜í•œ ë°ì€ ìƒ‰ìƒì˜ ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„±)
- "ì‹±í¬ëŒ€ ì˜¤ë¥¸ìª½ì— ìˆëŠ” ë¬´ì±„ìƒ‰ ê°ì²´" (ë‹¨ìˆœ ìœ„ì¹˜+ì†ì„±)
- "ì†ŒíŒŒ ì™¼ìª½ì— ìˆëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?" (ê¸ˆì§€ - "ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?" ì‚¬ìš©)
- "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" (ê¸ˆì§€ - ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" ì‚¬ìš©)
- "ê°€ì¥ ê°€ê¹Œìš´ ê²ƒì€?" (ê¸ˆì§€ - ATT ì†ì„± ë¯¸ëª…ì‹œ, "ëŠ”?" ì‚¬ìš©)

**âœ… ë°˜ë“œì‹œ ì‚¬ìš© - ë³µì¡í•˜ê³  ê³ ê¸‰ ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸**:
- "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í¬í¬ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´" (ATT + REL + ê¸°ì¤€ì )
- "í…Œì´ë¸” ìœ„ì— ìˆëŠ” ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´ ì¤‘ì—ì„œ ì‚¬ëŒìœ¼ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´" (POS + ATT + REL)
- "ì†ŒíŒŒ ì™¼ìª½ì— ìˆëŠ” ë°ì€ ìƒ‰ìƒì˜ ê°ì²´ ì¤‘ì—ì„œ ì°½ë¬¸ìœ¼ë¡œë¶€í„° ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´" (POS + ATT + REL)
- "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í¬í¬ ì™¼ìª½ì— ìˆëŠ” ê°€ì¥ ë¨¼ ê°ì²´" (ATT + POS + REL)
- "í…Œì´ë¸” ì¤‘ì•™ì— ìˆëŠ” ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´ ì¤‘ì—ì„œ ì‚¬ëŒ ì•ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´" (POS + ATT + POS + REL)
- "ì‹ìš© ê°€ëŠ¥í•œ ê°ì²´ ì¤‘ì—ì„œ í…Œì´ë¸” ì™¼ìª½ì— ìˆëŠ” í¬í¬ë¡œë¶€í„° ê°€ì¥ ë¨¼ ê°ì²´" (ATT + POS + REL)

ğŸš¨ **ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìƒì„± ì „ ë°˜ë“œì‹œ í™•ì¸)**:

**ì§ˆë¬¸ ë³µì¡ë„ ê²€ì¦**:
- [ ] ì§ˆë¬¸ì´ ë‹¨ìˆœí•œ "X ì˜¤ë¥¸ìª½ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ Y ê°ì²´" í˜•ì‹ì´ ì•„ë‹Œê°€? (ì´ëŸ° í˜•ì‹ì€ ì ˆëŒ€ ê¸ˆì§€)
- [ ] ì§ˆë¬¸ì— ì¤‘ì²©ëœ ì¡°ê±´ì´ë‚˜ ë³µì¡í•œ ê³µê°„ ê´€ê³„ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
- [ ] ê° ì§ˆë¬¸ì— ATT, POS, RELì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆê³ , ì„œë¡œ ë³µì¡í•˜ê²Œ ì–½í˜€ìˆëŠ”ê°€?

**ì§ˆë¬¸ í˜•ì‹ ê²€ì¦**:
- [ ] **CRITICAL**: ì§ˆë¬¸ì´ "~ê°ì²´"ë¡œ ëë‚˜ëŠ”ê°€? ("ëŠ”?", "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "~ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?", "ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?" í˜•ì‹ ê¸ˆì§€)
- [ ] ATT íƒœê·¸ì— êµ¬ì²´ì  ëª…ì‚¬("ì»µ", "ì ‘ì‹œ" ë“±)ê°€ ì•„ë‹Œ ì†ì„± ê¸°ë°˜ í‘œí˜„("ì›í˜• ë˜ëŠ” ì›í†µí˜• ê°ì²´" ë“±)ì„ ì‚¬ìš©í–ˆëŠ”ê°€?
- [ ] ATT ì†ì„±ì´ ì‹¤ì œ ì´ë¯¸ì§€ì˜ ê°ì²´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ê°€?
- [ ] POS í‘œí˜„ì´ êµ¬ì²´ì  ê°ì²´ ê¸°ì¤€ì¸ê°€? ("ì´ë¯¸ì§€ ì¤‘ì•™" ëŒ€ì‹  "í…Œì´ë¸” ì¤‘ì•™" ë“±)
- [ ] ìœ„ì¹˜ ë°˜ì „ ê·œì¹™ì„ ì ìš©í–ˆëŠ”ê°€? (ì‹¤ì œ ì™¼ìª½ â†’ ì§ˆë¬¸ì—ì„œëŠ” ì˜¤ë¥¸ìª½)

**ì„ íƒì§€ êµ¬ì„± ê²€ì¦**:
- [ ] ì§ˆë¬¸ì˜ ATT ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê°ì²´ê°€ ì„ íƒì§€ì— ìµœì†Œ 2ê°œ ì´ìƒ ìˆëŠ”ê°€? (ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ ìš”êµ¬)
- [ ] ê° ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì´ìœ ë¡œ ì œì™¸ë  ìˆ˜ ìˆëŠ”ê°€? (ATT ë¶ˆë§Œì¡±, POS ë¶ˆë§Œì¡±, REL ë¶ˆë§Œì¡± ë“±)
- [ ] ì„ íƒì§€ì— ë™ì¼í•œ ë¬¼ì²´ê°€ ì¤‘ë³µë˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ì„ íƒì§€ì˜ ëª¨ë“  ê°ì²´ê°€ ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] ì„ íƒì§€ê°€ ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì™€ ì†ì„±ì„ í¬í•¨í•˜ê³  ìˆëŠ”ê°€? (ëª¨ë‘ ê°™ì€ ì†ì„±ì˜ ê°ì²´ê°€ ì•„ë‹Œê°€?)

**ì¤‘ìš”**: ì •í™•íˆ 3ê°œì˜ ì§ˆë¬¸ë§Œ ìƒì„±í•˜ê³ , ê° ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ìœ„ì˜ ëª¨ë“  ê·œì¹™ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""

        # RateLimitError ì²˜ë¦¬: ì¬ì‹œë„ ë¡œì§ í¬í•¨
        max_retries = 5
        retry_delay = 1  # ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        
        generation_response = None
        generated_content = None
        
        for attempt in range(max_retries):
            try:
                generation_response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {
                            "role": "system",
                            "content": "You are an expert VQA question generator specializing in complex, multi-hop reasoning questions. CRITICAL RULES: 1) Each question MUST include ATT (attribute), POS (position), REL (relationship) in a COMPLEX, INTERWOVEN manner - NOT simple patterns like 'X right side, closest Y object'. 2) Questions MUST require advanced reasoning with nested conditions, multiple spatial relationships, or complex attribute combinations. 3) Use ONLY objects that actually exist in the image. 4) Choices must be clearly distinguishable and diverse (use color, position: 'red cup', 'leftmost chair'). 5) For POS, use specific object references ('center of table', NOT 'center of image'). 6) Reverse left/right positions in questions. 7) Use ONLY objective attributes (color, shape, material) - NEVER subjective ('small', 'pretty'). 8) Ask about concrete objects, NOT abstract properties. 9) At least 2 choices MUST satisfy the ATT condition to require advanced reasoning. 10) Each choice should be excluded for DIFFERENT reasons (ATT failure, POS failure, REL failure, etc.). 11) Generate exactly 3 questions with DIFFERENT complex structures. Return valid JSON."
                        },
                        {
                            "role": "user",
                            "content": question_generation_prompt
                        }
                    ],
                    temperature=0.5,
                    max_tokens=2000,
                    response_format={"type": "json_object"}
                )
                
                generated_content = generation_response.choices[0].message.content.strip()
                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
                
            except RateLimitError as e:
                if attempt < max_retries - 1:
                    # retry_after ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ exponential backoff
                    wait_time = getattr(e, 'retry_after', None)
                    if wait_time is None:
                        wait_time = retry_delay * (2 ** attempt)  # exponential backoff
                    else:
                        wait_time = float(wait_time) + 1  # retry_afterì— 1ì´ˆ ì¶”ê°€ ì—¬ìœ 
                    
                    print(f"[WARN] Rate limit reached. Waiting {wait_time:.2f} seconds before retry {attempt + 1}/{max_retries}...")
                    import time
                    time.sleep(wait_time)
                    continue
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ ë°˜í™˜
                    return jsonify({
                        'success': False,
                        'error': f'Rate limit exceeded after {max_retries} retries. Please try again later or reduce parallel workers.'
                    }), 429
            except Exception as e:
                # RateLimitErrorê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ë°˜í™˜
                import traceback
                traceback.print_exc()
                return jsonify({'success': False, 'error': f'OpenAI question generation failed: {str(e)}'}), 500
        
        if generated_content is None:
            return jsonify({
                'success': False,
                'error': 'Failed to generate questions after retries'
            }), 500
        
        # JSON íŒŒì‹±
        try:
            import json
            generated_data = json.loads(generated_content)
            questions = generated_data.get('questions', [])
            
            if not questions:
                return jsonify({'success': False, 'error': 'No questions generated'}), 500
            
            # ì •í™•íˆ 3ê°œë§Œ ë°˜í™˜ (ë” ë§ìœ¼ë©´ ì•ì˜ 3ê°œë§Œ)
            if len(questions) > 3:
                questions = questions[:3]
            elif len(questions) < 3:
                return jsonify({'success': False, 'error': f'Expected 3 questions but got {len(questions)}'}), 500
            
            return jsonify({
                'success': True,
                'image_id': image_id,
                'questions': questions
            })
        except json.JSONDecodeError as e:
            return jsonify({'success': False, 'error': f'Failed to parse JSON: {str(e)}', 'raw_response': generated_content}), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'OpenAI question generation failed: {str(e)}'}), 500

@app.route('/api/translate/question_and_choices', methods=['POST'])
def translate_question_and_choices():
    """Translate Korean question and choices to English together using GPT-5, with image analysis context."""
    data = request.json
    question_ko = data.get('question_ko', '').strip()
    choice_a = data.get('choice_a', '').strip()
    choice_b = data.get('choice_b', '').strip()
    choice_c = data.get('choice_c', '').strip()
    choice_d = data.get('choice_d', '').strip()
    image_id = data.get('image_id', None)  # ì´ë¯¸ì§€ ID ì¶”ê°€
    
    if not question_ko:
        return jsonify({'success': False, 'error': 'Question (Korean) is required'}), 400
    
    if not all([choice_a, choice_b, choice_c, choice_d]):
        return jsonify({'success': False, 'error': 'All choices are required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ìºì‹œì—ì„œë§Œ í™•ì¸)
        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì´ë¯¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìºì‹œë§Œ í™•ì¸
        # ìºì‹œ í‚¤ëŠ” "image_id_model" í˜•ì‹ì´ë¯€ë¡œ ëª¨ë“  ëª¨ë¸ì˜ ìºì‹œë¥¼ í™•ì¸
        image_analysis = ""
        if image_id:
            # ê¸°ë³¸ ëª¨ë¸ë¶€í„° í™•ì¸
            for model_name in [DEFAULT_MODEL, 'openai']:
                cache_key = f"{image_id}_{model_name}"
                if cache_key in image_analysis_cache:
                    image_analysis = image_analysis_cache[cache_key]
                    break
        
        # Questionê³¼ Choicesë¥¼ í•¨ê»˜ ë²ˆì—­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ (ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í¬í•¨)
        image_context = ""
        if image_analysis:
            image_context = f"""

IMAGE ANALYSIS CONTEXT:
{image_analysis}

Use this image analysis to better understand the context and spatial relationships mentioned in the Korean question. The analysis includes detailed features like colors, positions, orientations, and spatial relationships of objects in the image. Use this information to create more accurate <ATT>, <POS>, and <REL> tags that match the actual visual content."""
        
        prompt = f"""Translate the following Korean question and multiple choice options to English. You MUST follow this EXACT format:{image_context}

CORRECT FORMAT:
[Question with <ATT>, <POS>, <REL> tags embedded naturally in the sentence] <choice>(a) option1, (b) option2, (c) option3, (d) option4</choice> And provide the bounding box coordinate of the region related to your answer.

CRITICAL TAG USAGE RULES:

1. <REL> tag - Use ONLY for RELATIONSHIP terms (distance, order, placement):
   - Examples: "farthest", "closest", "second-closest", "placed on the floor"
   - DO NOT use for objects or locations
   - CORRECT: "Which object is <REL>farthest</REL> from..."
   - WRONG: "<REL>flag in the center</REL>" (this should be <POS>)

2. <POS> tag - Use ONLY for POSITION/LOCATION information:
   - Examples: "in the center", "on the left side of", "in front of", "to the left side", "on the right side", "around the dining table"
   - DO NOT use for object attributes or relationships
   - CORRECT: "...flag <POS>in the center of the table</POS>"
   - WRONG: "<POS>in the image</POS>" (too generic, not meaningful)
   - WRONG: "<ATT>flag in the center of the table</ATT>" (location info should be <POS>)

3. <ATT> tag - Use ONLY for ATTRIBUTES or TARGET GROUPS:
   - Examples: "red object", "square-shaped item", "among the items", "among the visible people", "edible food item", "object that can hold water", "non-edible item"
   - Use for describing WHAT object/group is being asked about
   - CORRECT: "Which <ATT>red object</ATT> is..."
   - CORRECT: "<ATT>Among the items</ATT> on the table..."
   - WRONG: "<ATT>flag in the center of the table</ATT>" (contains location, should split: flag <POS>in the center of the table</POS>)

4. GENERAL RULES:
   - Tags MUST contain actual meaningful content (NOT empty like <ATT></ATT>)
   - Tags should be embedded naturally within the question sentence, not at the end
   - The <choice> tag MUST come BEFORE "And provide..." phrase
   - DO NOT use generic phrases like "in the image" for <POS> tag
   - If a phrase contains both attribute and location, split them appropriately

Reference examples from exo_data_sample.json:

Example 1: "<REL>Second-closest</REL> to the refrigerator a countertop located <POS>in the center</POS> of the image, which object is it <ATT>among the items</ATT>? <choice>(a) sink, (b) vase, (c) orange bag, (d) rightmost red chair</choice> And provide the bounding box coordinate of the region related to your answer."

Example 2: "Which <ATT>square-shaped item</ATT> is <REL>placed on the floor</REL> <POS>in front of</POS> the brown-haired man sitting on the sofa? <choice>(a) handbag, (b) coke, (c) laptop, (d) cell phone</choice> And provide the bounding box coordinate of the region related to your answer."

Example 3: "Which <ATT>round and cylindrical object</ATT> is <REL>farthest</REL> from the person sitting <POS>on the right side of</POS> the dining table? <choice>(a) plate, (b) white cake, (c) rightmost coke, (d) vase</choice> And provide the bounding box coordinate of the region related to your answer."

Example 4: "Which <ATT>edible food item</ATT> is the <REL>farthest</REL> from the fork <POS>on the left side of</POS> the table? <choice>(a) glass, (b) potato fries, (c) hamburger, (d) cell phone</choice> And provide the bounding box coordinate of the region related to your answer."

Korean question: {question_ko}

Korean choices:
(a) {choice_a}
(b) {choice_b}
(c) {choice_c}
(d) {choice_d}

CRITICAL - Choice Translation Format:
- Use concise, intuitive adjective+noun or noun+noun format (NOT full sentences)
- Examples:
  * "a person in a black shirt" â†’ "black shirt person"
  * "a person wearing glasses" â†’ "glasses person"
  * "a cup on the table" â†’ "table cup" or "cup"
  * "a red chair" â†’ "red chair"
  * "a man with a blue t-shirt" â†’ "blue t-shirt man"
- DO NOT use full sentences like "a person who is wearing a black shirt"
- DO NOT use articles "a" or "the" unless necessary
- Keep choices short and intuitive

Translate the Korean question and choices to English following the EXACT format above. Make sure:
- <REL> is used ONLY for relationship terms (farthest, closest, etc.)
- <POS> is used ONLY for position/location information (in the center, on the left side, etc.)
- <ATT> is used ONLY for attributes or target groups (red object, among the items, etc.)
- All tags have meaningful content inside them
- Tags are naturally embedded in the question sentence
- <choice> tag comes before "And provide..." phrase
- DO NOT use generic phrases like "in the image" for <POS> tag
- Choices are in concise adjective+noun or noun+noun format"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a professional translator specializing in VQA (Visual Question Answering) questions. CRITICAL RULES: 1) <REL> tag ONLY for relationship terms (farthest, closest, etc.), 2) <POS> tag ONLY for position/location (in the center, on the left side, etc.), 3) <ATT> tag ONLY for attributes/target groups (red object, among the items, etc.), 4) Tags MUST contain actual meaningful content, 5) Format: [Question with tags] <choice>...</choice> And provide... (choice tag BEFORE 'And provide' phrase), 6) DO NOT use generic phrases like 'in the image' for <POS> tag, 7) Choices MUST be in concise adjective+noun or noun+noun format (e.g., 'black shirt person', 'glasses person'), NOT full sentences."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        translated_question = response.choices[0].message.content.strip()
        
        # íƒœê·¸ ê²€ì¦ - ë¹ˆ íƒœê·¸ í™•ì¸ (ë‚´ìš©ì´ ìˆëŠ” íƒœê·¸ë§Œ ìœ íš¨)
        has_valid_att = bool(re.search(r'<ATT>[^<]+</ATT>', translated_question, re.IGNORECASE))
        has_valid_pos = bool(re.search(r'<POS>[^<]+</POS>', translated_question, re.IGNORECASE))
        has_valid_rel = bool(re.search(r'<REL>[^<]+</REL>', translated_question, re.IGNORECASE))
        
        if not (has_valid_att or has_valid_pos or has_valid_rel):
            return jsonify({'success': False, 'error': 'Translation must include at least one of <ATT>, <POS>, or <REL> tags with actual content inside them'}), 400
        
        if '<choice>' not in translated_question:
            return jsonify({'success': False, 'error': 'Translation must include <choice> tag'}), 400
        
        # "And provide..." ë¬¸êµ¬ê°€ <choice> íƒœê·¸ ë’¤ì— ìˆëŠ”ì§€ í™•ì¸
        choice_match = re.search(r'<choice>.*?</choice>', translated_question, re.IGNORECASE | re.DOTALL)
        if choice_match:
            choice_end_pos = choice_match.end()
            if 'And provide the bounding box coordinate of the region related to your answer.' not in translated_question[choice_end_pos:]:
                return jsonify({'success': False, 'error': 'The phrase "And provide the bounding box coordinate..." must come AFTER the <choice> tag'}), 400
        else:
            if 'And provide the bounding box coordinate of the region related to your answer.' not in translated_question:
                return jsonify({'success': False, 'error': 'Translation must include the required ending phrase'}), 400
        
        # <choice> íƒœê·¸ì—ì„œ ê° ì„ íƒì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        choice_match = re.search(r'<choice>(.*?)</choice>', translated_question, re.IGNORECASE)
        choice_texts = {}
        if choice_match:
            choice_content = choice_match.group(1)
            for letter in ['a', 'b', 'c', 'd']:
                pattern = rf'\({letter}\)\s*([^,)]+)'
                match = re.search(pattern, choice_content, re.IGNORECASE)
                if match:
                    choice_texts[letter] = match.group(1).strip()
        
        # ë²ˆì—­ ê²°ê³¼ì—ì„œ ì•ë’¤ ëŒ€ê´„í˜¸ ì œê±°
        cleaned_question = translated_question.strip()
        # ì•ì˜ ëŒ€ê´„í˜¸ ì œê±° (ì˜ˆ: "[Question text..." -> "Question text...")
        if cleaned_question.startswith('[') and cleaned_question.endswith(']'):
            # ì „ì²´ê°€ ëŒ€ê´„í˜¸ë¡œ ê°ì‹¸ì ¸ ìˆëŠ” ê²½ìš°ë§Œ ì œê±°
            cleaned_question = cleaned_question[1:-1].strip()
        elif cleaned_question.startswith('['):
            # ì•ì—ë§Œ ëŒ€ê´„í˜¸ê°€ ìˆëŠ” ê²½ìš° ì œê±°
            cleaned_question = re.sub(r'^\[+\s*', '', cleaned_question).strip()
        
        # "?" ë’¤ì˜ "]" ì œê±°
        cleaned_question = re.sub(r'\?\s*\]+\s*', '? ', cleaned_question)
        # ë¬¸ì¥ ëì˜ "]" ì œê±° (choice íƒœê·¸ ì•)
        cleaned_question = re.sub(r'\]+\s*(?=<choice>)', ' ', cleaned_question, flags=re.IGNORECASE)
        
        return jsonify({
            'success': True,
            'translated_question': cleaned_question,
            'choice_texts': choice_texts
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/translate/rationale', methods=['POST'])
def translate_rationale():
    """Translate Korean rationale to English with image analysis context."""
    data = request.json
    rationale_ko = data.get('rationale_ko', '').strip()
    image_id = data.get('image_id', None)
    view_type = data.get('view_type', 'exo')  # 'exo' or 'ego'
    
    if not rationale_ko:
        return jsonify({'success': False, 'error': 'Rationale (Korean) is required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ìºì‹œì—ì„œ)
        # ìºì‹œ í‚¤ëŠ” "image_id_model" í˜•ì‹ì´ë¯€ë¡œ ëª¨ë“  ëª¨ë¸ì˜ ìºì‹œë¥¼ í™•ì¸
        image_analysis = ""
        if image_id:
            # ê¸°ë³¸ ëª¨ë¸ë¶€í„° í™•ì¸
            for model_name in [DEFAULT_MODEL, 'openai']:
                cache_key = f"{image_id}_{model_name}"
                if cache_key in image_analysis_cache:
                    image_analysis = image_analysis_cache[cache_key]
                    break
        
        # Questionê³¼ Response ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì†Œê±°ë²• í˜•ì‹ì„ ìœ„í•´)
        question = data.get('question', '').strip()
        response = data.get('response', '').strip()  # ì˜ˆ: "(b) vase"
        
        # view íƒ€ì…ì— ë”°ë¼ ì‹œì‘ ë¬¸êµ¬ ê²°ì •
        question_type = "exo-centric" if view_type == 'exo' else "ego-centric"
        
        # ì´ë¯¸ì§€ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
        image_context = ""
        if image_analysis:
            image_context = f"""

IMAGE ANALYSIS CONTEXT:
{image_analysis}

Use this image analysis to better understand the visual context and spatial relationships when translating the rationale."""
        
        # ì†Œê±°ë²• í˜•ì‹ ê°€ì´ë“œ
        elimination_guide = ""
        if question and response:
            # Responseì—ì„œ ì •ë‹µ ì¶”ì¶œ (ì˜ˆ: "(b) vase" -> "b")
            response_match = re.search(r'\(([a-d])\)', response, re.IGNORECASE)
            if response_match:
                correct_answer = response_match.group(1).lower()
                # Choice íƒœê·¸ì—ì„œ ëª¨ë“  ì„ íƒì§€ ì¶”ì¶œ
                choice_match = re.search(r'<choice>(.*?)</choice>', question, re.IGNORECASE)
                if choice_match:
                    choice_content = choice_match.group(1)
                    choices = {}
                    for letter in ['a', 'b', 'c', 'd']:
                        pattern = rf'\({letter}\)\s*([^,)]+)'
                        match = re.search(pattern, choice_content, re.IGNORECASE)
                        if match:
                            choices[letter] = match.group(1).strip()
                    
                    elimination_guide = f"""

ELIMINATION METHOD FORMAT:
The rationale must follow an elimination method format:
1. Start with "The question is {question_type}:"
2. Explain why each incorrect choice (a, b, c, d) is excluded, EXCEPT for the correct answer ({correct_answer})
3. For each incorrect choice, state why it doesn't match the question criteria
4. Finally, explain why the correct answer ({correct_answer}: {choices.get(correct_answer, '')}) is the right choice
5. End with "Therefore [correct answer] is [the answer/description]." - DO NOT add any additional explanation after "Therefore" sentence
6. CRITICAL: After "Therefore" statement, do NOT add phrases like "as it is...", "because it is...", "since it is...", or any additional descriptive clauses

Example format:
"The question is {question_type}: [Choice a] is excluded because [reason]. [Choice b] is excluded because [reason]. [Choice c] is excluded because [reason]. Therefore [correct answer] is [the answer/description]."

WRONG examples (DO NOT include):
- "Therefore the sandwich is correct, as it is the closest edible object to the wine glass on the table in the restaurant."
- "Therefore the vase is correct because it is the farthest object from the boy."

CORRECT examples:
- "Therefore the sandwich is correct."
- "Therefore the vase is the farthest object from the boy, making the vase correct."

Current question: {question}
Correct answer: {response}
"""
        
        prompt = f"""Translate the following Korean rationale to English. Follow these CRITICAL requirements:{image_context}{elimination_guide}

REQUIREMENTS:
1. The rationale MUST start with "The question is {question_type}:"
2. Use elimination method format: explain why incorrect choices are excluded, then explain why the correct answer is right
3. The translation must be at least 2 sentences long
4. Make it natural, grammatically correct, and detailed
5. Use the image analysis context to create accurate descriptions of spatial relationships and object positions
6. DO NOT include any bounding box coordinates (x1, y1, x2, y2) or coordinate information in the rationale
7. When the Korean rationale mentions choice letters (a, b, c, d), translate them to the corresponding English choice text from the question
8. CRITICAL: End the rationale with a simple "Therefore" statement. DO NOT add additional explanatory clauses after "Therefore" such as "as it is...", "because it is...", "since it is...", or any descriptive phrases that repeat information already stated

Korean rationale: {rationale_ko}

Translate to English following the format and style of exo_data_sample.json examples."""
        
        # Choice ì •ë³´ë¥¼ rationale ë²ˆì—­ì— í™œìš©í•˜ê¸° ìœ„í•œ ë§¤í•‘ ìƒì„±
        choice_mapping = ""
        if question and response:
            choice_match = re.search(r'<choice>(.*?)</choice>', question, re.IGNORECASE)
            if choice_match:
                choice_content = choice_match.group(1)
                choices = {}
                for letter in ['a', 'b', 'c', 'd']:
                    pattern = rf'\({letter}\)\s*([^,)]+)'
                    match = re.search(pattern, choice_content, re.IGNORECASE)
                    if match:
                        choices[letter] = match.group(1).strip()
                
                if choices:
                    choice_mapping = f"""

CHOICE MAPPING (for translating choice letters in Korean rationale):
When the Korean rationale mentions choice letters (a, b, c, d) or Korean choice text, translate them to the corresponding English choice:
{', '.join([f'({k}) {v}' for k, v in choices.items()])}

For example, if the Korean rationale says "(d) í¬í¬" or just "d" or "í¬í¬", translate it to "fork" (which is choice (d) fork).
"""
        
        # í”„ë¡¬í”„íŠ¸ì— choice ë§¤í•‘ ì¶”ê°€
        enhanced_prompt = prompt + choice_mapping
        
        translated_rationale = ""
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"You are a professional translator specializing in VQA (Visual Question Answering) rationales. Always start with 'The question is {question_type}:' and use elimination method format with at least 2 sentences. Never include bounding box coordinates. When Korean rationale mentions choice letters (a, b, c, d) or Korean choice text, translate them to the corresponding English choice text. CRITICAL: End with a simple 'Therefore' statement - do NOT add additional explanatory clauses like 'as it is...', 'because it is...', or 'since it is...' after the 'Therefore' sentence."},
                    {"role": "user", "content": enhanced_prompt}
                ],
                temperature=0.3,
                max_tokens=400
            )
            
            translated_rationale = response.choices[0].message.content.strip()
        except Exception as api_error:
            print(f"[ERROR] API error in rationale translation: {type(api_error).__name__}: {str(api_error)}")
            import traceback
            traceback.print_exc()
            return jsonify({'success': False, 'error': f'Translation API error: {str(api_error)}'}), 500
        
        if not translated_rationale:
            return jsonify({'success': False, 'error': 'Translation returned empty result'}), 500
        
        # ì‹œì‘ ë¬¸êµ¬ ê²€ì¦
        if not translated_rationale.startswith(f"The question is {question_type}:"):
            # ìë™ìœ¼ë¡œ ì‹œì‘ ë¬¸êµ¬ ì¶”ê°€
            translated_rationale = f"The question is {question_type}: {translated_rationale}"
        
        # bounding box ì¢Œí‘œ ì œê±° (x1, y1, x2, y2 ë˜ëŠ” [x, y, w, h] í˜•ì‹)
        translated_rationale = re.sub(r'\[?\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*\]?', '', translated_rationale)
        translated_rationale = re.sub(r'bounding box[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
        translated_rationale = re.sub(r'bbox[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
        translated_rationale = re.sub(r'coordinate[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
        translated_rationale = re.sub(r'\(x\d+.*?y\d+.*?\)', '', translated_rationale, flags=re.IGNORECASE)
        
        # "Therefore" ë¬¸ì¥ ë’¤ì˜ ì¶”ê°€ ì„¤ëª… ì œê±° (as it is, because it is, since it is ë“±)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ", as it is", ", because it is", ", since it is" ê°™ì€ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì œê±°
        translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s*(as|because|since)\s+it\s+is[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ì¶”ê°€ ë¬¸ì¥ì´ ìˆê³ , ê·¸ê²ƒì´ "as it is", "because it is", "since it is"ë¡œ ì‹œì‘í•˜ë©´ ì œê±°
        translated_rationale = re.sub(r'(Therefore[^.]*\.)\s+((As|Because|Since)\s+it\s+is[^.]*?\.)', r'\1', translated_rationale, flags=re.IGNORECASE)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ", as" ë˜ëŠ” ", because" ë˜ëŠ” ", since"ë¡œ ì‹œì‘í•˜ëŠ” ì¶”ê°€ ì„¤ëª…ì´ ìˆìœ¼ë©´ ì œê±°
        translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s+(as|because|since)\s+[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
        # "Therefore" ë¬¸ì¥ì„ ì°¾ì•„ì„œ ê·¸ ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œê¹Œì§€ë§Œ ë‚¨ê¸°ê³ , ê·¸ ë’¤ì˜ ëª¨ë“  ì¶”ê°€ ì„¤ëª… ì œê±° (ë” ì•ˆì „í•œ ë°©ë²•)
        # "Therefore" ë¬¸ì¥ ë’¤ì— ë‚˜ì˜¤ëŠ” ", as it is..." ê°™ì€ ëª¨ë“  ì¶”ê°€ ì„¤ëª… ì œê±°
        therefore_match = re.search(r'(Therefore[^.]*?\.)', translated_rationale, re.IGNORECASE)
        if therefore_match:
            therefore_end = therefore_match.end()
            # "Therefore" ë¬¸ì¥ ë’¤ì— ", as", ", because", ", since" ê°™ì€ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì œê±°
            remaining = translated_rationale[therefore_end:].strip()
            if remaining:
                # ", as it is", ", because it is", ", since it is" ê°™ì€ íŒ¨í„´ ì œê±°
                remaining = re.sub(r'^,\s*(as|because|since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                # "As it is", "Because it is", "Since it is" ê°™ì€ íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ ì œê±°
                remaining = re.sub(r'^(As|Because|Since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                # ", as", ", because", ", since" ê°™ì€ íŒ¨í„´ ì œê±°
                remaining = re.sub(r'^,\s+(as|because|since)\s+[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                translated_rationale = translated_rationale[:therefore_end] + (' ' + remaining if remaining else '')
        
        translated_rationale = re.sub(r'\s+', ' ', translated_rationale).strip()
        
        # ë¬¸ì¥ ìˆ˜ í™•ì¸ (ìµœì†Œ 2ë¬¸ì¥)
        sentences = [s.strip() for s in translated_rationale.split('.') if s.strip()]
        sentence_count = len(sentences)
        
        if sentence_count < 2:
            # 2ë¬¸ì¥ ì´ìƒìœ¼ë¡œ í™•ì¥
            additional_prompt = f"""The following rationale is too short. Expand it to at least 2 sentences while maintaining the elimination method format. Do NOT include any bounding box coordinates or coordinate information:

Current rationale: {translated_rationale}

Expand it to at least 2 sentences, keeping the same format and style."""
            
            additional_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a professional translator. Expand the rationale to at least 2 sentences while maintaining the elimination method format. Never include bounding box coordinates."},
                    {"role": "user", "content": additional_prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            translated_rationale = additional_response.choices[0].message.content.strip()
            # ë‹¤ì‹œ bounding box ì¢Œí‘œ ì œê±°
            translated_rationale = re.sub(r'\[?\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*,\s*\d+\.?\d*\s*\]?', '', translated_rationale)
            translated_rationale = re.sub(r'bounding box[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'bbox[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'coordinate[^.]*\.?', '', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'\(x\d+.*?y\d+.*?\)', '', translated_rationale, flags=re.IGNORECASE)
            # "Therefore" ë¬¸ì¥ ë’¤ì˜ ì¶”ê°€ ì„¤ëª… ì œê±°
            translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s*(as|because|since)\s+it\s+is[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'(Therefore[^.]*\.)\s+((As|Because|Since)\s+it\s+is[^.]*?\.)', r'\1', translated_rationale, flags=re.IGNORECASE)
            translated_rationale = re.sub(r'(Therefore[^,.]*?)(,\s+(as|because|since)\s+[^.]*?\.)', r'\1.', translated_rationale, flags=re.IGNORECASE)
            # "Therefore" ë¬¸ì¥ì„ ì°¾ì•„ì„œ ê·¸ ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œê¹Œì§€ë§Œ ë‚¨ê¸°ê³ , ê·¸ ë’¤ì˜ ëª¨ë“  ì¶”ê°€ ì„¤ëª… ì œê±°
            therefore_match = re.search(r'(Therefore[^.]*?\.)', translated_rationale, re.IGNORECASE)
            if therefore_match:
                therefore_end = therefore_match.end()
                remaining = translated_rationale[therefore_end:].strip()
                if remaining:
                    remaining = re.sub(r'^,\s*(as|because|since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                    remaining = re.sub(r'^(As|Because|Since)\s+it\s+is[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                    remaining = re.sub(r'^,\s+(as|because|since)\s+[^.]*?\.', '', remaining, flags=re.IGNORECASE)
                    translated_rationale = translated_rationale[:therefore_end] + (' ' + remaining if remaining else '')
            translated_rationale = re.sub(r'\s+', ' ', translated_rationale).strip()
        
        return jsonify({
            'success': True,
            'translated_rationale': translated_rationale
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/review_translation', methods=['POST'])
def review_translation():
    """Review translated question, response, and rationale using GPT-5 for grammar and unnecessary phrases."""
    data = request.json
    question = data.get('question', '').strip()
    response = data.get('response', '').strip()
    rationale = data.get('rationale', '').strip()
    
    if not question and not rationale:
        return jsonify({'success': False, 'error': 'Question or Rationale is required'}), 400
    
    try:
        if not OPENAI_AVAILABLE:
            return jsonify({'success': False, 'error': 'OpenAI library not installed. Install with: pip install openai'}), 500
        
        if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
            return jsonify({'success': False, 'error': 'OPENAI_API_KEY is not set. Please set it in coco_web_annotator.py'}), 500
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ê²€ìˆ˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        review_prompt = f"""Review the following English translations for a VQA (Visual Question Answering) task. Check for:
1. Grammar errors and awkward phrasing
2. Unnecessary phrases or redundant words
3. Naturalness and clarity
4. Consistency with VQA format requirements

Question:
{question if question else '(empty)'}

Response:
{response if response else '(empty)'}

Rationale:
{rationale if rationale else '(empty)'}

CRITICAL INSTRUCTIONS:
- If the texts are grammatically correct, natural, and have no unnecessary phrases, respond with ONLY: "OK"
- If there are ANY issues that need revision, you MUST provide the response in EXACTLY this format (do not deviate):

=== Issues Found ===
[Here, explain in detail:
1. Which specific sentences are unnatural or have grammar errors
2. What the errors are (e.g., "The phrase 'X' is awkward because...")
3. What unnecessary phrases exist (e.g., "The word 'Y' is redundant")
4. How to fix each issue (e.g., "Change 'X' to 'Y' for better clarity")
Be very specific and detailed. Point out exact sentences and words that need fixing.]

=== Question (ìˆ˜ì •) ===
[If Question needs revision, provide the corrected version here. If Question is fine, write "(No changes needed)"]

=== Rationale (ìˆ˜ì •) ===
[If Rationale needs revision, provide the corrected version here. If Rationale is fine, write "(No changes needed)"]

IMPORTANT:
- You MUST always include the "=== Issues Found ===" section when there are any issues
- Be specific: mention exact sentence numbers, phrases, or words that are problematic
- Explain WHY each issue is a problem and HOW to fix it
- If everything is perfect, respond with ONLY "OK" (nothing else)"""
        
        review_result = None
        review_response = None
        
        try:
            # GPT-4o-mini ì‚¬ìš©
            review_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a professional English grammar and style reviewer for VQA (Visual Question Answering) tasks. Review texts for grammar, naturalness, and unnecessary phrases."},
                    {"role": "user", "content": review_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
        except Exception as api_error:
            print(f"[ERROR] GPT-4o-mini API error: {type(api_error).__name__}: {str(api_error)}")
            import traceback
            traceback.print_exc()
            return jsonify({
                'success': False,
                'error': f'Review API error: {str(api_error)}'
            }), 500
        
        # ì‘ë‹µ ê²€ì¦
        if not review_response:
            print(f"[ERROR] review_response is None")
            return jsonify({
                'success': False,
                'error': 'Failed to get response from GPT API'
            }), 500
        
        if not review_response.choices or len(review_response.choices) == 0:
            print(f"[ERROR] review_response.choices is empty")
            return jsonify({
                'success': False,
                'error': 'GPT API returned empty choices'
            }), 500
        
        if not review_response.choices[0].message or not review_response.choices[0].message.content:
            print(f"[ERROR] review_response.choices[0].message.content is empty")
            return jsonify({
                'success': False,
                'error': 'GPT API returned empty content'
            }), 500
        
        review_result = review_response.choices[0].message.content.strip()
        
        if not review_result or len(review_result) == 0:
            print(f"[ERROR] review_result is empty after strip")
            return jsonify({
                'success': False,
                'error': 'GPT API returned empty result'
            }), 500
        
        # "OK"ì¸ì§€ í™•ì¸
        review_upper = review_result.upper().strip()
        
        # OK ì²´í¬: ë‹¤ì–‘í•œ í˜•ì‹ì˜ OK ì¸ì‹
        # 1. ì •í™•íˆ "OK"
        # 2. "OK"ë¡œ ì‹œì‘í•˜ê³  ì§§ì€ ê²½ìš° (ì˜ˆ: "OK.", "OK\n", "OK ", "OKAY")
        # 3. "OK"ë§Œ í¬í•¨í•˜ê³  ë‹¤ë¥¸ ë‚´ìš©ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš°
        is_ok = False
        
        if review_upper == "OK":
            is_ok = True
        elif review_upper.startswith("OK") and len(review_upper) <= 20:
            # "OK"ë¡œ ì‹œì‘í•˜ê³  ì§§ì€ ê²½ìš°
            # "OK.", "OK\n", "OK ", "OKAY", "OK -", "OK:" ë“± í—ˆìš©
            remaining = review_upper[2:].strip()
            if not remaining or remaining in [".", ":", "-", " ", "\n", "\r", "\r\n"] or remaining.startswith(".") or remaining.startswith(":") or remaining.startswith("-"):
                is_ok = True
        elif "OK" in review_upper and len(review_upper) <= 30:
            # "OK"ê°€ í¬í•¨ë˜ì–´ ìˆê³  ì „ì²´ê°€ ì§§ì€ ê²½ìš° (ì˜ˆ: "The text is OK")
            # í•˜ì§€ë§Œ ë„ˆë¬´ ê¸´ ì„¤ëª…ì´ ìˆìœ¼ë©´ OKê°€ ì•„ë‹˜
            ok_index = review_upper.find("OK")
            before_ok = review_upper[:ok_index].strip()
            after_ok = review_upper[ok_index+2:].strip()
            # OK ì•ë’¤ë¡œ ì¤‘ìš”í•œ ë‚´ìš©ì´ ê±°ì˜ ì—†ìœ¼ë©´ OKë¡œ ê°„ì£¼
            if len(before_ok) <= 15 and len(after_ok) <= 10:
                is_ok = True
        
        if is_ok:
            return jsonify({
                'success': True,
                'needs_revision': False,
                'message': 'ê²€ìˆ˜ í†µê³¼',
                'review_notes': review_result
            })
        else:
            # ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš°
            revised_question = None
            revised_rationale = None
            issues_found = None
            
            # review_notesëŠ” í•­ìƒ ì±„ì›Œì•¼ í•¨ (ì´ë¯¸ ìœ„ì—ì„œ ê²€ì¦í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì²´í¬ë§Œ)
            if not review_result or len(review_result.strip()) == 0:
                print(f"[ERROR] review_result is empty in else block (should not happen)")
                return jsonify({
                    'success': False,
                    'error': 'Review result is empty'
                }), 500
            
            # === Issues Found === ë¶€ë¶„ ì¶”ì¶œ (ë” ìœ ì—°í•œ íŒ¨í„´)
            # íŒ¨í„´ 1: ì •í™•í•œ í˜•ì‹
            issues_match = re.search(r'=== Issues Found ===\s*([\s\S]*?)(?=\n\n=== Question|=== Rationale|=== Response|$)', review_result, re.IGNORECASE)
            if issues_match:
                issues_found = issues_match.group(1).strip()
            else:
                # íŒ¨í„´ 2: "Issues Found" ë˜ëŠ” "Issues:" ê°™ì€ ë³€í˜•
                issues_match2 = re.search(r'(?:Issues Found|Issues:|Problems:|Issues to fix):?\s*([\s\S]*?)(?=\n\n=== Question|=== Rationale|=== Response|$)', review_result, re.IGNORECASE)
                if issues_match2:
                    issues_found = issues_match2.group(1).strip()
                else:
                    # íŒ¨í„´ 3: Issues Foundê°€ ì—†ìœ¼ë©´ ì‘ë‹µì˜ ì²˜ìŒ ë¶€ë¶„ì„ Issuesë¡œ ì‚¬ìš© (Question/Rationale ì„¹ì…˜ ì „ê¹Œì§€)
                    before_question = re.search(r'^([\s\S]*?)(?=\n\n=== Question|=== Rationale|=== Response)', review_result, re.IGNORECASE)
                    if before_question and not review_result.startswith("==="):
                        # OKê°€ ì•„ë‹ˆê³  ì„¹ì…˜ í—¤ë”ê°€ ì—†ëŠ” ê²½ìš°, ì „ì²´ë¥¼ Issuesë¡œ ê°„ì£¼
                        issues_found = before_question.group(1).strip()
            
            # Issues Foundê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì˜ ì¼ë¶€ë¥¼ ì‚¬ìš©
            if not issues_found or len(issues_found) < 10:
                # Question/Rationale ì„¹ì…˜ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ Issuesë¡œ ì‚¬ìš©
                temp_result = review_result
                temp_result = re.sub(r'=== Question.*?===.*?(?=\n\n=== Rationale|$)', '', temp_result, flags=re.IGNORECASE | re.DOTALL)
                temp_result = re.sub(r'=== Rationale.*?===.*?$', '', temp_result, flags=re.IGNORECASE | re.DOTALL)
                temp_result = temp_result.strip()
                if temp_result and len(temp_result) > 10:
                    issues_found = temp_result
            
            # === Question (ìˆ˜ì •) === ë¶€ë¶„ ì¶”ì¶œ
            question_match = re.search(r'=== Question \(ìˆ˜ì •\) ===\s*([\s\S]*?)(?=\n\n=== Rationale|=== Response|$)', review_result, re.IGNORECASE)
            if question_match:
                revised_question = question_match.group(1).strip()
                # "(No changes needed)" ì²´í¬
                if revised_question.upper().strip() == "(NO CHANGES NEEDED)":
                    revised_question = None
            
            # === Rationale (ìˆ˜ì •) === ë¶€ë¶„ ì¶”ì¶œ
            rationale_match = re.search(r'=== Rationale \(ìˆ˜ì •\) ===\s*([\s\S]*?)$', review_result, re.IGNORECASE)
            if rationale_match:
                revised_rationale = rationale_match.group(1).strip()
                # "(No changes needed)" ì²´í¬
                if revised_rationale.upper().strip() == "(NO CHANGES NEEDED)":
                    revised_rationale = None
            
            # ìµœì¢… ê²€ì¦: Issues Foundê°€ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì„ Issuesë¡œ ì‚¬ìš©
            if not issues_found or len(issues_found) < 10:
                # Questionê³¼ Rationaleì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€
                full_text = review_result
                if revised_question:
                    full_text = re.sub(r'=== Question.*?===\s*' + re.escape(revised_question), '', full_text, flags=re.IGNORECASE | re.DOTALL)
                if revised_rationale:
                    full_text = re.sub(r'=== Rationale.*?===\s*' + re.escape(revised_rationale), '', full_text, flags=re.IGNORECASE | re.DOTALL)
                full_text = re.sub(r'=== .*? ===', '', full_text).strip()
                if full_text and len(full_text) > 10:
                    issues_found = full_text
            
            # ìµœì¢… ê²€ì¦: Issues Foundê°€ ì—¬ì „íˆ ì—†ê³ , Question/Rationaleë„ ì—†ìœ¼ë©´
            # ì „ì²´ ì‘ë‹µì„ Issues Foundë¡œ ì‚¬ìš©
            if (not issues_found or len(issues_found) < 10) and not revised_question and not revised_rationale:
                issues_found = review_result
            
            # ìµœì¢… ì‘ë‹µ êµ¬ì„±
            response_data = {
                'success': True,
                'needs_revision': True,
                'revised_question': revised_question,
                'revised_rationale': revised_rationale,
                'issues_found': issues_found,
                'review_notes': review_result
            }
            
            return jsonify(response_data)
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/save', methods=['POST'])
def save_annotation():
    """Save annotation data to JSON file."""
    data = request.json
    
    # Validation: Check required fields (bboxëŠ” ì„ íƒì‚¬í•­)
    required_fields = ['question', 'response', 'view']
    missing_fields = []
    
    for field in required_fields:
        if field == 'view':
            if not data.get(field) or data.get(field).strip() == '':
                missing_fields.append('view')
        else:
            if not data.get(field) or data.get(field).strip() == '':
                missing_fields.append(field)
    
    if missing_fields:
        return jsonify({
            'error': 'Missing required fields',
            'missing_fields': missing_fields,
            'message': f'Please fill in: {", ".join(missing_fields)}'
        }), 400
    
    # Get image info
    image_id = data['image_id']
    image_info = annotator.coco.imgs[image_id]
    view_type = data['view']
    
    # image_path ìƒì„±: "/íŒŒì¼ëª…" í˜•ì‹
    image_filename = image_info['file_name']
    relative_image_path = f"/{image_filename}"
    
    # bbox ì²˜ë¦¬: bboxê°€ ìˆìœ¼ë©´ ì²˜ë¦¬, ì—†ìœ¼ë©´ None (ì„ íƒì‚¬í•­)
    selected_bboxes = data.get('selected_bboxes', [])
    if selected_bboxes and len(selected_bboxes) > 0:
        if len(selected_bboxes) == 1:
            # ë‹¨ì¼ bboxì¸ ê²½ìš° ë°°ì—´ë¡œ ê°ì‹¸ì§€ ì•Šê³  ì§ì ‘ ì €ì¥
            bbox_value = selected_bboxes[0]
        else:
            # ì—¬ëŸ¬ bboxì¸ ê²½ìš° ë°°ì—´ë¡œ ì €ì¥
            bbox_value = selected_bboxes
    else:
        # bboxê°€ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì €ì¥
        bbox_value = None
    
    annotation = {
        'image_id': data['image_id'],
        'image_path': relative_image_path,  # ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½
        'image_resolution': f"{image_info['width']}x{image_info['height']}",  # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (web_annotations_exo.json, web_annotations_ego.jsonì—ë§Œ ì €ì¥)
        'question': data['question'],
        'response': data['response'],
        'rationale': data.get('rationale', ''),
        'question_ko': data.get('question_ko', ''),  # í•œê¸€ ì§ˆë¬¸ ì €ì¥
        'rationale_ko': data.get('rationale_ko', ''),  # í•œê¸€ ê·¼ê±° ì €ì¥
        'view': view_type,
        'bbox': bbox_value  # ë‹¨ì¼ bboxëŠ” ë°°ì—´ë¡œ ê°ì‹¸ì§€ ì•ŠìŒ
    }
    
    # view íƒ€ì…ì— ë”°ë¼ í•´ë‹¹ íŒŒì¼ ê²½ë¡œ ì„ íƒ
    output_path = annotator.output_json_path_exo if view_type == 'exo' else annotator.output_json_path_ego
    other_output_path = annotator.output_json_path_ego if view_type == 'exo' else annotator.output_json_path_exo
    
    # í•´ë‹¹ view íƒ€ì…ì˜ annotations ë¡œë“œ
    view_annotations = []
    if os.path.exists(output_path):
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                view_annotations = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            view_annotations = []
    
    # ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ì—ì„œë„ ê°™ì€ image_idê°€ ìˆìœ¼ë©´ ì œê±° (view íƒ€ì… ë³€ê²½ ì‹œ)
    other_view_annotations = []
    if os.path.exists(other_output_path):
        try:
            with open(other_output_path, 'r', encoding='utf-8') as f:
                other_view_annotations = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            other_view_annotations = []
    
    # ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ì—ì„œ ê°™ì€ image_id ì œê±°
    other_view_annotations = [ann for ann in other_view_annotations if ann.get('image_id') != data['image_id']]
    
    # í˜„ì¬ view íƒ€ì… íŒŒì¼ì—ì„œ ì—…ë°ì´íŠ¸ ë˜ëŠ” ì¶”ê°€
    found = False
    for i, ann in enumerate(view_annotations):
        if ann.get('image_id') == data['image_id']:
            view_annotations[i] = annotation  # ë®ì–´ì“°ê¸°
            found = True
            break
    
    if not found:
        view_annotations.append(annotation)  # ìƒˆë¡œ ì¶”ê°€
    
    
    # Save to file
    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        # í˜„ì¬ view íƒ€ì… íŒŒì¼ ì €ì¥ (bboxëŠ” í•œ ì¤„ë¡œ ì €ì¥)
        with open(output_path, 'w', encoding='utf-8') as f:
            json_str = json.dumps(view_annotations, indent=2, ensure_ascii=False)
            # bbox ë°°ì—´ì„ í•œ ì¤„ë¡œ ë³€ê²½: "bbox": [\n      ìˆ«ì,\n      ...\n    ] -> "bbox": [ìˆ«ì, ...]
            json_str = re.sub(
                r'"bbox":\s*\[\s*\n\s*([^\]]+?)\s*\n\s*\]',
                lambda m: f'"bbox": [{re.sub(r"\\s+", " ", m.group(1).strip())}]',
                json_str,
                flags=re.MULTILINE
            )
            f.write(json_str)
        
        # ë‹¤ë¥¸ view íƒ€ì… íŒŒì¼ë„ ì €ì¥ (ê°™ì€ image_id ì œê±°ëœ ë²„ì „)
        if other_view_annotations != [] or os.path.exists(other_output_path):
            other_output_dir = os.path.dirname(other_output_path)
            if other_output_dir and not os.path.exists(other_output_dir):
                os.makedirs(other_output_dir, exist_ok=True)
            with open(other_output_path, 'w', encoding='utf-8') as f:
                json_str = json.dumps(other_view_annotations, indent=2, ensure_ascii=False)
                # bbox ë°°ì—´ì„ í•œ ì¤„ë¡œ ë³€ê²½
                json_str = re.sub(
                    r'"bbox":\s*\[\s*\n\s*([^\]]+?)\s*\n\s*\]',
                    lambda m: f'"bbox": [{re.sub(r"\\s+", " ", m.group(1).strip())}]',
                    json_str,
                    flags=re.MULTILINE
                )
                f.write(json_str)
        
        # ì „ì²´ annotationsë„ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ë¡œë“œ ì‹œ ë°˜ì˜)
        annotator._reload_annotations()
        
        response_data = {'success': True, 'updated': found}
        
        return jsonify(response_data)
    except (IOError, OSError) as e:
        return jsonify({'error': f'Failed to save: {e}'}), 500


def create_template():
    """Create HTML template for the annotation interface."""
    template_dir = 'templates'
    if not os.path.exists(template_dir):
        os.makedirs(template_dir)

    # index.html ë®ì–´ì“°ê¸° ë°©ì§€ ì¶”ê°€
    target = os.path.join(template_dir, 'index.html')
    if os.path.exists(target):
        return
    
    html_content = '''<!DOCTYPE html>
<html>
<head>
    <title>COCO Annotation Tool</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .container { display: flex; gap: 20px; }
        .image-panel { flex: 2; }
        .control-panel { flex: 1; min-width: 350px; }
        .image-container { 
            border: 2px solid #ccc; 
            position: relative; 
            display: inline-block;
        }
        #image { max-width: 100%; display: block; }
        .bbox { 
            position: absolute; 
            border: 2px solid rgba(255, 0, 0, 0.7); 
            background-color: rgba(255, 0, 0, 0.1);
            cursor: pointer;
            transition: all 0.2s ease;
            z-index: 10;
        }
        .bbox:hover { 
            border-color: rgba(255, 255, 0, 0.9);
            background-color: rgba(255, 255, 0, 0.2);
            transform: scale(1.05);
            box-shadow: 0 0 10px rgba(255, 255, 0, 0.5);
            z-index: 20;
        }
        .bbox.selected { 
            border-color: rgba(0, 0, 255, 0.9);
            background-color: rgba(0, 0, 255, 0.2);
            border-width: 3px;
        }
        .bbox.selected:hover { 
            border-color: rgba(0, 255, 255, 0.9);
            background-color: rgba(0, 255, 255, 0.3);
        }
        .bbox-label {
            position: absolute;
            top: -20px;
            left: 0;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 2px 5px;
            font-size: 11px;
            white-space: nowrap;
            display: none;
            pointer-events: none;
        }
        .bbox:hover .bbox-label {
            display: block;
        }
        .form-group { margin-bottom: 15px; }
        label { display: block; font-weight: bold; margin-bottom: 5px; }
        textarea, input { width: 100%; padding: 8px; border: 1px solid #ccc; }
        button { 
            padding: 10px 15px; 
            margin: 5px; 
            border: none; 
            cursor: pointer;
        }
        .btn-save { background-color: lightgreen; }
        .btn-nav { background-color: lightblue; }
        .status { 
            position: fixed; 
            bottom: 0; 
            left: 0; 
            right: 0; 
            background: #f0f0f0; 
            padding: 10px; 
            border-top: 1px solid #ccc;
        }
    </style>
</head>
<body>
    <h1>MS-COCO Annotation Tool (Web Version)</h1>
    
    <div class="container">
        <div class="image-panel">
            <div class="image-container" id="imageContainer">
                <img id="image" src="" alt="COCO Image">
            </div>
        </div>
        
        <div class="control-panel">
            <div class="form-group">
                <label>Image Info:</label>
                <div id="imageInfo">Loading...</div>
            </div>
            
            <div class="form-group">
                <label for="question">Question: 
                    <span style="color: red;">*</span></label>
                <textarea id="question" rows="4"></textarea>
            </div>
            
            <div class="form-group">
                <label for="response">Response: 
                    <span style="color: red;">*</span></label>
                <textarea id="response" rows="4"></textarea>
            </div>
            
            <div class="form-group">
                <label for="rationale">Rationale:</label>
                <textarea id="rationale" rows="3"></textarea>
            </div>
            
            <div class="form-group">
                <label>View: <span style="color: red;">*</span></label>
                <div>
                    <input type="radio" id="viewExo" name="view" value="exo">
                    <label for="viewExo">Exo</label>
                </div>
                <div>
                    <input type="radio" id="viewEgo" name="view" value="ego">
                    <label for="viewEgo">Ego</label>
                </div>
            </div>
            
            <div class="form-group">
                <label for="selectedBboxes">Selected Bounding Boxes: 
                    <span style="color: red;">*</span></label>
                <textarea id="selectedBboxes" rows="3" readonly></textarea>
                <button onclick="clearBboxes()">Clear Bboxes</button>
            </div>
            
            <div class="form-group">
                <button class="btn-nav" onclick="previousImage()">Previous</button>
                <button class="btn-nav" onclick="nextImage()">Next</button>
                <button class="btn-save" onclick="saveAnnotation()">Save</button>
            </div>
        </div>
    </div>
    
    <div class="status" id="status">Ready</div>

    <script>
        let currentIndex = 0;
        let currentImageData = null;
        let selectedBboxes = [];
        let bboxElements = [];

        function loadImage(index) {
            fetch(`/api/image/${index}`)
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert(data.error);
                        return;
                    }
                    
                    currentImageData = data;
                    currentIndex = index;
                    
                    // Update image
                    const img = document.getElementById('image');
                    img.src = data.image_data;
                    
                    // Wait for image to load before drawing bboxes
                    img.onload = () => {
                        drawBboxes();
                    };
                    
                    // Update info
                    document.getElementById('imageInfo').innerHTML = 
                        `Image ${index + 1}/${data.total_images}<br>` +
                        `ID: ${data.image_id}<br>` +
                        `Original Size: ${data.width}x` +
                        `${data.height}<br>` +
                        `Display Size: ${data.display_width}x` +
                        `${data.display_height}<br>` +
                        `File: ${data.file_name}`;
                    
                    // Load existing annotation
                    if (data.existing_annotation) {
                        document.getElementById('question').value = 
                            data.existing_annotation.question || '';
                        document.getElementById('response').value = 
                            data.existing_annotation.response || '';
                        document.getElementById('rationale').value = 
                            data.existing_annotation.rationale || '';
                        selectedBboxes = data.existing_annotation.bbox || [];
                        
                        // Set view radio button
                        const view = data.existing_annotation.view || '';
                        if (view === 'exo') {
                            document.getElementById('viewExo').checked = true;
                        } else if (view === 'ego') {
                            document.getElementById('viewEgo').checked = true;
                        }
                    } else {
                        document.getElementById('question').value = '';
                        document.getElementById('response').value = '';
                        document.getElementById('rationale').value = '';
                        selectedBboxes = [];
                        // Clear view radio buttons
                        document.getElementById('viewExo').checked = false;
                        document.getElementById('viewEgo').checked = false;
                    }
                    
                    updateBboxDisplay();
                    updateStatus();
                })
                .catch(error => {
                    console.error('Error:', error);
                    alert('Failed to load image');
                });
        }

        function drawBboxes() {
            // Clear existing bboxes
            bboxElements.forEach(el => el.remove());
            bboxElements = [];
            
            if (!currentImageData) return;
            
            const container = document.getElementById('imageContainer');
            const img = document.getElementById('image');
            const scale = currentImageData.scale || 1.0;
            
            currentImageData.bboxes.forEach((bbox, index) => {
                const [x, y, w, h] = bbox;
                
                // Scale bbox coordinates to match displayed image size
                const scaledX = x * scale;
                const scaledY = y * scale;
                const scaledW = w * scale;
                const scaledH = h * scale;
                
                const div = document.createElement('div');
                div.className = 'bbox';
                div.style.left = `${scaledX}px`;
                div.style.top = `${scaledY}px`;
                div.style.width = `${scaledW}px`;
                div.style.height = `${scaledH}px`;
                
                // Add label
                const label = document.createElement('div');
                label.className = 'bbox-label';
                label.textContent = `Box ${index + 1}: [${x},${y},${w},${h}]`;
                div.appendChild(label);
                
                // Check if selected
                if (selectedBboxes.some(sb => 
                    JSON.stringify(sb) === JSON.stringify(bbox))) {
                    div.classList.add('selected');
                }
                
                // Add click event
                div.addEventListener('click', (e) => {
                    e.stopPropagation();
                    selectBbox(bbox, div);
                });
                
                container.appendChild(div);
                bboxElements.push(div);
            });
        }

        function selectBbox(bbox, element) {
            const bboxStr = JSON.stringify(bbox);
            const existingIndex = selectedBboxes.findIndex(sb => 
                JSON.stringify(sb) === bboxStr);
            
            if (existingIndex === -1) {
                selectedBboxes.push(bbox);
                element.classList.add('selected');
            } else {
                selectedBboxes.splice(existingIndex, 1);
                element.classList.remove('selected');
            }
            
            updateBboxDisplay();
            updateStatus();
        }

        function updateBboxDisplay() {
            const display = selectedBboxes.map(bbox => 
                `[${bbox.join(',')}]`).join(', ');
            document.getElementById('selectedBboxes').value = display;
        }

        function clearBboxes() {
            selectedBboxes = [];
            updateBboxDisplay();
            drawBboxes();
        }

        function previousImage() {
            if (currentIndex > 0) {
                loadImage(currentIndex - 1);
            }
        }

        function nextImage() {
            loadImage(currentIndex + 1);
        }

        function saveAnnotation() {
            const question = document.getElementById('question').value.trim();
            const response = document.getElementById('response').value.trim();
            const rationale = document.getElementById('rationale').value.trim();
            
            // Get selected view
            const viewRadios = document.getElementsByName('view');
            let selectedView = '';
            for (let radio of viewRadios) {
                if (radio.checked) {
                    selectedView = radio.value;
                    break;
                }
            }
            
            // Client-side validation
            const missingFields = [];
            if (!question) missingFields.push('question');
            if (!response) missingFields.push('response');
            if (!selectedView) missingFields.push('view');
            if (selectedBboxes.length === 0) missingFields.push('bbox');
            
            if (missingFields.length > 0) {
                alert(`Please fill in the following required fields: ` +
                      `${missingFields.join(', ')}`);
                return;
            }
            
            const data = {
                image_id: currentImageData.image_id,
                question: question,
                response: response,
                rationale: rationale,
                view: selectedView,
                selected_bboxes: selectedBboxes
            };
            
            fetch('/api/save', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify(data)
            })
            .then(response => response.json())
            .then(result => {
                if (result.success) {
                    alert('Annotation saved successfully!');
                    nextImage();
                } else {
                    if (result.missing_fields) {
                        alert(`Server validation failed: ${result.message}`);
                    } else {
                        alert('Failed to save: ' + result.error);
                    }
                }
            })
            .catch(error => {
                console.error('Error:', error);
                alert('Failed to save annotation');
            });
        }

        function updateStatus() {
            document.getElementById('status').textContent = 
                `Current: ${currentIndex + 1} | Selected bboxes: ` +
                `${selectedBboxes.length}`;
        }

        // Auto-save function
        function autoSave() {
            const question = document.getElementById('question').value.trim();
            const response = document.getElementById('response').value.trim();
            const rationale = document.getElementById('rationale').value.trim();
            
            // Get selected view
            const viewRadios = document.getElementsByName('view');
            let selectedView = '';
            for (let radio of viewRadios) {
                if (radio.checked) {
                    selectedView = radio.value;
                    break;
                }
            }
            
            // Only auto-save if all required fields are filled
            if (currentImageData && question && response && 
                selectedView && selectedBboxes.length > 0) {
                const data = {
                    image_id: currentImageData.image_id,
                    question: question,
                    response: response,
                    rationale: rationale,
                    view: selectedView,
                    selected_bboxes: selectedBboxes
                };
                
                fetch('/api/save', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(data)
                })
                .then(response => response.json())
                .then(result => {
                    if (result.success) {
                        console.log('Auto-saved');
                    }
                })
                .catch(error => {
                    console.error('Auto-save error:', error);
                });
            }
        }

        // Save on unload
        window.addEventListener('beforeunload', (e) => {
            autoSave();
        });

        // Auto-save every 30 seconds
        setInterval(autoSave, 30000);

        // Handle keyboard shortcuts
        document.addEventListener('keydown', (e) => {
            if (e.ctrlKey || e.metaKey) {
                if (e.key === 's') {
                    e.preventDefault();
                    saveAnnotation();
                } else if (e.key === 'ArrowLeft') {
                    e.preventDefault();
                    previousImage();
                } else if (e.key === 'ArrowRight') {
                    e.preventDefault();
                    nextImage();
                }
            }
        });

        // Load first image on start
        loadImage(0);
    </script>
</body>
</html>'''
    
    with open(os.path.join(template_dir, 'index.html'), 'w', encoding='utf-8') as f:
        f.write(html_content)


def main():
    """Main function to start the web server."""
    
    parser = argparse.ArgumentParser(
        description='Web-based COCO Annotation Tool')
    parser.add_argument('--mscoco_folder', 
                        default='./mscoco',
                        help='Path to mscoco folder (contains exo_images and ego_images)')
    parser.add_argument('--coco_json', 
                        default='/Data/MSCOCO/annotations/instances_train2017.json',
                        help='Path to COCO annotations JSON file')
    parser.add_argument('--output_json', required=True,
                        help='Path to output JSON file for annotations')
    parser.add_argument('--host', default='0.0.0.0', 
                        help='Host to run server on')
    parser.add_argument('--port', default=5000, type=int, 
                        help='Port to run server on')
    parser.add_argument('--categories_json', default=None,
                        help='Path to custom categories JSON (list of {id,name})')
    parser.add_argument('--test_folder', default=None,
                        help='Test folder name (e.g., exo_test_image) to use instead of exo_images')

    
    args = parser.parse_args()
    
    # Validate paths
    if not os.path.exists(args.mscoco_folder):
        print(f"Error: mscoco folder not found: {args.mscoco_folder}")
        return
    
    # í…ŒìŠ¤íŠ¸ í´ë”ê°€ ì§€ì •ë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ë³¸ í´ë” í™•ì¸
    if args.test_folder:
        exo_images_path = os.path.join(args.mscoco_folder, args.test_folder)
        print(f"[INFO] Using test folder: {exo_images_path}")
        # test_folder ëª¨ë“œì—ì„œëŠ” ego_images_pathë¥¼ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        ego_images_path = None
    else:
        exo_images_path = os.path.join(args.mscoco_folder, 'exo_images')
        ego_images_path = os.path.join(args.mscoco_folder, 'ego_images')
    
    if not os.path.exists(exo_images_path):
        print(f"Warning: exo images folder not found: {exo_images_path}")
    if ego_images_path and not os.path.exists(ego_images_path):
        print(f"Warning: ego_images folder not found: {ego_images_path}")
    
    if not os.path.exists(args.coco_json):
        print(f"Error: COCO JSON file not found: {args.coco_json}")
        return
    
    # Create output directory
    output_dir = os.path.dirname(args.output_json) if os.path.dirname(args.output_json) else '.'
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    # Initialize global annotator
    global annotator
    annotator = COCOWebAnnotator(args.mscoco_folder, args.coco_json, 
                                 args.output_json, args.categories_json, 
                                 test_folder=args.test_folder)
    
    # Create template
    create_template()
    
    
    print(f"Starting web server at http://{args.host}:{args.port}")
    print("Access the annotation tool in your web browser")
    print(f"Exo annotations will be saved to: {annotator.output_json_path_exo}")
    print(f"Ego annotations will be saved to: {annotator.output_json_path_ego}")
    
    # ë©€í‹°ìŠ¤ë ˆë“œ ëª¨ë“œë¡œ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ë°©ì§€)
    app.run(host=args.host, port=args.port, debug=True, threaded=True)


if __name__ == "__main__":
    main()
